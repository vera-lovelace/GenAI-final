{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vera-lovelace/GenAI-final/blob/main/Extended_RAG_Model_GraphRAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YzICc7GNDQS"
      },
      "source": [
        "# RAG Mini Project\n",
        "## Milestone #2 : Vectorise and store Chunks\n",
        "\n",
        "Use the embedding code from Assignment A1 to create embeddings from the  text chunks generated and save in Pickle file from Milestone #1.\n",
        "\n",
        "Create a Python dictionary as a Vector database using the embedding vector as keys (note: convert list of embeddings to a tuple) and the text as the value\n",
        "Experiment with some queries and use cosine similarity to get the most similar text from your vector database.\n",
        "If the results are not satisfactory, you may want to refactor your code by:\n",
        "changing the embedding technique\n",
        "modifying the chunking technique from Milestone #1. Your code should be modular enough to make this fairly straightforward if needed. It is what software development is all about.\n",
        "When satisfied, store your Python dict (vector db) in a pickle file.\n",
        "\n",
        "\n",
        "### Deliverables: Zip file with\n",
        "\n",
        "Jupyter Notebook\n",
        "Summary of your efforts (issues, success in matching chunks to queries based on embeddings, …)\n",
        "Pickle file with the Python vector database for use in the final Mini Project Deliverable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NqMv3iTNUGM",
        "outputId": "e8a4f896-02cc-45f3-a516-84311f99ecaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n",
            "Collecting docx\n",
            "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from docx) (5.3.1)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.11/dist-packages (from docx) (11.1.0)\n",
            "Building wheels for collected packages: docx\n",
            "  Building wheel for docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53892 sha256=7bbff404ee47ea5dffa96ebfb2871bd673d32f1a9f3a6ff1d2c5e3b93b4d99d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/3e/c3/e81c11effd0be5658a035947c66792dd993bcff317eae0e1ed\n",
            "Successfully built docx\n",
            "Installing collected packages: docx\n",
            "Successfully installed docx-0.2.4\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "\n",
        "!pip install python-docx\n",
        "!pip install docx\n",
        "\n",
        "from docx import Document\n",
        "from io import BytesIO\n",
        "import re\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab import files\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ftyx_HIB2Jf3"
      },
      "outputs": [],
      "source": [
        "# Extract Chunks using document paragraphs\n",
        "# Chunk size is controlled by parameter\n",
        "\n",
        "def extract_fixed_chunks(file_path, chunk_size=1000):\n",
        "    \"\"\"\n",
        "    Extract fixed-size chunks from a Word document.\n",
        "\n",
        "    Args:\n",
        "        file_path (str or bytes): Path to Word document or binary content\n",
        "        chunk_size (int): Target size of each chunk in characters\n",
        "\n",
        "    Returns:\n",
        "        list: List of text chunks of approximately chunk_size characters\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Handle both file path and binary content\n",
        "        if isinstance(file_path, bytes):\n",
        "            doc = Document(BytesIO(file_path))\n",
        "        else:\n",
        "            doc = Document(file_path)\n",
        "\n",
        "        # Extract and clean all text\n",
        "        full_text = \"\"\n",
        "        for para in doc.paragraphs:\n",
        "            text = para.text.strip()\n",
        "            if text:  # Skip empty paragraphs\n",
        "                # Clean and normalise the text\n",
        "                text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
        "                text = re.sub(r'\\s+', ' ', text)  # Remove multiple spaces\n",
        "                full_text += text + \" \"  # Add space between paragraphs\n",
        "\n",
        "        # Split text into sentences\n",
        "        sentences = re.split('(?<=[.!?-]) +', full_text)\n",
        "\n",
        "        chunks = []\n",
        "        current_chunk = \"\"\n",
        "\n",
        "        for sentence in sentences:\n",
        "            # If adding this sentence would exceed chunk_size\n",
        "            if len(current_chunk) + len(sentence) > chunk_size:\n",
        "                # If current chunk is not empty, add it to chunks\n",
        "                if current_chunk:\n",
        "                    chunks.append(current_chunk.strip())\n",
        "                    current_chunk = \"\"\n",
        "\n",
        "                # Handle sentences longer than chunk_size\n",
        "                if len(sentence) > chunk_size:\n",
        "                    # Split long sentence into fixed-size chunks\n",
        "                    words = sentence.split()\n",
        "                    temp_chunk = \"\"\n",
        "\n",
        "                    for word in words:\n",
        "                        if len(temp_chunk) + len(word) + 1 <= chunk_size:\n",
        "                            temp_chunk += (\" \" + word if temp_chunk else word)\n",
        "                        else:\n",
        "                            chunks.append(temp_chunk.strip())\n",
        "                            temp_chunk = word\n",
        "\n",
        "                    if temp_chunk:\n",
        "                        current_chunk = temp_chunk\n",
        "                else:\n",
        "                    current_chunk = sentence\n",
        "            else:\n",
        "                # Add sentence to current chunk\n",
        "                current_chunk += (\" \" + sentence if current_chunk else sentence)\n",
        "\n",
        "        # Add the last chunk if not empty\n",
        "        if current_chunk:\n",
        "            chunks.append(current_chunk.strip())\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error processing document: {str(e)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: a function that reads triples from a .txt file, vectorises the triples and stores them in a dictionary with the embedding as key and the triple as value\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def vectorise_triples(file_path):\n",
        "    \"\"\"\n",
        "    Reads triples from a text file, vectorizes them, and stores them in a dictionary.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the .txt file containing the triples.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are embedding vectors (as tuples) and values are the corresponding triples.\n",
        "              Returns an empty dictionary if the file does not exist or if an error occurs during processing.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            triples = [line.strip() for line in file if line.strip()]\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at '{file_path}'\")\n",
        "        return {}\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the file: {e}\")\n",
        "        return {}\n",
        "\n",
        "    model = SentenceTransformer('all-mpnet-base-v2') # Example model\n",
        "    vector_database = {}\n",
        "\n",
        "    for triple in triples:\n",
        "      try:\n",
        "          embedding = model.encode(triple)\n",
        "          vector_database[tuple(embedding)] = triple\n",
        "      except Exception as e:\n",
        "          print(f\"Error processing triple '{triple}': {e}\")\n",
        "\n",
        "    return vector_database\n",
        "\n",
        "# Example usage\n",
        "file_path = 'your_triples_file.txt' # Replace with your file path\n",
        "vector_db = vectorise_triples(file_path)\n",
        "\n",
        "\n",
        "# Save the vector database to a pickle file\n",
        "with open('vector_database.pickle', 'wb') as handle:\n",
        "    pickle.dump(vector_db, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "iqLc3lvI74HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find cosine similarity of sentences\n",
        "def find_similar_sentences(query, plain_embeddings=True, graph_embeddings=False):\n",
        "    \"\"\"\n",
        "    Finds similar texts to query based on similarity threshold.\n",
        "\n",
        "    Args:\n",
        "        query: embeddings of query\n",
        "        plain_embeddings: List of plain text embeddings\n",
        "        graph_embeddings: List of graph base embeddings\n",
        "\n",
        "    Returns:\n",
        "        List of similar sentence embeddings\n",
        "    \"\"\"\n",
        "    similar_sentences = []\n",
        "    if plain_embeddings:\n",
        "      for i in range(len(plain_embeddings)):\n",
        "          similarity = np.dot(query, plain_embeddings[i]) / (\n",
        "              np.linalg.norm(query) * np.linalg.norm(plain_embeddings[i]))\n",
        "          if similarity > 0.55:\n",
        "              similar_sentences.append(plain_embeddings[i])\n",
        "    if graph_embeddings:\n",
        "      for i in range(len(graph_embeddings)):\n",
        "          similarity = np.dot(query, graph_embeddings[i]) / (\n",
        "              np.linalg.norm(query) * np.linalg.norm(graph_embeddings[i]))\n",
        "          if similarity > 0.55:\n",
        "              similar_sentences.append(graph_embeddings[i])\n",
        "    return similar_sentences"
      ],
      "metadata": {
        "id": "UzfkeP_CCi3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fZdcpvLSHCy",
        "outputId": "09ae27f1-f7fe-4f4b-eabd-53a895ab3b4b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5 Word documents\n",
            "\n",
            "Processing: 3.Major Data Breaches and Their Impact on Privacy Regulation.docx\n",
            "\n",
            "Generating embeddings for next 3 chunks...\n",
            "\n",
            "\n",
            "Processing: 2.DevelopmentPrivacyProtectionUSA.docx\n",
            "\n",
            "Generating embeddings for next 3 chunks...\n",
            "\n",
            "\n",
            "Processing: 5.Global Approaches to Data Protection.docx\n",
            "\n",
            "Generating embeddings for next 2 chunks...\n",
            "\n",
            "\n",
            "Processing: 1.The Evolution of Privacy.docx\n",
            "\n",
            "Generating embeddings for next 3 chunks...\n",
            "\n",
            "\n",
            "Processing: 4.The Evolution of European Data Protection.docx\n",
            "\n",
            "Generating embeddings for next 3 chunks...\n",
            "\n",
            "\n",
            "Extracting relevant chunks to queries...\n",
            "\n",
            "Query: When was the TRW Credit Data breach and how many credit records were exposed?\n",
            "Similar Sentences:\n",
            "Major Data Breaches and Their Impact on Privacy Regulation The history of data protection has been significantly shaped by major data breaches, each contributing to evolving privacy regulations and security practices. This document examines key breaches and their lasting impact on privacy protection. Early Notable Breaches (1984-2000): The TRW Credit Data breach in 1984 exposed 90 million credit records, leading to: - Enhanced security requirements for credit reporting agencies - Creation of consumer protection measures - Implementation of access controls The emergence of e-commerce in the 1990s brought new vulnerabilities: - CD Universe breach (1999) - 300,000 credit card numbers exposed - Egghead.com breach (2000) - 3.7 million customer records compromised These early incidents highlighted the need for: - Encryption of stored data - Secure transaction processing - Regular security audits Major Breaches of the 2000s: 2005 ChoicePoint Breach: - 163,000 consumer records compromised - $15 million in fines - Led to first state breach notification law in California - Sparked national discussion on data broker regulation 2007 TJX Companies Breach: - 45.7 million credit card numbers stolen - $256 million in costs - Resulted in: - PCI DSS compliance enhancement - Improved payment security standards - Increased focus on encryption Transformative Breaches (2010-2020): 2013 Target Breach: - 40 million credit card numbers exposed - 70 million customer records compromised -\n",
            "\n",
            "\n",
            "Query: How have major data breaches influenced the development of privacy regulations in both the EU and US? Provide specific examples.\n",
            "Similar Sentences:\n",
            "Major Data Breaches and Their Impact on Privacy Regulation The history of data protection has been significantly shaped by major data breaches, each contributing to evolving privacy regulations and security practices. This document examines key breaches and their lasting impact on privacy protection. Early Notable Breaches (1984-2000): The TRW Credit Data breach in 1984 exposed 90 million credit records, leading to: - Enhanced security requirements for credit reporting agencies - Creation of consumer protection measures - Implementation of access controls The emergence of e-commerce in the 1990s brought new vulnerabilities: - CD Universe breach (1999) - 300,000 credit card numbers exposed - Egghead.com breach (2000) - 3.7 million customer records compromised These early incidents highlighted the need for: - Encryption of stored data - Secure transaction processing - Regular security audits Major Breaches of the 2000s: 2005 ChoicePoint Breach: - 163,000 consumer records compromised - $15 million in fines - Led to first state breach notification law in California - Sparked national discussion on data broker regulation 2007 TJX Companies Breach: - 45.7 million credit card numbers stolen - $256 million in costs - Resulted in: - PCI DSS compliance enhancement - Improved payment security standards - Increased focus on encryption Transformative Breaches (2010-2020): 2013 Target Breach: - 40 million credit card numbers exposed - 70 million customer records compromised -\n",
            "\n",
            "\n",
            "The Development of Privacy Protection in the United States: A Sectoral Approach The United States has historically taken a markedly different approach to privacy protection compared to Europe, developing a patchwork of sector-specific laws rather than comprehensive federal legislation. This sectoral approach reflects American values of free market economics and limited government intervention. Early Privacy Developments (1960s-1970s): The Fair Credit Reporting Act of 1970 was one of the first federal laws addressing privacy concerns, focusing specifically on the collection and use of consumer credit information. This law established important principles including: - Consumer right to access their credit reports - Requirement for accurate reporting - Time limits on negative information - Procedures for disputing incorrect information The Privacy Act of 1974 represented another significant step, though limited to government agencies. It established: - Rules for government collection and use of personal data - Individual rights to access and correct records - Restrictions on sharing between agencies - Civil and criminal penalties for violations The Evolution of Sectoral Privacy Laws: Different industries received specific privacy regulations over time: Healthcare: The Health Insurance Portability and Accountability Act (HIPAA) of 1996 created comprehensive privacy rules for medical information, including: - Patient rights to access medical records -\n",
            "\n",
            "\n",
            "Restrictions on information sharing - Security requirements for health data - Breach notification requirements - Substantial penalties for violations Financial Services: The Gramm-Leach-Bliley Act of 1999 established privacy rules for financial institutions: - Required privacy notices to customers - Opt-out rights for information sharing - Security standards for financial data - State enforcement mechanisms Children's Privacy: The Children's Online Privacy Protection Act (COPPA) of 1998 specifically addressed children's privacy online: - Parental consent requirements - Restrictions on data collection from children under 13 - Requirements for privacy policies - Limits on marketing to children Education: The Family Educational Rights and Privacy Act (FERPA) protects student education records: - Parent/student rights to access records - Limitations on disclosure without consent - Requirements for schools' privacy practices The Digital Age and New Challenges: The rise of internet companies in the 1990s and 2000s exposed gaps in U.S. privacy protection. The Federal Trade Commission (FTC) became the de facto privacy regulator, using its authority to: - Enforce company privacy promises - Investigate data breaches - Issue privacy guidelines - Impose fines for privacy violations Notable FTC actions included: - 2011 Facebook settlement requiring privacy audits - 2012 Google privacy violation fine ($22.5 million) -\n",
            "\n",
            "\n",
            "Global Approaches to Data Protection: A Comparative Analysis Data protection approaches vary significantly across different regions of the world, reflecting diverse cultural, political, and economic priorities. This document examines how different regions approach privacy and data protection. European Union Approach: Comprehensive Protection: - GDPR as global standard - Privacy as fundamental right - Strict consent requirements - Significant penalties - Data Protection Authorities Key Features: - Data minimization principles - Purpose limitation - Storage limitations - Individual rights emphasis - Cross-border transfer restrictions United States Approach: Sectoral Regulation: - Industry-specific laws - State-level legislation - FTC enforcement - Market-driven solutions - Limited federal oversight Key Features: - Consumer protection focus - Industry self-regulation - State-level innovation - Breach notification requirements - Sectoral compliance frameworks Asia-Pacific Approaches: China: - Personal Information Protection Law (2021) - Cybersecurity Law (2017) - Data localization requirements - State security emphasis - Strict cross-border data rules Japan: - Act on Protection of Personal Information - GDPR adequacy decision - Balanced approach - Cultural privacy norms - International cooperation focus South Korea: - Personal Information Protection Act - Strict consent requirements - Criminal penalties - Comprehensive protection -\n",
            "\n",
            "\n",
            "The Evolution of European Data Protection: From Privacy Rights to GDPR The European approach to data protection and privacy has its roots in the aftermath of World War II, when privacy was recognized as a fundamental human right in the 1950 European Convention on Human Rights. This early foundation would shape decades of European privacy legislation and establish a distinctly European approach to data protection. The first significant European data protection law emerged in 1970, when the German state of Hesse passed the world's first data protection statute. This pioneering legislation established core principles that would later influence wider European data protection frameworks, including the concepts of data minimization and purpose limitation. The 1981 Council of Europe Convention 108 marked the first legally binding international treaty addressing privacy and data protection. It required signatories to enact legislation concerning the automatic processing of personal data and established key principles such as: - Fair and lawful data collection and processing - Storage limitation - Data accuracy requirements - Appropriate security measures A major milestone came in 1995 with the European Data Protection Directive (95/46/EC). This directive: - Harmonized data protection laws across EU member states - Established the concept of \"adequate level of protection\" for data transfers - Created national data protection authorities -\n",
            "\n",
            "\n",
            "Introduced the principles of purpose limitation and data minimization The rise of social media and cloud computing in the 2000s exposed limitations in the 1995 directive. Facebook's launch in Europe in 2006 and Google's growing presence highlighted new challenges in personal data processing and cross-border data flows. The concept of \"privacy by design\" emerged during this period, championed by regulators as a proactive approach to privacy protection. The 2012 \"right to be forgotten\" case against Google in Spain became a catalyst for stronger privacy rights. The European Court of Justice's 2014 ruling established individuals' right to request the removal of certain personal information from search engine results, fundamentally impacting how digital platforms handle personal data. The General Data Protection Regulation (GDPR), implemented in 2018, represents the most comprehensive privacy and security law in the world. Key innovations include: - Enhanced territorial scope affecting companies worldwide - Strict consent requirements for data processing - Significant fines up to 4% of global revenue - Data breach notification requirements - Rights to data portability and erasure - Requirement for Data Protection Officers in certain organizations The GDPR's impact has extended far beyond Europe, influencing privacy legislation worldwide and setting new global standards for data protection.\n",
            "\n",
            "\n",
            "Companies like Microsoft, Apple, and Google have had to significantly modify their data handling practices, often extending GDPR-level protections to users globally. Recent developments include: - The invalidation of the EU-US Privacy Shield in 2020 - Enhanced focus on artificial intelligence and automated decision-making - Growing emphasis on children's privacy protection - Increased scrutiny of digital advertising practices The European model continues to evolve, with discussions ongoing about the ePrivacy Regulation and artificial intelligence regulation, demonstrating the EU's commitment to maintaining comprehensive privacy protections in the digital age.\n",
            "\n",
            "\n",
            "Query: Compare and contrast how encryption technologies have evolved to meet different regional privacy requirements. Include specific examples from the EU, US, and Asia.\n",
            "Similar Sentences:\n",
            "Global Approaches to Data Protection: A Comparative Analysis Data protection approaches vary significantly across different regions of the world, reflecting diverse cultural, political, and economic priorities. This document examines how different regions approach privacy and data protection. European Union Approach: Comprehensive Protection: - GDPR as global standard - Privacy as fundamental right - Strict consent requirements - Significant penalties - Data Protection Authorities Key Features: - Data minimization principles - Purpose limitation - Storage limitations - Individual rights emphasis - Cross-border transfer restrictions United States Approach: Sectoral Regulation: - Industry-specific laws - State-level legislation - FTC enforcement - Market-driven solutions - Limited federal oversight Key Features: - Consumer protection focus - Industry self-regulation - State-level innovation - Breach notification requirements - Sectoral compliance frameworks Asia-Pacific Approaches: China: - Personal Information Protection Law (2021) - Cybersecurity Law (2017) - Data localization requirements - State security emphasis - Strict cross-border data rules Japan: - Act on Protection of Personal Information - GDPR adequacy decision - Balanced approach - Cultural privacy norms - International cooperation focus South Korea: - Personal Information Protection Act - Strict consent requirements - Criminal penalties - Comprehensive protection -\n",
            "\n",
            "\n",
            "The Evolution of Privacy-Enhancing Technologies Privacy-enhancing technologies (PETs) have evolved significantly since the early days of digital communication, reflecting growing concerns about data protection and privacy. This document traces the development of key privacy technologies and their impact on data protection. Early Encryption Technologies (1970s-1980s): Data Encryption Standard (DES): - Developed by IBM in 1974 - Standardized by NIST in 1977 - 56-bit key length - Used extensively in financial transactions - Eventually replaced due to security concerns Public Key Cryptography: - Diffie-Hellman key exchange (1976) - RSA algorithm (1977) - Enabled secure communication without pre-shared keys - Fundamental to modern secure communications 1990s Developments: Pretty Good Privacy (PGP): - Created by Phil Zimmermann in 1991 - Provided email encryption and digital signatures - Led to significant privacy debates - Influenced modern end-to-end encryption SSL/TLS Evolution: - SSL 2.0 released by Netscape (1995) - SSL 3.0 (1996) - TLS 1.0 (1999) - Enabled secure online commerce - Became foundation for HTTPS Early 2000s Innovations: Privacy-Preserving Data Mining: - Developed in response to growing data collection - Techniques for anonymizing datasets - Statistical disclosure control methods - K-anonymity concept introduced Tor Network: - Released in 2002 - Enabled anonymous internet browsing - Onion routing technology - Used by privacy advocates and journalists -\n",
            "\n",
            "\n",
            "Query: What role have tech companies played in shaping privacy standards globally, and how have different regions responded to their influence?\n",
            "Similar Sentences:\n",
            "2019 Facebook fine ($5 billion) for privacy violations State-Level Innovation: In the absence of comprehensive federal legislation, states have taken the lead: California's Leadership: - 2003 Security Breach Notification Law (first in the nation) - 2018 California Consumer Privacy Act (CCPA) - 2020 California Privacy Rights Act (CPRA) These laws have influenced other states and national privacy discussions. Recent Developments: - Growing number of state privacy laws (Virginia, Colorado, Utah) - Increased focus on biometric privacy protection - Emerging regulations for artificial intelligence - Ongoing debates about federal privacy legislation The U.S. approach continues to evolve, with calls for comprehensive federal privacy legislation growing stronger. However, the sectoral approach remains deeply embedded in the American legal framework, creating ongoing challenges for businesses operating across state lines and internationally.\n",
            "\n",
            "\n",
            "Global Approaches to Data Protection: A Comparative Analysis Data protection approaches vary significantly across different regions of the world, reflecting diverse cultural, political, and economic priorities. This document examines how different regions approach privacy and data protection. European Union Approach: Comprehensive Protection: - GDPR as global standard - Privacy as fundamental right - Strict consent requirements - Significant penalties - Data Protection Authorities Key Features: - Data minimization principles - Purpose limitation - Storage limitations - Individual rights emphasis - Cross-border transfer restrictions United States Approach: Sectoral Regulation: - Industry-specific laws - State-level legislation - FTC enforcement - Market-driven solutions - Limited federal oversight Key Features: - Consumer protection focus - Industry self-regulation - State-level innovation - Breach notification requirements - Sectoral compliance frameworks Asia-Pacific Approaches: China: - Personal Information Protection Law (2021) - Cybersecurity Law (2017) - Data localization requirements - State security emphasis - Strict cross-border data rules Japan: - Act on Protection of Personal Information - GDPR adequacy decision - Balanced approach - Cultural privacy norms - International cooperation focus South Korea: - Personal Information Protection Act - Strict consent requirements - Criminal penalties - Comprehensive protection -\n",
            "\n",
            "\n",
            "Technical security standards Emerging Market Approaches: Brazil (LGPD): - GDPR-influenced framework - National DPA establishment - Consent requirements\n",
            "\n",
            "\n",
            "Decentralized identity systems Implementation Challenges: Technical Limitations: - Performance overhead - Implementation complexity - Integration difficulties - Scalability challenges Adoption Barriers: - User experience impacts - Cost considerations - Technical expertise requirements - Regulatory compliance needs Future Directions: Emerging Areas: - Privacy-preserving biometrics - Decentralized privacy systems - Privacy-focused AI development - Quantum privacy technologies Standards Development: - International standardization - Industry best practices - Compliance frameworks - Interoperability standards The evolution of privacy-enhancing technologies continues to accelerate, driven by increasing privacy concerns and regulatory requirements.\n",
            "\n",
            "\n",
            "Introduced the principles of purpose limitation and data minimization The rise of social media and cloud computing in the 2000s exposed limitations in the 1995 directive. Facebook's launch in Europe in 2006 and Google's growing presence highlighted new challenges in personal data processing and cross-border data flows. The concept of \"privacy by design\" emerged during this period, championed by regulators as a proactive approach to privacy protection. The 2012 \"right to be forgotten\" case against Google in Spain became a catalyst for stronger privacy rights. The European Court of Justice's 2014 ruling established individuals' right to request the removal of certain personal information from search engine results, fundamentally impacting how digital platforms handle personal data. The General Data Protection Regulation (GDPR), implemented in 2018, represents the most comprehensive privacy and security law in the world. Key innovations include: - Enhanced territorial scope affecting companies worldwide - Strict consent requirements for data processing - Significant fines up to 4% of global revenue - Data breach notification requirements - Rights to data portability and erasure - Requirement for Data Protection Officers in certain organizations The GDPR's impact has extended far beyond Europe, influencing privacy legislation worldwide and setting new global standards for data protection.\n",
            "\n",
            "\n",
            "Companies like Microsoft, Apple, and Google have had to significantly modify their data handling practices, often extending GDPR-level protections to users globally. Recent developments include: - The invalidation of the EU-US Privacy Shield in 2020 - Enhanced focus on artificial intelligence and automated decision-making - Growing emphasis on children's privacy protection - Increased scrutiny of digital advertising practices The European model continues to evolve, with discussions ongoing about the ePrivacy Regulation and artificial intelligence regulation, demonstrating the EU's commitment to maintaining comprehensive privacy protections in the digital age.\n",
            "\n",
            "\n",
            "Query: How have approaches to data breach notification evolved since 2000, and what are the key differences between jurisdictions?\n",
            "Similar Sentences:\n",
            "Major Data Breaches and Their Impact on Privacy Regulation The history of data protection has been significantly shaped by major data breaches, each contributing to evolving privacy regulations and security practices. This document examines key breaches and their lasting impact on privacy protection. Early Notable Breaches (1984-2000): The TRW Credit Data breach in 1984 exposed 90 million credit records, leading to: - Enhanced security requirements for credit reporting agencies - Creation of consumer protection measures - Implementation of access controls The emergence of e-commerce in the 1990s brought new vulnerabilities: - CD Universe breach (1999) - 300,000 credit card numbers exposed - Egghead.com breach (2000) - 3.7 million customer records compromised These early incidents highlighted the need for: - Encryption of stored data - Secure transaction processing - Regular security audits Major Breaches of the 2000s: 2005 ChoicePoint Breach: - 163,000 consumer records compromised - $15 million in fines - Led to first state breach notification law in California - Sparked national discussion on data broker regulation 2007 TJX Companies Breach: - 45.7 million credit card numbers stolen - $256 million in costs - Resulted in: - PCI DSS compliance enhancement - Improved payment security standards - Increased focus on encryption Transformative Breaches (2010-2020): 2013 Target Breach: - 40 million credit card numbers exposed - 70 million customer records compromised -\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Main - Note that chunk size to use is set here in main and overrides default\n",
        "def main():\n",
        "    try:\n",
        "        # Directory containing Word documents\n",
        "        directory = \"content\"\n",
        "\n",
        "        # Get all .docx files in the directory\n",
        "        docx_files = list(Path(directory).glob(\"*.docx\"))\n",
        "\n",
        "        if not docx_files:\n",
        "            print(f\"No Word documents found in {directory}\")\n",
        "            return\n",
        "\n",
        "        print(f\"Found {len(docx_files)} Word documents\")\n",
        "\n",
        "        vectors_dict = {}\n",
        "        vectors = []\n",
        "        # Initialize the model\n",
        "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "          # Process each document\n",
        "        for doc_path in docx_files:\n",
        "          try:\n",
        "              print(f\"\\nProcessing: {doc_path.name}\")\n",
        "\n",
        "              # Extract chunks of approximately 100 characters\n",
        "              chunks = extract_fixed_chunks(str(doc_path), chunk_size=1500)\n",
        "\n",
        "              # get chunk embeddings and save to vector dictionary\n",
        "              print(f\"\\nGenerating embeddings for next {len(chunks)} chunks...\\n\")\n",
        "              for chunk in chunks:\n",
        "                  embeddings = model.encode(chunk)\n",
        "                  vectors_dict[tuple(embeddings)] = chunk\n",
        "                  vectors.append(embeddings)\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"Error processing {doc_path.name}: {str(e)}\")\n",
        "              continue\n",
        "\n",
        "        # run queries to find similarity in chunks\n",
        "        queries = ['When was the TRW Credit Data breach and how many credit records were exposed?','How have major data breaches influenced the development of privacy regulations in both the EU and US? Provide specific examples.','Compare and contrast how encryption technologies have evolved to meet different regional privacy requirements. Include specific examples from the EU, US, and Asia.','What role have tech companies played in shaping privacy standards globally, and how have different regions responded to their influence?', 'How have approaches to data breach notification evolved since 2000, and what are the key differences between jurisdictions?']\n",
        "        print(\"\\nExtracting relevant chunks to queries...\\n\")\n",
        "        for query in queries:\n",
        "          query_embedding = model.encode(query)\n",
        "          similar_sentences = find_similar_sentences(query_embedding, vectors)\n",
        "\n",
        "          print(f\"Query: {query}\")\n",
        "          print(\"Similar Sentences:\")\n",
        "          for sentence in similar_sentences:\n",
        "            chunk = vectors_dict[tuple(sentence)]\n",
        "            print(chunk)\n",
        "            print('\\n')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error accessing directory: {str(e)}\")\n",
        "\n",
        "# Call main and start the creating embeddings\n",
        "main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHBRrpl15FzG"
      },
      "source": [
        "/content/sample_data/mydata"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}