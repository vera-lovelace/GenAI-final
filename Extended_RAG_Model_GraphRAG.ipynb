{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vera-lovelace/GenAI-final/blob/graphRAG/Extended_RAG_Model_GraphRAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YzICc7GNDQS"
      },
      "source": [
        "# RAG Mini Project\n",
        "## Milestone #2 : Vectorise and store Chunks\n",
        "\n",
        "Use the embedding code from Assignment A1 to create embeddings from the  text chunks generated and save in Pickle file from Milestone #1.\n",
        "\n",
        "Create a Python dictionary as a Vector database using the embedding vector as keys (note: convert list of embeddings to a tuple) and the text as the value\n",
        "Experiment with some queries and use cosine similarity to get the most similar text from your vector database.\n",
        "If the results are not satisfactory, you may want to refactor your code by:\n",
        "changing the embedding technique\n",
        "modifying the chunking technique from Milestone #1. Your code should be modular enough to make this fairly straightforward if needed. It is what software development is all about.\n",
        "When satisfied, store your Python dict (vector db) in a pickle file.\n",
        "\n",
        "\n",
        "### Deliverables: Zip file with\n",
        "\n",
        "Jupyter Notebook\n",
        "Summary of your efforts (issues, success in matching chunks to queries based on embeddings, …)\n",
        "Pickle file with the Python vector database for use in the final Mini Project Deliverable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NqMv3iTNUGM",
        "outputId": "930d88c0-4d91-40cb-feac-109d7a4bfc54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: docx in /usr/local/lib/python3.11/dist-packages (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from docx) (5.3.1)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.11/dist-packages (from docx) (11.1.0)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.11/dist-packages (7.1.4)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib) (3.2.1)\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "\n",
        "!pip install python-docx\n",
        "!pip install docx\n",
        "!pip install rdflib\n",
        "\n",
        "from docx import Document\n",
        "from io import BytesIO\n",
        "import re\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab import files\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "import spacy\n",
        "from rdflib import Graph, Literal\n",
        "\n",
        "from torch.nn.functional import cosine_similarity\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ftyx_HIB2Jf3"
      },
      "outputs": [],
      "source": [
        "# Extract Chunks using document paragraphs\n",
        "# Chunk size is controlled by parameter\n",
        "def extract_fixed_chunks(file_path, chunk_size=1000):\n",
        "    \"\"\"\n",
        "    Extract fixed-size chunks from a Word document.\n",
        "\n",
        "    Args:\n",
        "        file_path (str or bytes): Path to Word document or binary content\n",
        "        chunk_size (int): Target size of each chunk in characters\n",
        "\n",
        "    Returns:\n",
        "        list: List of text chunks of approximately chunk_size characters\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Handle both file path and binary content\n",
        "        if isinstance(file_path, bytes):\n",
        "            doc = Document(BytesIO(file_path))\n",
        "        else:\n",
        "            doc = Document(file_path)\n",
        "\n",
        "        # Extract and clean all text\n",
        "        full_text = \"\"\n",
        "        for para in doc.paragraphs:\n",
        "            text = para.text.strip()\n",
        "            if text:  # Skip empty paragraphs\n",
        "                # Clean and normalise the text\n",
        "                text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
        "                text = re.sub(r'\\s+', ' ', text)  # Remove multiple spaces\n",
        "                full_text += text + \" \"  # Add space between paragraphs\n",
        "\n",
        "        # Split text into sentences\n",
        "        sentences = re.split('(?<=[.!?-]) +', full_text)\n",
        "\n",
        "        chunks = []\n",
        "        current_chunk = \"\"\n",
        "\n",
        "        for sentence in sentences:\n",
        "            # If adding this sentence would exceed chunk_size\n",
        "            if len(current_chunk) + len(sentence) > chunk_size:\n",
        "                # If current chunk is not empty, add it to chunks\n",
        "                if current_chunk:\n",
        "                    chunks.append(current_chunk.strip())\n",
        "                    current_chunk = \"\"\n",
        "\n",
        "                # Handle sentences longer than chunk_size\n",
        "                if len(sentence) > chunk_size:\n",
        "                    # Split long sentence into fixed-size chunks\n",
        "                    words = sentence.split()\n",
        "                    temp_chunk = \"\"\n",
        "\n",
        "                    for word in words:\n",
        "                        if len(temp_chunk) + len(word) + 1 <= chunk_size:\n",
        "                            temp_chunk += (\" \" + word if temp_chunk else word)\n",
        "                        else:\n",
        "                            chunks.append(temp_chunk.strip())\n",
        "                            temp_chunk = word\n",
        "\n",
        "                    if temp_chunk:\n",
        "                        current_chunk = temp_chunk\n",
        "                else:\n",
        "                    current_chunk = sentence\n",
        "            else:\n",
        "                # Add sentence to current chunk\n",
        "                current_chunk += (\" \" + sentence if current_chunk else sentence)\n",
        "\n",
        "        # Add the last chunk if not empty\n",
        "        if current_chunk:\n",
        "            chunks.append(current_chunk.strip())\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error processing document: {str(e)}\")\n",
        "\n",
        "# Find cosine similarity of sentences\n",
        "def find_similar_sentences(query, embeddings):\n",
        "    \"\"\"\n",
        "    Finds similar texts to query based on similarity threshold.\n",
        "\n",
        "    Args:\n",
        "        query: embeddings of query\n",
        "        embeddings: List of text embeddings\n",
        "\n",
        "    Returns:\n",
        "        List of similar sentence embeddings\n",
        "    \"\"\"\n",
        "    similar_sentences = []\n",
        "    for i in range(len(embeddings)):\n",
        "        similarity = np.dot(query, embeddings[i]) / (\n",
        "            np.linalg.norm(query) * np.linalg.norm(embeddings[i]))\n",
        "        if similarity > 0.55:\n",
        "            similar_sentences.append(embeddings[i])\n",
        "    return similar_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fZdcpvLSHCy",
        "outputId": "a5890bac-21ef-48f1-a193-8a8e5701428d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found files: [PosixPath('content/docs/CCPA.docx'), PosixPath('content/docs/EU GDPR.docx'), PosixPath('content/docs/HIPAA.docx'), PosixPath('content/docs/3.Major Data Breaches and Their Impact on Privacy Regulation.docx'), PosixPath('content/docs/1.The Evolution of Privacy.docx'), PosixPath('content/docs/2.DevelopmentPrivacyProtectionUSA.docx'), PosixPath('content/docs/CPRA.docx'), PosixPath('content/docs/4.The Evolution of European Data Protection.docx'), PosixPath('content/docs/5.Global Approaches to Data Protection.docx')]\n",
            "Found 9 Word documents\n",
            "\n",
            "Processing: CCPA.docx\n",
            "\n",
            "Generating embeddings for next 126 chunks...\n",
            "\n",
            "\n",
            "Processing: EU GDPR.docx\n",
            "\n",
            "Generating embeddings for next 276 chunks...\n",
            "\n",
            "\n",
            "Processing: HIPAA.docx\n",
            "\n",
            "Generating embeddings for next 58 chunks...\n",
            "\n",
            "\n",
            "Processing: 3.Major Data Breaches and Their Impact on Privacy Regulation.docx\n",
            "\n",
            "Generating embeddings for next 3 chunks...\n",
            "\n",
            "\n",
            "Processing: 1.The Evolution of Privacy.docx\n",
            "\n",
            "Generating embeddings for next 3 chunks...\n",
            "\n",
            "\n",
            "Processing: 2.DevelopmentPrivacyProtectionUSA.docx\n",
            "\n",
            "Generating embeddings for next 3 chunks...\n",
            "\n",
            "\n",
            "Processing: CPRA.docx\n",
            "\n",
            "Generating embeddings for next 138 chunks...\n",
            "\n",
            "\n",
            "Processing: 4.The Evolution of European Data Protection.docx\n",
            "\n",
            "Generating embeddings for next 3 chunks...\n",
            "\n",
            "\n",
            "Processing: 5.Global Approaches to Data Protection.docx\n",
            "\n",
            "Generating embeddings for next 2 chunks...\n",
            "\n",
            "\n",
            "=== Querying RAG ===\n",
            "\n",
            "\n",
            "Extracting relevant chunks to queries...\n",
            "\n",
            "Query: When was the Tor network released?\n",
            "Similar Sentences:\n",
            "Query: List where the GDPR approach was applied.\n",
            "Similar Sentences:\n",
            "Query: How major data breaches impacted Apple and Microsoft?\n",
            "Similar Sentences:\n",
            "Major Data Breaches and Their Impact on Privacy Regulation The history of data protection has been significantly shaped by major data breaches, each contributing to evolving privacy regulations and security practices. This document examines key breaches and their lasting impact on privacy protection. Early Notable Breaches (1984-2000): The TRW Credit Data breach in 1984 exposed 90 million credit records, leading to: - Enhanced security requirements for credit reporting agencies - Creation of consumer protection measures - Implementation of access controls The emergence of e-commerce in the 1990s brought new vulnerabilities: - CD Universe breach (1999) - 300,000 credit card numbers exposed - Egghead.com breach (2000) - 3.7 million customer records compromised These early incidents highlighted the need for: - Encryption of stored data - Secure transaction processing - Regular security audits Major Breaches of the 2000s: 2005 ChoicePoint Breach: - 163,000 consumer records compromised - $15 million in fines - Led to first state breach notification law in California - Sparked national discussion on data broker regulation 2007 TJX Companies Breach: - 45.7 million credit card numbers stolen - $256 million in costs - Resulted in: - PCI DSS compliance enhancement - Improved payment security standards - Increased focus on encryption Transformative Breaches (2010-2020): 2013 Target Breach: - 40 million credit card numbers exposed - 70 million customer records compromised -\n",
            "\n",
            "\n",
            "Query: How privacy regulations affect various industries in the USA?\n",
            "Similar Sentences:\n",
            "(14) Issuing regulations requiring businesses whose processing of consumers’ personal information presents significant risk to consumers’ privacy or security, to: (A) Perform a cybersecurity audit on an annual basis, including defining the scope of the audit and establishing a process to ensure that audits are thorough and independent. The factors to be considered in determining when processing may result in significant risk to the security of personal information shall include the size and complexity of the business and the nature and scope of processing activities. (B) Submit to the California Privacy Protection Agency on a regular basis a risk assessment with respect to their processing of personal information, including whether the processing involves sensitive personal information, and identifying and weighing the benefits resulting from the processing to the business, the consumer, other stakeholders, and the public, against the potential risks to the rights of the consumer associated with that processing, with the goal of restricting or prohibiting the processing if the risks to privacy of the consumer outweigh the benefits resulting from processing to the consumer, the business, other stakeholders, and the public. Nothing in this section shall require a business to divulge trade secrets.\n",
            "\n",
            "\n",
            "(g) Provide technical assistance and advice to the Legislature, upon request, with respect to privacy-related legislation. (h) Monitor relevant developments relating to the protection of personal information and, in particular, the development of information and communication technologies and commercial practices. (i) Cooperate with other agencies with jurisdiction over privacy laws and with data processing authorities in California, other states, territories, and countries to ensure consistent application of privacy protections. (j) Establish a mechanism pursuant to which persons doing business in California that do not meet the definition of business set forth in paragraph (1), (2), or (3) of subdivision (d) of Section 1798.140 may voluntarily certify that they are in compliance with this title, as set forth in paragraph (4) of subdivision (d) of Section 1798.140, and make a list of those entities available to the public. (k) Solicit, review, and approve applications for grants to the extent funds are available pursuant to paragraph (2) of subdivision (b) of Section 1798.160. (l) Perform all other acts necessary or appropriate in the exercise of its power, authority, and jurisdiction and seek to balance the goals of strengthening consumer privacy while giving attention to the impact on businesses. (Amended by Stats. 2024, Ch. 121, Sec. 11. (AB 3286) Effective January 1, 2025.) 1798.199.45.\n",
            "\n",
            "\n",
            "The Development of Privacy Protection in the United States: A Sectoral Approach The United States has historically taken a markedly different approach to privacy protection compared to Europe, developing a patchwork of sector-specific laws rather than comprehensive federal legislation. This sectoral approach reflects American values of free market economics and limited government intervention. Early Privacy Developments (1960s-1970s): The Fair Credit Reporting Act of 1970 was one of the first federal laws addressing privacy concerns, focusing specifically on the collection and use of consumer credit information. This law established important principles including: - Consumer right to access their credit reports - Requirement for accurate reporting - Time limits on negative information - Procedures for disputing incorrect information The Privacy Act of 1974 represented another significant step, though limited to government agencies. It established: - Rules for government collection and use of personal data - Individual rights to access and correct records - Restrictions on sharing between agencies - Civil and criminal penalties for violations The Evolution of Sectoral Privacy Laws: Different industries received specific privacy regulations over time: Healthcare: The Health Insurance Portability and Accountability Act (HIPAA) of 1996 created comprehensive privacy rules for medical information, including: - Patient rights to access medical records -\n",
            "\n",
            "\n",
            "Restrictions on information sharing - Security requirements for health data - Breach notification requirements - Substantial penalties for violations Financial Services: The Gramm-Leach-Bliley Act of 1999 established privacy rules for financial institutions: - Required privacy notices to customers - Opt-out rights for information sharing - Security standards for financial data - State enforcement mechanisms Children's Privacy: The Children's Online Privacy Protection Act (COPPA) of 1998 specifically addressed children's privacy online: - Parental consent requirements - Restrictions on data collection from children under 13 - Requirements for privacy policies - Limits on marketing to children Education: The Family Educational Rights and Privacy Act (FERPA) protects student education records: - Parent/student rights to access records - Limitations on disclosure without consent - Requirements for schools' privacy practices The Digital Age and New Challenges: The rise of internet companies in the 1990s and 2000s exposed gaps in U.S. privacy protection. The Federal Trade Commission (FTC) became the de facto privacy regulator, using its authority to: - Enforce company privacy promises - Investigate data breaches - Issue privacy guidelines - Impose fines for privacy violations Notable FTC actions included: - 2011 Facebook settlement requiring privacy audits - 2012 Google privacy violation fine ($22.5 million) -\n",
            "\n",
            "\n",
            "2019 Facebook fine ($5 billion) for privacy violations State-Level Innovation: In the absence of comprehensive federal legislation, states have taken the lead: California's Leadership: - 2003 Security Breach Notification Law (first in the nation) - 2018 California Consumer Privacy Act (CCPA) - 2020 California Privacy Rights Act (CPRA) These laws have influenced other states and national privacy discussions. Recent Developments: - Growing number of state privacy laws (Virginia, Colorado, Utah) - Increased focus on biometric privacy protection - Emerging regulations for artificial intelligence - Ongoing debates about federal privacy legislation The U.S. approach continues to evolve, with calls for comprehensive federal privacy legislation growing stronger. However, the sectoral approach remains deeply embedded in the American legal framework, creating ongoing challenges for businesses operating across state lines and internationally.\n",
            "\n",
            "\n",
            "In addition, the terms of agreement or policies in which the arrangements are spelled out, are often complex and unclear, and as a result, most consumers never have the time to read or understand them. (F) This asymmetry of information makes it difficult for consumers to understand what they are exchanging and therefore to negotiate effectively with businesses. Unlike in other areas of the economy where consumers can comparison shop, or can understand at a glance if a good or service is expensive or affordable, it is hard for the consumer to know how much the consumers information is worth to any given business, when data use practices vary so widely between businesses. (G) The State therefore has an interest in mandating laws that will allow consumers to understand more fully how their information is being used, and for what purposes. In the same way that ingredient labels on foods help consumers shop more effectively, disclosure around data management practices will help consumers become more informed counterparties in the data economy, and promote competition. Additionally, if a consumer can tell a business not to sell the consumer‘s data, then that consumer will not have to scour a privacy policy to see whether the business is, in fact, selling that data, and the resulting savings in time is worth, in the aggregate, a tremendous amount of money.\n",
            "\n",
            "\n",
            "(4) The law should adjust to technological changes, help consumers exercise their rights, and assist businesses with compliance, with the continuing goal of strengthening consumer privacy. (5) The law should enable pro‐consumer new products and services and promote efficiency of implementation for business, provided that the amendments do not compromise or weaken consumer privacy. (6) The law should be amended, if necessary, to improve its operation, provided that the amendments do not compromise or weaken consumer privacy, while giving attention to the impact on business and innovation. (7) Businesses should be held accountable for violating the law through vigorous administrative and civil enforcement. (8) To the extent it advances consumer privacy and business compliance, the law should be compatible with privacy laws in other jurisdictions. SEC. 4. Section 1798.100 of the Civil Code is amended to read: 1798.100. General Duties of Businesses that Collect Personal Information 1798.100. (a) A consumer shall have the right to request that a business that collects a consumer’s personal information disclose to that consumer the categories and specific pieces of personal information the business has collected.\n",
            "\n",
            "\n",
            "(15) Issuing regulations requiring businesses whose processing of consumers’ personal information presents significant risk to consumers’ privacy or security, to: (A) Perform a cybersecurity audit on an annual basis, including defining the scope of the audit and establishing a process to ensure that audits are thorough and independent. The factors to be considered in determining when processing may result in significant risk to the security of personal information shall include the size and complexity of the business and the nature and scope of processing activities. (B) Submit to the California Privacy Protection Agency on a regular basis a risk assessment with respect to their processing of personal information, including whether the processing involves sensitive personal information, and identifying and weighing the benefits resulting from the processing to the business, the consumer, other stakeholders, and the public, against the potential risks to the rights of the consumer associated with that processing, with the goal of restricting or prohibiting the processing if the risks to privacy of the consumer outweigh the benefits resulting from processing to the consumer, the business, other stakeholders, and the public. Nothing in this section shall require a business to divulge trade secrets.\n",
            "\n",
            "\n",
            "(g) Provide technical assistance and advice to the Legislature, upon request, with respect to privacy-related legislation. (h) Monitor relevant developments relating to the protection of personal information and in particular, the development of information and communication technologies and commercial practices. (i) Cooperate with other agencies with jurisdiction over privacy laws and with data processing authorities in California, other states, territories, and countries to ensure consistent application of privacy protections. (j) Establish a mechanism pursuant to which persons doing business in California that do not meet the definition of business set forth in paragraph (1), (2), or (3) of subdivision (d) of Section 1798.140 may voluntarily certify that they are in compliance with this title, as set forth in paragraph (4) of subdivision (d) of Section 1798.140, and make a list of those entities available to the public. (k) Solicit, review, and approve applications for grants to the extent funds are available pursuant to paragraph (2) of subdivision (b) of Section 1798.160. (l) Perform all other acts necessary or appropriate in the exercise of its power, authority, and jurisdiction and seek to balance the goals of strengthening consumer privacy while giving attention to the impact on businesses. SEC. 24.8. Section 1798.199.45 is added to the Civil Code, to read: 1798.199.45.\n",
            "\n",
            "\n",
            "Query: When was the TRW Credit Data breach and how many credit records were exposed?\n",
            "Similar Sentences:\n",
            "Major Data Breaches and Their Impact on Privacy Regulation The history of data protection has been significantly shaped by major data breaches, each contributing to evolving privacy regulations and security practices. This document examines key breaches and their lasting impact on privacy protection. Early Notable Breaches (1984-2000): The TRW Credit Data breach in 1984 exposed 90 million credit records, leading to: - Enhanced security requirements for credit reporting agencies - Creation of consumer protection measures - Implementation of access controls The emergence of e-commerce in the 1990s brought new vulnerabilities: - CD Universe breach (1999) - 300,000 credit card numbers exposed - Egghead.com breach (2000) - 3.7 million customer records compromised These early incidents highlighted the need for: - Encryption of stored data - Secure transaction processing - Regular security audits Major Breaches of the 2000s: 2005 ChoicePoint Breach: - 163,000 consumer records compromised - $15 million in fines - Led to first state breach notification law in California - Sparked national discussion on data broker regulation 2007 TJX Companies Breach: - 45.7 million credit card numbers stolen - $256 million in costs - Resulted in: - PCI DSS compliance enhancement - Improved payment security standards - Increased focus on encryption Transformative Breaches (2010-2020): 2013 Target Breach: - 40 million credit card numbers exposed - 70 million customer records compromised -\n",
            "\n",
            "\n",
            "Query: How have approaches to data breach notification evolved since 2000, and what are the key differences between jurisdictions?\n",
            "Similar Sentences:\n",
            "For example, the need to mitigate an immediate risk of damage would call for prompt communication with data subjects whereas the need to implement appropriate measures against continuing or similar personal data breaches may justify more time for communication. (87) It should be ascertained whether all appropriate technological protection and organisational measures have been implemented to establish immediately whether a personal data breach has taken place and to inform promptly the supervisory authority and the data subject. The fact that the notification was made without undue delay should be established taking into account in particular the nature and gravity of the personal data breach and its consequences and adverse effects for the data subject. Such notification may result in an intervention of the supervisory authority in accordance with its tasks and powers laid down in this Regulation. (88) In setting detailed rules concerning the format and procedures applicable to the notification of personal data breaches, due consideration should be given to the circumstances of that breach, including whether or not personal data had been protected by appropriate technical protection measures, effectively limiting the likelihood of identity fraud or other forms of misuse.\n",
            "\n",
            "\n",
            "3.The notification referred to in paragraph 1 shall at least: (a) describe the nature of the personal data breach including where possible, the categories and approximate number of data subjects concerned and the categories and approximate number of personal data records concerned; (b) communicate the name and contact details of the data protection officer or other contact point where more information can be obtained; (c) describe the likely consequences of the personal data breach; (d) describe the measures taken or proposed to be taken by the controller to address the personal data breach, including, where appropriate, measures to mitigate its possible adverse effects. 4.Where, and in so far as, it is not possible to provide the information at the same time, the information may be provided in phases without undue further delay. 5.The controller shall document any personal data breaches, comprising the facts relating to the personal data breach, its effects and the remedial action taken. That documentation shall enable the supervisory authority to verify compliance with this Article. Article 34 Communication of a personal data breach to the data subject 1.When the personal data breach is likely to result in a high risk to the rights and freedoms of natural persons, the controller shall communicate the personal data breach to the data subject without undue delay.\n",
            "\n",
            "\n",
            "Major Data Breaches and Their Impact on Privacy Regulation The history of data protection has been significantly shaped by major data breaches, each contributing to evolving privacy regulations and security practices. This document examines key breaches and their lasting impact on privacy protection. Early Notable Breaches (1984-2000): The TRW Credit Data breach in 1984 exposed 90 million credit records, leading to: - Enhanced security requirements for credit reporting agencies - Creation of consumer protection measures - Implementation of access controls The emergence of e-commerce in the 1990s brought new vulnerabilities: - CD Universe breach (1999) - 300,000 credit card numbers exposed - Egghead.com breach (2000) - 3.7 million customer records compromised These early incidents highlighted the need for: - Encryption of stored data - Secure transaction processing - Regular security audits Major Breaches of the 2000s: 2005 ChoicePoint Breach: - 163,000 consumer records compromised - $15 million in fines - Led to first state breach notification law in California - Sparked national discussion on data broker regulation 2007 TJX Companies Breach: - 45.7 million credit card numbers stolen - $256 million in costs - Resulted in: - PCI DSS compliance enhancement - Improved payment security standards - Increased focus on encryption Transformative Breaches (2010-2020): 2013 Target Breach: - 40 million credit card numbers exposed - 70 million customer records compromised -\n",
            "\n",
            "\n",
            "Query: What kind of data is protected by privacy acts?\n",
            "Similar Sentences:\n",
            "Civil Code - CIV DIVISION 3. OBLIGATIONS [1427 - 3273.69] ( Heading of Division 3 amended by Stats. 1988, Ch. 160, Sec. 14. ) PART 4. OBLIGATIONS ARISING FROM PARTICULAR TRANSACTIONS [1738 - 3273.69] ( Part 4 enacted 1872. ) TITLE 1.81.5. California Consumer Privacy Act of 2018 [1798.100 - 1798.199.100] ( Title 1.81.5 added by Stats. 2018, Ch. 55, Sec. 3. ) 1798.100. General Duties of Businesses that Collect Personal Information (a) A business that controls the collection of a consumer’s personal information shall, at or before the point of collection, inform consumers of the following: (1) The categories of personal information to be collected and the purposes for which the categories of personal information are collected or used and whether that information is sold or shared. A business shall not collect additional categories of personal information or use personal information collected for additional purposes that are incompatible with the disclosed purpose for which the personal information was collected without providing the consumer with notice consistent with this section. (2) If the business collects sensitive personal information, the categories of sensitive personal information to be collected and the purposes for which the categories of sensitive personal information are collected or used, and whether that information is sold or shared.\n",
            "\n",
            "\n",
            "(C) Identify by category or categories the personal information of the consumer that the business disclosed for a business purpose during the applicable period of time by reference to the enumerated category or categories in subdivision (c) that most closely describes the personal information, and provide the categories of persons to whom the consumer’s personal information was disclosed for a business purpose during the applicable period of time by reference to the enumerated category or categories in subdivision (c) that most closely describes the personal information disclosed. The business shall disclose the information in a list that is separate from a list generated for the purposes of subparagraph (B). (5) Disclose the following information in its online privacy policy or policies if the business has an online privacy policy or policies and in any California-specific description of consumers’ privacy rights, or if the business does not maintain those policies, on its internet website, and update that information at least once every 12 months: (A) A description of a consumer’s rights pursuant to Sections 1798.100, 1798.105, 1798.106, 1798.110, 1798.115, and 1798.125 and two or more designated methods for submitting requests, except as provided in subparagraph (A) of paragraph (1) of subdivision (a).\n",
            "\n",
            "\n",
            "Personal information includes, but is not limited to, the following if it identifies, relates to, describes, is reasonably capable of being associated with, or could be reasonably linked, directly or indirectly, with a particular consumer or household: (A) Identifiers such as a real name, alias, postal address, unique personal identifier, online identifier, Internet Protocol address, email address, account name, social security number, driver’s license number, passport number, or other similar identifiers. (B) Any personal information described in subdivision (e) of Section 1798.80. (C) Characteristics of protected classifications under California or federal law. (D) Commercial information, including records of personal property, products or services purchased, obtained, or considered, or other purchasing or consuming histories or tendencies. (E) Biometric information. (F) Internet or other electronic network activity information, including, but not limited to, browsing history, search history, and information regarding a consumer’s interaction with an internet website application, or advertisement. (G) Geolocation data. (H) Audio, electronic, visual, thermal, olfactory, or similar information. (I) Professional or employment-related information. (J) Education information, defined as information that is not publicly available personally identifiable information as defined in the Family Educational Rights and Privacy Act (20 U.S.C. Sec. 1232g; 34 C.F.R. Part 99).\n",
            "\n",
            "\n",
            "(K) Inferences drawn from any of the information identified in this subdivision to create a profile about a consumer reflecting the consumer’s preferences, characteristics, psychological trends, predispositions, behavior, attitudes, intelligence, abilities, and aptitudes. (L) Sensitive personal information. (2) (A) “Personal information” does not include publicly available information or lawfully obtained, truthful information that is a matter of public concern. (B) (i) For purposes of this paragraph, “publicly available” means any of the following: (I) Information that is lawfully made available from federal, state, or local government records. (II) Information that a business has a reasonable basis to believe is lawfully made available to the general public by the consumer or from widely distributed media. (III) Information made available by a person to whom the consumer has disclosed the information if the consumer has not restricted the information to a specific audience. (ii) “Publicly available” does not mean biometric information collected by a business about a consumer without the consumer’s knowledge. (3) “Personal information” does not include consumer information that is deidentified or aggregate consumer information. (4) “Personal information” can exist in various formats, including, but not limited to, all of the following: (A) Physical formats, including paper documents, printed images, vinyl records, or video tapes.\n",
            "\n",
            "\n",
            "If a third party materially alters how it uses or shares the personal information of a consumer in a manner that is materially inconsistent with the promises made at the time of collection, it shall provide prior notice of the new or changed practice to the consumer. The notice shall be sufficiently prominent and robust to ensure that existing consumers can easily exercise their choices consistently with this title. This subparagraph does not authorize a business to make material, retroactive privacy policy changes or make other changes in their privacy policy in a manner that would violate the Unfair and Deceptive Practices Act (Chapter 5 (commencing with Section 17200) of Part 2 of Division 7 of the Business and Professions Code). (ae) “Sensitive personal information” means: (1) Personal information that reveals: (A) A consumer’s social security, driver’s license, state identification card, or passport number. (B) A consumer’s account log-in, financial account, debit card, or credit card number in combination with any required security or access code, password, or credentials allowing access to an account. (C) A consumer’s precise geolocation. (D) A consumer’s racial or ethnic origin, citizenship or immigration status, religious or philosophical beliefs, or union membership. (E) The contents of a consumer’s mail, email, and text messages unless the business is the intended recipient of the communication. (F) A consumer’s genetic data. (G) (i) A consumer’s neural data.\n",
            "\n",
            "\n",
            "(B) A provider of health care governed by the Confidentiality of Medical Information Act (Part 2.6 (commencing with Section 56) of Division 1) or a covered entity governed by the privacy, security, and breach notification rules issued by the United States Department of Health and Human Services, Parts 160 and 164 of Title 45 of the Code of Federal Regulations, established pursuant to the Health Insurance Portability and Accountability Act of 1996 (Public Law 104-191), to the extent the provider or covered entity maintains patient information in the same manner as medical information or protected health information as described in subparagraph (A) of this section. (C) Personal information collected as part of a clinical trial or other biomedical research study subject to, or conducted in accordance with, the Federal Policy for the Protection of Human Subjects, also known as the Common Rule, pursuant to good clinical practice guidelines issued by the International Council for Harmonisation or pursuant to human subject protection requirements of the United States Food and Drug Administration, provided that the information is not sold or shared in a manner not permitted by this subparagraph, and, if it is inconsistent, that participants be informed of that use and provide consent.\n",
            "\n",
            "\n",
            "(3) A business associate of a covered entity governed by the privacy, security, and data breach notification rules issued by the United States Department of Health and Human Services, Parts 160 and 164 of Title 45 of the Code of Federal Regulations, established pursuant to the federal Health Insurance Portability and Accountability Act of 1996 (Public Law 104-191) and the federal Health Information Technology for Economic and Clinical Health Act, Title XIII of the federal American Recovery and Reinvestment Act of 2009 (Public Law 111-5), to the extent that the business associate maintains, uses, and discloses patient information in the same manner as medical information or protected health information as described in paragraph (1). (4) (A) Information that meets both of the following conditions: (i) It is deidentified in accordance with the requirements for deidentification set forth in Section 164.514 of Part 164 of Title 45 of the Code of Federal Regulations. (ii) It is derived from patient information that was originally collected, created, transmitted, or maintained by an entity regulated by the Health Insurance Portability and Accountability Act, the Confidentiality Of Medical Information Act, or the Federal Policy for the Protection of Human Subjects, also known as the Common Rule.\n",
            "\n",
            "\n",
            "Wherever possible, law relating to consumers’ personal information should be construed to harmonize with the provisions of this title, but in the event of a conflict between other laws and the provisions of this title, the provisions of the law that afford the greatest protection for the right of privacy for consumers shall control. (Amended November 3, 2020, by initiative Proposition 24, Sec. 19. Effective December 16, 2020. Operative January 1, 2023, pursuant to Sec. 31 of Proposition 24.) 1798.180. Preemption This title is a matter of statewide concern and supersedes and preempts all rules, regulations, codes, ordinances, and other laws adopted by a city, county, city and county, municipality, or local agency regarding the collection and sale of consumers’ personal information by a business. (Amended November 3, 2020, by initiative Proposition 24, Sec. 20. Effective December 16, 2020. Operative January 1, 2023, pursuant to Sec. 31 of Proposition 24.) 1798.185.\n",
            "\n",
            "\n",
            "(14) Issuing regulations requiring businesses whose processing of consumers’ personal information presents significant risk to consumers’ privacy or security, to: (A) Perform a cybersecurity audit on an annual basis, including defining the scope of the audit and establishing a process to ensure that audits are thorough and independent. The factors to be considered in determining when processing may result in significant risk to the security of personal information shall include the size and complexity of the business and the nature and scope of processing activities. (B) Submit to the California Privacy Protection Agency on a regular basis a risk assessment with respect to their processing of personal information, including whether the processing involves sensitive personal information, and identifying and weighing the benefits resulting from the processing to the business, the consumer, other stakeholders, and the public, against the potential risks to the rights of the consumer associated with that processing, with the goal of restricting or prohibiting the processing if the risks to privacy of the consumer outweigh the benefits resulting from processing to the consumer, the business, other stakeholders, and the public. Nothing in this section shall require a business to divulge trade secrets.\n",
            "\n",
            "\n",
            "(b) On and after the later of July 1, 2021, or within six months of the agency providing the Attorney General with notice that it is prepared to assume rulemaking responsibilities under this title, adopt, amend, and rescind regulations pursuant to Section 1798.185 to carry out the purposes and provisions of the California Consumer Privacy Act of 2018, including regulations specifying recordkeeping requirements for businesses to ensure compliance with this title. (c) Through the implementation of this title, protect the fundamental privacy rights of natural persons with respect to the use of their personal information. (d) Promote public awareness and understanding of the risks, rules, responsibilities, safeguards, and rights in relation to the collection, use, sale, and disclosure of personal information, including the rights of minors with respect to their own information, and provide a public report summarizing the risk assessments filed with the agency pursuant to paragraph (14) of subdivision (a) of Section 1798.185 while ensuring that data security is not compromised. (e) Provide guidance to consumers regarding their rights under this title. (f) Provide guidance to businesses regarding their duties and responsibilities under this title and appoint a Chief Privacy Auditor to conduct audits of businesses to ensure compliance with this title pursuant to regulations adopted pursuant to paragraph (17) of subdivision (a) of Section 1798.185.\n",
            "\n",
            "\n",
            "(4) The processing of personal data should be designed to serve mankind. The right to the protection of personal data is not an absolute right; it must be considered in relation to its function in society and be balanced against other fundamental rights, in accordance with the principle of proportionality. This Regulation respects all fundamental rights and observes the freedoms and principles recognised in the Charter as enshrined in the Treaties, in particular the respect for private and family life, home and communications, the protection of personal data, freedom of thought, conscience and religion, freedom of expression and information, freedom to conduct a business, the right to an effective remedy and to a fair trial, and cultural, religious and linguistic diversity. (5) The economic and social integration resulting from the functioning of the internal market has led to a substantial increase in cross-border flows of personal data. The exchange of personal data between public and private actors, including natural persons, associations and undertakings across the Union has increased. National authorities in the Member States are being called upon by Union law to cooperate and exchange personal data so as to be able to perform their duties or carry out tasks on behalf of an authority in another Member State. (6) Rapid technological developments and globalisation have brought new challenges for the protection of personal data.\n",
            "\n",
            "\n",
            "The scale of the collection and sharing of personal data has increased significantly. Technology allows both private companies and public authorities to make use of personal data on an unprecedented scale in order to pursue their activities. Natural persons increasingly make personal information available publicly and globally. Technology has transformed both the economy and social life, and should further facilitate the free flow of personal data within the Union and the transfer to third countries and international organisations, while ensuring a high level of the protection of personal data. (7) Those developments require a strong and more coherent data protection framework in the Union, backed by strong enforcement, given the importance of creating the trust that will allow the digital economy to develop across the internal market. Natural persons should have control of their own personal data. Legal and practical certainty for natural persons, economic operators and public authorities should be enhanced. (8) Where this Regulation provides for specifications or restrictions of its rules by Member State law, Member States may, as far as necessary for coherence and for making the national provisions comprehensible to the persons to whom they apply, incorporate elements of this Regulation into their national law.\n",
            "\n",
            "\n",
            "(9) The objectives and principles of Directive 95/46/EC remain sound, but it has not prevented fragmentation in the implementation of data protection across the Union, legal uncertainty or a widespread public perception that there are significant risks to the protection of natural persons, in particular with regard to online activity. Differences in the level of protection of the rights and freedoms of natural persons, in particular the right to the protection of personal data, with regard to the processing of personal data in the Member States may prevent the free flow of personal data throughout the Union. Those differences may therefore constitute an obstacle to the pursuit of economic activities at the level of the Union, distort competition and impede authorities in the discharge of their responsibilities under Union law. Such a difference in levels of protection is due to the existence of differences in the implementation and application of Directive 95/46/EC. (10) In order to ensure a consistent and high level of protection of natural persons and to remove the obstacles to flows of personal data within the Union, the level of protection of the rights and freedoms of natural persons with regard to the processing of such data should be equivalent in all Member States.\n",
            "\n",
            "\n",
            "Consistent and homogenous application of the rules for the protection of the fundamental rights and freedoms of natural persons with regard to the processing of personal data should be ensured throughout the Union. Regarding the processing of personal data for compliance with a legal obligation, for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller, Member States should be allowed to maintain or introduce national provisions to further specify the application of the rules of this Regulation. In conjunction with the general and horizontal law on data protection implementing Directive 95/46/EC, Member States have several sector-specific laws in areas that need more specific provisions. This Regulation also provides a margin of manoeuvre for Member States to specify its rules, including for the processing of special categories of personal data (‘sensitive data’). To that extent, this Regulation does not exclude Member State law that sets out the circumstances for specific processing situations, including determining more precisely the conditions under which the processing of personal data is lawful.\n",
            "\n",
            "\n",
            "In order to determine whether a processing activity can be considered to monitor the behaviour of data subjects, it should be ascertained whether natural persons are tracked on the internet including potential subsequent use of personal data processing techniques which consist of profiling a natural person, particularly in order to take decisions concerning her or him or for analysing or predicting her or his personal preferences, behaviours and attitudes. (25) Where Member State law applies by virtue of public international law, this Regulation should also apply to a controller not established in the Union, such as in a Member State's diplomatic mission or consular post. (26) The principles of data protection should apply to any information concerning an identified or identifiable natural person. Personal data which have undergone pseudonymisation, which could be attributed to a natural person by the use of additional information should be considered to be information on an identifiable natural person. To determine whether a natural person is identifiable, account should be taken of all the means reasonably likely to be used, such as singling out, either by the controller or by another person to identify the natural person directly or indirectly.\n",
            "\n",
            "\n",
            "To ascertain whether means are reasonably likely to be used to identify the natural person, account should be taken of all objective factors, such as the costs of and the amount of time required for identification, taking into consideration the available technology at the time of the processing and technological developments. The principles of data protection should therefore not apply to anonymous information, namely information which does not relate to an identified or identifiable natural person or to personal data rendered anonymous in such a manner that the data subject is not or no longer identifiable. This Regulation does not therefore concern the processing of such anonymous information, including for statistical or research purposes. (27) This Regulation does not apply to the personal data of deceased persons. Member States may provide for rules regarding the processing of personal data of deceased persons. (28) The application of pseudonymisation to personal data can reduce the risks to the data subjects concerned and help controllers and processors to meet their data-protection obligations. The explicit introduction of ‘pseudonymisation’ in this Regulation is not intended to preclude any other measures of data protection.\n",
            "\n",
            "\n",
            "(31) Public authorities to which personal data are disclosed in accordance with a legal obligation for the exercise of their official mission, such as tax and customs authorities, financial investigation units, independent administrative authorities, or financial market authorities responsible for the regulation and supervision of securities markets should not be regarded as recipients if they receive personal data which are necessary to carry out a particular inquiry in the general interest, in accordance with Union or Member State law. The requests for disclosure sent by the public authorities should always be in writing, reasoned and occasional and should not concern the entirety of a filing system or lead to the interconnection of filing systems. The processing of personal data by those public authorities should comply with the applicable data-protection rules according to the purposes of the processing. (32) Consent should be given by a clear affirmative act establishing a freely given, specific, informed and unambiguous indication of the data subject's agreement to the processing of personal data relating to him or her, such as by a written statement, including by electronic means, or an oral statement.\n",
            "\n",
            "\n",
            "An undertaking which controls the processing of personal data in undertakings affiliated to it should be regarded, together with those undertakings, as a group of undertakings. (38) Children merit specific protection with regard to their personal data, as they may be less aware of the risks, consequences and safeguards concerned and their rights in relation to the processing of personal data. Such specific protection should, in particular, apply to the use of personal data of children for the purposes of marketing or creating personality or user profiles and the collection of personal data with regard to children when using services offered directly to a child. The consent of the holder of parental responsibility should not be necessary in the context of preventive or counselling services offered directly to a child. (39) Any processing of personal data should be lawful and fair. It should be transparent to natural persons that personal data concerning them are collected, used, consulted or otherwise processed and to what extent the personal data are or will be processed. The principle of transparency requires that any information and communication relating to the processing of those personal data be easily accessible and easy to understand, and that clear and plain language be used.\n",
            "\n",
            "\n",
            "Personal data should be processed in a manner that ensures appropriate security and confidentiality of the personal data, including for preventing unauthorised access to or use of personal data and the equipment used for the processing. (40) In order for processing to be lawful, personal data should be processed on the basis of the consent of the data subject concerned or some other legitimate basis, laid down by law, either in this Regulation or in other Union or 4.5.2016 L 119/7 Official Journal of the European Union EN Member State law as referred to in this Regulation, including the necessity for compliance with the legal obligation to which the controller is subject or the necessity for the performance of a contract to which the data subject is party or in order to take steps at the request of the data subject prior to entering into a contract. (41) Where this Regulation refers to a legal basis or a legislative measure, this does not necessarily require a legislative act adopted by a parliament, without prejudice to requirements pursuant to the constitutional order of the Member State concerned. However, such a legal basis or legislative measure should be clear and precise and its application should be foreseeable to persons subject to it, in accordance with the case-law of the Court of Justice of the European Union (the ‘Court of Justice’) and the European Court of Human Rights.\n",
            "\n",
            "\n",
            "Furthermore, that law could specify the general conditions of this Regulation governing the lawfulness of personal data processing, establish specifications for determining the controller, the type of personal data which are subject to the processing, the data subjects concerned, the entities to which the personal data may be disclosed, the purpose limitations, the storage period and other measures to ensure lawful and fair processing. It should also be for Union or Member State law to determine whether the controller performing a task carried out in the public interest or in the exercise of official authority should be a public authority or another natural or legal person governed by public law, or, where it is in the public interest to do so, including for health purposes such as public health and social protection and the management of health care services, by private law, such as a professional association. (46) The processing of personal data should also be regarded to be lawful where it is necessary to protect an interest which is essential for the life of the data subject or that of another natural person. Processing of personal data 4.5.2016 L 119/8 Official Journal of the European Union EN (1)Council Directive 93/13/EEC of 5 April 1993 on unfair terms in consumer contracts (OJ L 95, 21.4.1993, p. 29). based on the vital interest of another natural person should in principle take place only where the processing cannot be manifestly based on another legal basis.\n",
            "\n",
            "\n",
            "The interests and fundamental rights of the data subject could in particular override the interest of the data controller where personal data are processed in circumstances where data subjects do not reasonably expect further processing. Given that it is for the legislator to provide by law for the legal basis for public authorities to process personal data, that legal basis should not apply to the processing by public authorities in the performance of their tasks. The processing of personal data strictly necessary for the purposes of preventing fraud also constitutes a legitimate interest of the data controller concerned. The processing of personal data for direct marketing purposes may be regarded as carried out for a legitimate interest. (48) Controllers that are part of a group of undertakings or institutions affiliated to a central body may have a legitimate interest in transmitting personal data within the group of undertakings for internal administrative purposes, including the processing of clients' or employees' personal data. The general principles for the transfer of personal data, within a group of undertakings, to an undertaking located in a third country remain unaffected. (49) The processing of personal data to the extent strictly necessary and proportionate for the purposes of ensuring network and information security, i.e.\n",
            "\n",
            "\n",
            "the ability of a network or an information system to resist, at a given level of confidence, accidental events or unlawful or malicious actions that compromise the availability, authenticity, integrity and confidentiality of stored or transmitted personal data, and the security of the related services offered by, or accessible via, those networks and systems, by public authorities, by computer emergency response teams (CERTs), computer security incident response teams (CSIRTs), by providers of electronic communications networks and services and by providers of security technologies and services, constitutes a legitimate interest of the data controller concerned. This could, for example, include preventing unauthorised access to electronic communications networks and malicious code distribution and stopping ‘denial of service’ attacks and damage to computer and electronic communication systems. (50) The processing of personal data for purposes other than those for which the personal data were initially collected should be allowed only where the processing is compatible with the purposes for which the personal data were initially collected. In such a case, no legal basis separate from that which allowed the collection of the personal data is required.\n",
            "\n",
            "\n",
            "Where the data subject has given consent or the processing is based on Union or Member State law which constitutes a necessary and proportionate measure in a democratic society to safeguard, in particular, important objectives of general public interest, the controller should be allowed to further process the personal data irrespective of the compatibility of the purposes. In any case, the application of the principles set out in this Regulation and in particular the information of the data subject on those other purposes and on his or her rights including the right to object, should be ensured. Indicating possible criminal acts or threats to public security by the controller and transmitting the relevant personal data in individual cases or in several cases relating to the same criminal act or threats to public security to a competent authority should be regarded as being in the legitimate interest pursued by the controller. However, such transmission in the legitimate interest of the controller or further processing of personal data should be prohibited if the processing is not compatible with a legal, professional or other binding obligation of secrecy. (51) Personal data which are, by their nature, particularly sensitive in relation to fundamental rights and freedoms merit specific protection as the context of their processing could create significant risks to the fundamental rights and freedoms.\n",
            "\n",
            "\n",
            "(57) If the personal data processed by a controller do not permit the controller to identify a natural person, the data controller should not be obliged to acquire additional information in order to identify the data subject for the sole purpose of complying with any provision of this Regulation. However, the controller should not refuse to take additional information provided by the data subject in order to support the exercise of his or her rights. Identification should include the digital identification of a data subject, for example through authentication mechanism such as the same credentials, used by the data subject to log-in to the on-line service offered by the data controller. (58) The principle of transparency requires that any information addressed to the public or to the data subject be concise, easily accessible and easy to understand, and that clear and plain language and, additionally, where appropriate, visualisation be used. Such information could be provided in electronic form, for example, when addressed to the public, through a website. This is of particular relevance in situations where the proliferation of actors and the technological complexity of practice make it difficult for the data subject to know and understand whether, by whom and for what purpose personal data relating to him or her are being collected, such as in the case of online advertising.\n",
            "\n",
            "\n",
            "Where the controller intends to process the personal data for a purpose other than that for which they were collected, the controller should provide the data subject prior to that further processing with information on that other purpose and other necessary information. Where the origin of the personal data cannot be provided to the data subject because various sources have been used, general information should be provided. (62) However, it is not necessary to impose the obligation to provide information where the data subject already possesses the information, where the recording or disclosure of the personal data is expressly laid down by law or where the provision of information to the data subject proves to be impossible or would involve a disproportionate effort. The latter could in particular be the case where processing is carried out for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes. In that regard, the number of data subjects, the age of the data and any appropriate safeguards adopted should be taken into consideration. (63) A data subject should have the right of access to personal data which have been collected concerning him or her, and to exercise that right easily and at reasonable intervals, in order to be aware of, and verify, the lawfulness of the processing.\n",
            "\n",
            "\n",
            "This includes the right for data subjects to have access to data concerning their health, for example the data in their medical records containing information such as diagnoses, examination results, assessments by treating physicians and any treatment or interventions provided. Every data subject should therefore have the right to know and obtain communication in particular with regard to the purposes for which the personal data are processed, where possible the period for which the personal data are processed, the recipients of the personal data, the logic involved in any automatic personal data processing and, at least when based on profiling, the consequences of such processing. Where possible, the controller should be able to provide remote access to a secure system which would provide the data subject with direct access to his or her personal data. That right should not adversely affect the rights or freedoms of others, including trade secrets or intellectual property and in particular the copyright protecting the software. However, the result of those considerations should not be a refusal to provide all information to the data subject. Where the controller processes a large quantity of information concerning the data subject, the controller should be able to request that, before the information is delivered, the data subject specify the information or processing activities to which the request relates.\n",
            "\n",
            "\n",
            "(69) Where personal data might lawfully be processed because processing is necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller, or on grounds of the legitimate interests of a controller or a third party, a data subject should, nevertheless, be entitled to object to the processing of any personal data relating to his or her particular situation. It should be for the controller to demonstrate that its compelling legitimate interest overrides the interests or the fundamental rights and freedoms of the data subject. (70) Where personal data are processed for the purposes of direct marketing, the data subject should have the right to object to such processing, including profiling to the extent that it is related to such direct marketing, whether with regard to initial or further processing, at any time and free of charge. That right should be explicitly brought to the attention of the data subject and presented clearly and separately from any other information.\n",
            "\n",
            "\n",
            "(73) Restrictions concerning specific principles and the rights of information, access to and rectification or erasure of personal data, the right to data portability, the right to object, decisions based on profiling, as well as the communication of a personal data breach to a data subject and certain related obligations of the controllers may be imposed by Union or Member State law, as far as necessary and proportionate in a democratic society to safeguard public security, including the protection of human life especially in response to natural or manmade disasters, the prevention, investigation and prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security, or of breaches of ethics for regulated professions, other important objectives of general public interest of the Union or of a Member State, in particular an important economic or financial interest of the Union or of a Member State, the keeping of public registers kept for reasons of general public interest, further processing of archived personal data to provide specific information related to the political behaviour under former totalitarian state regimes or the protection of the data subject or the rights and freedoms of others, including social protection, public health and humanitarian purposes.\n",
            "\n",
            "\n",
            "In order to be able to demonstrate compliance with this Regulation, the controller should adopt internal policies and implement measures which meet in particular the principles of data protection by design and data protection by default. Such measures could consist, inter alia, of minimising the processing of personal data, pseudonymising personal data as soon as possible, transparency with regard to the functions and processing of personal data, enabling the data subject to monitor the data processing, enabling the controller to create and improve security features. When developing, designing, selecting and using applications, services and products that are based on the processing of personal data or process personal data to fulfil their task, producers of the products, services and applications should be encouraged to take into account the right to data protection when developing and designing such products, services and applications and, with due regard to the state of the art, to make sure that controllers and processors are able to fulfil their data protection obligations. The principles of data protection by design and by default should also be taken into consideration in the context of public tenders.\n",
            "\n",
            "\n",
            "Each controller and processor should be obliged to cooperate with the supervisory authority and make those records, on request, available to it, so that it might serve for monitoring those processing operations. (83) In order to maintain security and to prevent processing in infringement of this Regulation, the controller or processor should evaluate the risks inherent in the processing and implement measures to mitigate those risks, such as encryption. Those measures should ensure an appropriate level of security, including confidentiality, taking into account the state of the art and the costs of implementation in relation to the risks and the nature of the personal data to be protected. In assessing data security risk, consideration should be given to the risks that are presented by personal data processing, such as accidental or unlawful destruction, loss, alteration, unauthorised disclosure of, or access to, personal data transmitted, stored or otherwise processed which may in particular lead to physical, material or non-material damage. (84) In order to enhance compliance with this Regulation where processing operations are likely to result in a high risk to the rights and freedoms of natural persons, the controller should be responsible for the carrying-out of a data protection impact assessment to evaluate, in particular, the origin, nature, particularity and severity of that risk.\n",
            "\n",
            "\n",
            "The outcome of the assessment should be taken into account when determining the appropriate measures to be taken in order to demonstrate that the processing of personal data complies with this Regulation. Where a data-protection impact assessment indicates that processing operations involve a high risk which the controller cannot mitigate by appropriate measures in terms of available technology and costs of implementation, a consultation of the supervisory authority should take place prior to the processing. (85) A personal data breach may, if not addressed in an appropriate and timely manner, result in physical, material or non-material damage to natural persons such as loss of control over their personal data or limitation of their rights, discrimination, identity theft or fraud, financial loss, unauthorised reversal of pseudonymisation, damage to reputation, loss of confidentiality of personal data protected by professional secrecy or any other significant economic or social disadvantage to the natural person concerned.\n",
            "\n",
            "\n",
            "(108) In the absence of an adequacy decision, the controller or processor should take measures to compensate for the lack of data protection in a third country by way of appropriate safeguards for the data subject. Such appropriate safeguards may consist of making use of binding corporate rules, standard data protection clauses adopted by the Commission, standard data protection clauses adopted by a supervisory authority or contractual clauses authorised by a supervisory authority. Those safeguards should ensure compliance with data protection requirements and the rights of the data subjects appropriate to processing within the Union, including the availability of enforceable data subject rights and of effective legal remedies, including to obtain effective administrative or judicial redress and to claim compensation, in the Union or in a third country. They should relate in particular to compliance with the general principles relating to personal data processing, the principles of data protection by design and by default. Transfers may also be carried out by public authorities or bodies with public authorities or bodies in third countries or with international organisations with corresponding duties or functions, including on the basis of provisions to be inserted into administrative arrangements, such as a memorandum of understanding, providing for enforceable and effective rights for data subjects.\n",
            "\n",
            "\n",
            "In order to take account of the importance of the right to freedom of expression in every democratic society, it is necessary to interpret notions relating to that freedom, such as journalism, broadly. (154) This Regulation allows the principle of public access to official documents to be taken into account when applying this Regulation. Public access to official documents may be considered to be in the public interest. Personal data in documents held by a public authority or a public body should be able to be publicly disclosed by that authority or body if the disclosure is provided for by Union or Member State law to which the public authority or public body is subject. Such laws should reconcile public access to official documents and the reuse of public sector information with the right to the protection of personal data and may therefore provide for the necessary reconciliation with the right to the protection of personal data pursuant to this Regulation. The reference to public authorities and bodies should in that context include all authorities or other bodies covered by Member State law on public access to documents.\n",
            "\n",
            "\n",
            "However, public authorities which may receive personal data in the 4.5.2016 L 119/33 Official Journal of the European Union EN framework of a particular inquiry in accordance with Union or Member State law shall not be regarded as recipients; the processing of those data by those public authorities shall be in compliance with the applicable data protection rules according to the purposes of the processing; (10) ‘third party’ means a natural or legal person, public authority, agency or body other than the data subject, controller, processor and persons who, under the direct authority of the controller or processor, are authorised to process personal data; (11) ‘consent’ of the data subject means any freely given, specific, informed and unambiguous indication of the data subject's wishes by which he or she, by a statement or by a clear affirmative action, signifies agreement to the processing of personal data relating to him or her; (12) ‘personal data breach’ means a breach of security leading to the accidental or unlawful destruction, loss, alteration, unauthorised disclosure of, or access to, personal data transmitted, stored or otherwise processed; (13) ‘genetic data’ means personal data relating to the inherited or acquired genetic characteristics of a natural person which give unique information about the physiology or the health of that natural person and which result, in particular, from an analysis of a biological sample from the natural person in question;\n",
            "\n",
            "\n",
            "(e) kept in a form which permits identification of data subjects for no longer than is necessary for the purposes for which the personal data are processed; personal data may be stored for longer periods insofar as the personal data will be processed solely for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes in accordance with Article 89(1) subject to implementation of the appropriate technical and organisational measures required by this Regulation in order to safeguard the rights and freedoms of the data subject (‘storage limitation’); (f) processed in a manner that ensures appropriate security of the personal data, including protection against unauthorised or unlawful processing and against accidental loss, destruction or damage, using appropriate technical or organisational measures (‘integrity and confidentiality’). 2.The controller shall be responsible for, and be able to demonstrate compliance with, paragraph 1 (‘accountability’).\n",
            "\n",
            "\n",
            "CHAPTER III Rights of the data subject Section 1 Transparency and modalities Article 12 Transparent information, communication and modalities for the exercise of the rights of the data subject 1.The controller shall take appropriate measures to provide any information referred to in Articles 13 and 14 and any communication under Articles 15 to 22 and 34 relating to processing to the data subject in a concise, transparent, intelligible and easily accessible form, using clear and plain language, in particular for any information addressed specifically to a child. The information shall be provided in writing, or by other means, including, where appropriate, by electronic means. When requested by the data subject, the information may be provided orally, provided that the identity of the data subject is proven by other means. 4.5.2016 L 119/39 Official Journal of the European Union EN 2.The controller shall facilitate the exercise of data subject rights under Articles 15 to 22. In the cases referred to in Article 11(2), the controller shall not refuse to act on the request of the data subject for exercising his or her rights under Articles 15 to 22, unless the controller demonstrates that it is not in a position to identify the data subject. 3.The controller shall provide information on action taken on a request under Articles 15 to 22 to the data subject without undue delay and in any event within one month of receipt of the request.\n",
            "\n",
            "\n",
            "Article 14 Information to be provided where personal data have not been obtained from the data subject 1.Where personal data have not been obtained from the data subject, the controller shall provide the data subject with the following information: (a) the identity and the contact details of the controller and, where applicable, of the controller's representative; (b) the contact details of the data protection officer, where applicable; (c) the purposes of the processing for which the personal data are intended as well as the legal basis for the processing; (d) the categories of personal data concerned; (e) the recipients or categories of recipients of the personal data, if any; 4.5.2016 L 119/41 Official Journal of the European Union EN (f)where applicable, that the controller intends to transfer personal data to a recipient in a third country or international organisation and the existence or absence of an adequacy decision by the Commission, or in the case of transfers referred to in Article 46 or 47, or the second subparagraph of Article 49(1), reference to the appropriate or suitable safeguards and the means to obtain a copy of them or where they have been made available.\n",
            "\n",
            "\n",
            "In such cases the controller shall take appropriate measures to protect the data subject's rights and freedoms and legitimate interests, including making the information publicly available; (c) obtaining or disclosure is expressly laid down by Union or Member State law to which the controller is subject and which provides appropriate measures to protect the data subject's legitimate interests; or (d) where the personal data must remain confidential subject to an obligation of professional secrecy regulated by Union or Member State law, including a statutory obligation of secrecy.\n",
            "\n",
            "\n",
            "4.5.2016 L 119/52 Official Journal of the European Union EN 2.The communication to the data subject referred to in paragraph 1 of this Article shall describe in clear and plain language the nature of the personal data breach and contain at least the information and measures referred to in points (b), (c) and (d) of Article 33(3). 3.The communication to the data subject referred to in paragraph 1 shall not be required if any of the following conditions are met: (a) the controller has implemented appropriate technical and organisational protection measures, and those measures were applied to the personal data affected by the personal data breach, in particular those that render the personal data unintelligible to any person who is not authorised to access it, such as encryption; (b) the controller has taken subsequent measures which ensure that the high risk to the rights and freedoms of data subjects referred to in paragraph 1 is no longer likely to materialise; (c) it would involve disproportionate effort. In such a case, there shall instead be a public communication or similar measure whereby the data subjects are informed in an equally effective manner. 4.If the controller has not already communicated the personal data breach to the data subject, the supervisory authority, having considered the likelihood of the personal data breach resulting in a high risk, may require it to do so or may decide that any of the conditions referred to in paragraph 3 are met.\n",
            "\n",
            "\n",
            "2.Associations and other bodies representing categories of controllers or processors may prepare codes of conduct, or amend or extend such codes, for the purpose of specifying the application of this Regulation, such as with regard to: (a) fair and transparent processing; 4.5.2016 L 119/56 Official Journal of the European Union EN (b) the legitimate interests pursued by controllers in specific contexts; (c) the collection of personal data; (d) the pseudonymisation of personal data; (e) the information provided to the public and to data subjects; (f) the exercise of the rights of data subjects; (g) the information provided to, and the protection of, children, and the manner in which the consent of the holders of parental responsibility over children is to be obtained; (h) the measures and procedures referred to in Articles 24 and 25 and the measures to ensure security of processing referred to in Article 32; (i) the notification of personal data breaches to supervisory authorities and the communication of such personal data breaches to data subjects; (j) the transfer of personal data to third countries or international organisations; or (k) out-of-court proceedings and other dispute resolution procedures for resolving disputes between controllers and data subjects with regard to processing, without prejudice to the rights of data subjects pursuant to Articles 77 and 79.\n",
            "\n",
            "\n",
            "Article 50 International cooperation for the protection of personal data In relation to third countries and international organisations, the Commission and supervisory authorities shall take appropriate steps to: (a) develop international cooperation mechanisms to facilitate the effective enforcement of legislation for the protection of personal data; (b) provide international mutual assistance in the enforcement of legislation for the protection of personal data, including through notification, complaint referral, investigative assistance and information exchange, subject to appropriate safeguards for the protection of personal data and other fundamental rights and freedoms; (c) engage relevant stakeholders in discussion and activities aimed at furthering international cooperation in the enforcement of legislation for the protection of personal data; (d)promote the exchange and documentation of personal data protection legislation and practice, including on jurisdictional conflicts with third countries. CHAPTER VI Independent supervisory authorities Section 1 Independent status Article 51 Supervisory authority 1.Each Member State shall provide for one or more independent public authorities to be responsible for monitoring the application of this Regulation, in order to protect the fundamental rights and freedoms of natural persons in relation to processing and to facilitate the free flow of personal data within the Union (‘supervisory authority’).\n",
            "\n",
            "\n",
            "The Privacy Rule permits use and disclosure of protected health information, without an individual’s authorization or permission, for 12 national priority purposes.28 These disclosures are permitted, although not required, by the Rule in recognition of the important uses made of health information outside of the health care context. Specific conditions or limitations apply to each public interest purpose, striking the balance between the individual privacy interest and the public interest need for this information. Required by Law. Covered entities may use and disclose protected health information without individual authorization as required by law (including by OCR Privacy Rule Summary 7 Last Revised 05/03 statute, regulation, or court orders).29 Public Health Activities.\n",
            "\n",
            "\n",
            "A limited data set is protected health information from which certain specified direct identifiers of individuals and their relatives, household members, and employers have been removed.43 A limited data set may be used and disclosed for research, health care operations, and public health purposes, provided the recipient enters into a data use agreement promising specified safeguards for the protected health information within the limited data set. Authorized Uses and Disclosures Authorization. A covered entity must obtain the individual’s written authorization for any use or disclosure of protected health information that is not for treatment, payment or health care operations or otherwise permitted or required by the Privacy Rule.44 A covered entity may not condition treatment, payment, enrollment, or benefits eligibility on an individual granting an authorization, except in limited circumstances.45 An authorization must be written in specific terms. It may allow use and disclosure of protected health information by the covered entity seeking the authorization, or by a third party. Examples of disclosures that would require an individual’s authorization include disclosures to a life insurer for coverage purposes, disclosures to an employer of the results of a pre-employment physical or lab test, or disclosures to a pharmaceutical firm for their own marketing purposes.\n",
            "\n",
            "\n",
            "The Development of Privacy Protection in the United States: A Sectoral Approach The United States has historically taken a markedly different approach to privacy protection compared to Europe, developing a patchwork of sector-specific laws rather than comprehensive federal legislation. This sectoral approach reflects American values of free market economics and limited government intervention. Early Privacy Developments (1960s-1970s): The Fair Credit Reporting Act of 1970 was one of the first federal laws addressing privacy concerns, focusing specifically on the collection and use of consumer credit information. This law established important principles including: - Consumer right to access their credit reports - Requirement for accurate reporting - Time limits on negative information - Procedures for disputing incorrect information The Privacy Act of 1974 represented another significant step, though limited to government agencies. It established: - Rules for government collection and use of personal data - Individual rights to access and correct records - Restrictions on sharing between agencies - Civil and criminal penalties for violations The Evolution of Sectoral Privacy Laws: Different industries received specific privacy regulations over time: Healthcare: The Health Insurance Portability and Accountability Act (HIPAA) of 1996 created comprehensive privacy rules for medical information, including: - Patient rights to access medical records -\n",
            "\n",
            "\n",
            "Restrictions on information sharing - Security requirements for health data - Breach notification requirements - Substantial penalties for violations Financial Services: The Gramm-Leach-Bliley Act of 1999 established privacy rules for financial institutions: - Required privacy notices to customers - Opt-out rights for information sharing - Security standards for financial data - State enforcement mechanisms Children's Privacy: The Children's Online Privacy Protection Act (COPPA) of 1998 specifically addressed children's privacy online: - Parental consent requirements - Restrictions on data collection from children under 13 - Requirements for privacy policies - Limits on marketing to children Education: The Family Educational Rights and Privacy Act (FERPA) protects student education records: - Parent/student rights to access records - Limitations on disclosure without consent - Requirements for schools' privacy practices The Digital Age and New Challenges: The rise of internet companies in the 1990s and 2000s exposed gaps in U.S. privacy protection. The Federal Trade Commission (FTC) became the de facto privacy regulator, using its authority to: - Enforce company privacy promises - Investigate data breaches - Issue privacy guidelines - Impose fines for privacy violations Notable FTC actions included: - 2011 Facebook settlement requiring privacy audits - 2012 Google privacy violation fine ($22.5 million) -\n",
            "\n",
            "\n",
            "Proposed Law The California Privacy Rights Act of 2020 Section 0.5: Table of Contents Section 1: Title: The California Privacy Rights Act of 2020 Section 2: Findings and Declarations Section 3: Purpose and Intent (A) Consumer Rights (B) Responsibilities of Businesses (C) Implementation of the Law Section 4: General Duties of Businesses that Collect Personal Information Section 5: Consumers’ Right to Delete Personal Information Section 6: Consumers’ Right to Correct Inaccurate Personal Information Section 7: Consumers’ Right to Know What Personal Information is Being Collected.\n",
            "\n",
            "\n",
            "The people of the State of California hereby find and declare all of the following: (A) In 1972, California voters amended the California Constitution to include the right of privacy among the “inalienable” rights of all people. Voters acted in response to the accelerating encroachment on personal freedom and security caused by increased data collection and usage in contemporary society. The amendment established a legal and enforceable constitutional right of privacy for every Californian. Fundamental to this right of privacy is the ability of individuals to control the use, including the sale, of their personal information. (B) Since California voters approved the constitutional right of privacy, the California Legislature has adopted specific mechanisms to safeguard Californians’ privacy, including the Online Privacy Protection Act, the Privacy Rights for California Minors in the Digital World Act, and Shine the Light, but consumers had no right to learn what personal information a business had collected about them and how they used it or to direct businesses not to sell the consumer’s personal information. (C) That changed in 2018, when more than 629,000 California voters signed petitions to qualify the California Consumer Privacy Act of 2018 for the ballot. In response to the measure’s qualification, the Legislature enacted the California Consumer Privacy Act of 2018 (CCPA) into law.\n",
            "\n",
            "\n",
            "In enacting this Act, it is the purpose and intent of the people of the State of California to further protect consumers’ rights, including the constitutional right of privacy. The implementation of this Act shall be guided by the following principles: (A) Consumer Rights (1) Consumers should know who is collecting their personal information and that of their children, how it is being used, and to whom it is disclosed so that they have the information necessary to exercise meaningful control over businesses’ use of their personal information and that of their children. (2) Consumers should be able to control the use of their personal information, including limiting the use of their sensitive personal information, the unauthorized use or disclosure of which creates a heightened risk of harm to the consumer, and they should have meaningful options over how it is collected, used, and disclosed. (3) Consumers should have access to their personal information and should be able to correct it, delete it, and take it with them from one business to another. (4) Consumers or their authorized agents should be able to exercise these options through easily accessible self-serve tools. (5) Consumers should be able to exercise these rights without being penalized for doing so. (6) Consumers should be able to hold businesses accountable for failing to take reasonable precautions to protect their most sensitive personal information from hackers and security breaches.\n",
            "\n",
            "\n",
            "(4) Businesses should provide consumers or their authorized agents with easily accessible means to allow consumers and their children to obtain their personal information, to delete it, or correct it, and to opt‐out of its sale and the sharing across business platforms, services, businesses and devices, and to limit the use of their sensitive personal information. (5) Businesses should not penalize consumers for exercising these rights. (6) Businesses should take reasonable precautions to protect consumers’ personal information from a security breach. (7) Businesses should be held accountable when they violate consumers’ privacy rights, and the penalties should be higher when the violation affects children. (C) Implementation of the Law (1) The rights of consumers and the responsibilities of businesses should be implemented with the goal of strengthening consumer privacy, while giving attention to the impact on business and innovation. Consumer privacy and the development of beneficial new products and services are not necessarily incompatible goals. Strong consumer privacy rights create incentives to innovate and develop new products that are privacy protective. (2) Businesses and consumers should be provided with clear guidance about their responsibilities and rights. (3) The law should place the consumer in a position to knowingly and freely negotiate with a business over the business’ use of the consumer’s personal information.\n",
            "\n",
            "\n",
            "(C) Identify by category or categories the personal information of the consumer that the business disclosed for a business purpose in the preceding 12 monthsduring the applicable period of time by reference to the enumerated category or categories in subdivision (c) that most closely describes the personal information, and provide the categories of third parties persons to whom the consumer’s personal information was disclosed for a business purpose in the preceding 12 months during the applicable period of time by reference to the enumerated category or categories in subdivision (c) that most closely describes the personal information disclosed. The business shall disclose the information in a list that is separate from a list generated for the purposes of subparagraph (B). (5) Disclose the following information in its online privacy policy or policies if the business has an online privacy policy or policies and in any California‐specific description of consumers’ privacy rights, or if the business does not maintain those policies, on its internet website, and update that information at least once every 12 months: (A) A description of a consumer’s rights pursuant to Sections 1798.100, 1798.105, 1798.106, 1798.110, 1798.115, and 1798.125 and one two or more designated methods for submitting requests, except as provided in subparagraph (A) of paragraph (1) of subdivision (a).\n",
            "\n",
            "\n",
            "(D) (C) The business transfers to a third party the personal information of a consumer as an asset that is part of a merger, acquisition, bankruptcy, or other transaction in which the third party assumes control of all or part of the business, provided that information is used or shared consistently with Sections 1798.110 and 1798.115 this title. If a third party materially alters how it uses or shares the personal information of a consumer in a manner that is materially inconsistent with the promises made at the time of collection, it shall provide prior notice of the new or changed practice to the consumer. The notice shall be sufficiently prominent and robust to ensure that existing consumers can easily exercise their choices consistently with Section 1798.120 this title. This subparagraph does not authorize a business to make material, retroactive privacy policy changes or make other changes in their privacy policy in a manner that would violate the Unfair and Deceptive Practices Act (Chapter 5 (commencing with Section 17200) of Part 2 of Division 7 of the Business and Professions Code). (ae) “Sensitive personal information“ means: (1) Personal information that reveals: (A) A consumer’s social security, driver’s license, state identification card, or passport number. (B) A consumer’s account log-in, financial account, debit card, or credit card number in combination with any required security or access code, password, or credentials allowing access to an account.\n",
            "\n",
            "\n",
            "(15) Issuing regulations requiring businesses whose processing of consumers’ personal information presents significant risk to consumers’ privacy or security, to: (A) Perform a cybersecurity audit on an annual basis, including defining the scope of the audit and establishing a process to ensure that audits are thorough and independent. The factors to be considered in determining when processing may result in significant risk to the security of personal information shall include the size and complexity of the business and the nature and scope of processing activities. (B) Submit to the California Privacy Protection Agency on a regular basis a risk assessment with respect to their processing of personal information, including whether the processing involves sensitive personal information, and identifying and weighing the benefits resulting from the processing to the business, the consumer, other stakeholders, and the public, against the potential risks to the rights of the consumer associated with that processing, with the goal of restricting or prohibiting the processing if the risks to privacy of the consumer outweigh the benefits resulting from processing to the consumer, the business, other stakeholders, and the public. Nothing in this section shall require a business to divulge trade secrets.\n",
            "\n",
            "\n",
            "(b) On and after the earlier of July 1, 2021, or within six months of the agency providing the Attorney General with notice that it is prepared to assume rulemaking responsibilities under this title, adopt, amend, and rescind regulations pursuant to Section 1798.185 to carry out the purposes and provisions of the California Consumer Privacy Act of 2018, including regulations specifying record keeping requirements for businesses to ensure compliance with this title. (c) Through the implementation of this title, protect the fundamental privacy rights of natural persons with respect to the use of their personal information. (d) Promote public awareness and understanding of the risks, rules, responsibilities, safeguards, and rights in relation to the collection, use, sale, and disclosure of personal information, including the rights of minors with respect to their own information, and provide a public report summarizing the risk assessments filed with the agency pursuant to paragraph (15) of subdivision (a) of Section 1798.185 while ensuring that data security is not compromised. (e) Provide guidance to consumers regarding their rights under this title. (f) Provide guidance to businesses regarding their duties and responsibilities under this title and appoint a Chief Privacy Auditor to conduct audits of businesses to ensure compliance with this title pursuant to regulations adopted pursuant to paragraph (18) of subdivision (a) of Section 1798.185.\n",
            "\n",
            "\n",
            "Query: Summarize how GDPR is applicable to international organizations using only articles tagged with GDPR  (EU GDPR paper)\n",
            "Similar Sentences:\n",
            "Query: What privacy protection is applicable in California?\n",
            "Similar Sentences:\n",
            "(d) A business, or a service provider or contractor acting pursuant to its contract with the business, another service provider, or another contractor, shall not be required to comply with a consumer’s request to delete the consumer’s personal information if it is reasonably necessary for the business, service provider, or contractor to maintain the consumer’s personal information in order to: (1) Complete the transaction for which the personal information was collected, fulfill the terms of a written warranty or product recall conducted in accordance with federal law, provide a good or service requested by the consumer, or reasonably anticipated by the consumer within the context of a business’ ongoing business relationship with the consumer, or otherwise perform a contract between the business and the consumer. (2) Help to ensure security and integrity to the extent the use of the consumer’s personal information is reasonably necessary and proportionate for those purposes. (3) Debug to identify and repair errors that impair existing intended functionality. (4) Exercise free speech, ensure the right of another consumer to exercise that consumer’s right of free speech, or exercise another right provided for by law. (5) Comply with the California Electronic Communications Privacy Act pursuant to Chapter 3.6 (commencing with Section 1546) of Title 12 of Part 2 of the Penal Code.\n",
            "\n",
            "\n",
            "(C) Identify by category or categories the personal information of the consumer that the business disclosed for a business purpose during the applicable period of time by reference to the enumerated category or categories in subdivision (c) that most closely describes the personal information, and provide the categories of persons to whom the consumer’s personal information was disclosed for a business purpose during the applicable period of time by reference to the enumerated category or categories in subdivision (c) that most closely describes the personal information disclosed. The business shall disclose the information in a list that is separate from a list generated for the purposes of subparagraph (B). (5) Disclose the following information in its online privacy policy or policies if the business has an online privacy policy or policies and in any California-specific description of consumers’ privacy rights, or if the business does not maintain those policies, on its internet website, and update that information at least once every 12 months: (A) A description of a consumer’s rights pursuant to Sections 1798.100, 1798.105, 1798.106, 1798.110, 1798.115, and 1798.125 and two or more designated methods for submitting requests, except as provided in subparagraph (A) of paragraph (1) of subdivision (a).\n",
            "\n",
            "\n",
            "(2) Include a description of a consumer’s rights pursuant to Sections 1798.120 and 1798.121, along with a separate link to the “Do Not Sell or Share My Personal Information” internet web page and a separate link to the “Limit the Use of My Sensitive Personal Information” internet web page, if applicable, or a single link to both choices, or a statement that the business responds to and abides by opt-out preference signals sent by a platform, technology, or mechanism in accordance with subdivision (b), in: (A) Its online privacy policy or policies if the business has an online privacy policy or policies. (B) Any California-specific description of consumers’ privacy rights. (3) Ensure that all individuals responsible for handling consumer inquiries about the business’ privacy practices or the business’ compliance with this title are informed of all requirements in Sections 1798.120, 1798.121, and this section and how to direct consumers to exercise their rights under those sections.\n",
            "\n",
            "\n",
            "For purposes of this title, commercial conduct takes place wholly outside of California if the business collected that information while the consumer was outside of California, no part of the sale of the consumer’s personal information occurred in California, and no personal information collected while the consumer was in California is sold. This paragraph shall not prohibit a business from storing, including on a device, personal information about a consumer when the consumer is in California and then collecting that personal information when the consumer and stored personal information is outside of California. (2) (A) This subdivision shall not apply if the consumer’s personal information contains information related to accessing, procuring, or searching for services regarding contraception, pregnancy care, and perinatal care, including, but not limited to, abortion services. (B) This paragraph does not alter the use of aggregated or deidentified personal information consistent with a business purpose as defined in paragraphs (1), (2), (3), (4), (5), (7), or (8) of subdivision (e) of Section 1798.140, provided that the personal information is only retained in aggregated and deidentified form and is not sold or shared. (C) This paragraph does not alter the duty of a business to preserve or retain evidence pursuant to California or federal law in an ongoing civil proceeding.\n",
            "\n",
            "\n",
            "(b) The obligations imposed on businesses by Sections 1798.110, 1798.115, 1798.120, 1798.121, 1798.130, and 1798.135 shall not apply where compliance by the business with the title would violate an evidentiary privilege under California law and shall not prevent a business from providing the personal information of a consumer to a person covered by an evidentiary privilege under California law as part of a privileged communication. (c) (1) This title shall not apply to any of the following: (A) Medical information governed by the Confidentiality of Medical Information Act (Part 2.6 (commencing with Section 56) of Division 1) or protected health information that is collected by a covered entity or business associate governed by the privacy, security, and breach notification rules issued by the United States Department of Health and Human Services, Parts 160 and 164 of Title 45 of the Code of Federal Regulations, established pursuant to the Health Insurance Portability and Accountability Act of 1996 (Public Law 104-191) and the Health Information Technology for Economic and Clinical Health Act (Public Law 111-5).\n",
            "\n",
            "\n",
            "Administrative Enforcement (a) Any business, service provider, contractor, or other person that violates this title shall be liable for an administrative fine of not more than two thousand five hundred dollars ($2,500) for each violation or seven thousand five hundred dollars ($7,500) for each intentional violation or violations involving the personal information of consumers whom the business, service provider, contractor, or other person has actual knowledge are under 16 years of age, as adjusted pursuant to subdivision (d) of Section 1798.199.95, in an administrative enforcement action brought by the California Privacy Protection Agency. (b) Any administrative fine assessed for a violation of this title, and the proceeds of any settlement of an action brought pursuant to subdivision (a), shall be deposited in the Consumer Privacy Fund, created within the General Fund pursuant to subdivision (a) of Section 1798.160 with the intent to fully offset any costs incurred by the state courts, the Attorney General, and the California Privacy Protection Agency in connection with this title. (Amended by Stats. 2024, Ch. 121, Sec. 7. (AB 3286) Effective January 1, 2025.) 1798.160.\n",
            "\n",
            "\n",
            "Consumer Privacy Fund (a) A special fund to be known as the “Consumer Privacy Fund” is hereby created within the General Fund in the State Treasury, and is available upon appropriation by the Legislature first to offset any costs incurred by the state courts in connection with actions brought to enforce this title, the costs incurred by the California Privacy Protection Agency in carrying out its duties under this title, the costs incurred by the Attorney General in carrying out the Attorney General’s duties under this title, and then for the purposes of establishing an investment fund in the State Treasury, with any earnings or interest from the fund to be deposited in the General Fund, and making grants to promote and protect consumer privacy, educate children in the area of online privacy, and fund cooperative programs with international law enforcement organizations to combat fraudulent activities with respect to consumer data breaches. (b) Funds transferred to the Consumer Privacy Fund shall be used exclusively as follows: (1) To offset any costs incurred by the state courts, the California Privacy Protection Agency, and the Attorney General in connection with this title. (2) After satisfying the obligations under paragraph (1), the remaining funds shall be allocated each fiscal year as follows: (A) Ninety-one percent shall be invested by the Treasurer in financial assets with the goal of maximizing long-term yields consistent with a prudent level of risk.\n",
            "\n",
            "\n",
            "The principal shall not be subject to transfer or appropriation, provided that any interest and earnings shall be transferred on an annual basis to the General Fund for appropriation by the Legislature for General Fund purposes. (B) Subject to subdivision (d), 9 percent shall be made available to the California Privacy Protection Agency for the purposes of making grants in California, with 3 percent allocated to each of the following grant recipients: (i) Nonprofit organizations to promote and protect consumer privacy. (ii) Nonprofit organizations and public agencies, including school districts, to educate children in the area of online privacy. (iii) State and local law enforcement agencies to fund cooperative programs with international law enforcement organizations to combat fraudulent activities with respect to consumer data breaches. (c) Funds in the Consumer Privacy Fund shall not be subject to appropriation or transfer by the Legislature for any other purpose. (d) (1) The California Privacy Protection Agency shall begin administering the grant program described in subparagraph (B) of paragraph (2) of subdivision (b) when the amount of grant funds available after all other distributions have been made in accordance with this section exceeds three hundred thousand dollars ($300,000).\n",
            "\n",
            "\n",
            "(14) Issuing regulations requiring businesses whose processing of consumers’ personal information presents significant risk to consumers’ privacy or security, to: (A) Perform a cybersecurity audit on an annual basis, including defining the scope of the audit and establishing a process to ensure that audits are thorough and independent. The factors to be considered in determining when processing may result in significant risk to the security of personal information shall include the size and complexity of the business and the nature and scope of processing activities. (B) Submit to the California Privacy Protection Agency on a regular basis a risk assessment with respect to their processing of personal information, including whether the processing involves sensitive personal information, and identifying and weighing the benefits resulting from the processing to the business, the consumer, other stakeholders, and the public, against the potential risks to the rights of the consumer associated with that processing, with the goal of restricting or prohibiting the processing if the risks to privacy of the consumer outweigh the benefits resulting from processing to the consumer, the business, other stakeholders, and the public. Nothing in this section shall require a business to divulge trade secrets.\n",
            "\n",
            "\n",
            "Beginning the later of July 1, 2021, or six months after the agency provides notice to the Attorney General that it is prepared to begin rulemaking under this title, the authority assigned to the Attorney General to adopt regulations under this section shall be exercised by the California Privacy Protection Agency. Notwithstanding any other law, civil and administrative enforcement of the provisions of law added or amended by this act shall not commence until July 1, 2023, and shall only apply to violations occurring on or after that date. Enforcement of provisions of law contained in the California Consumer Privacy Act of 2018 amended by this act shall remain in effect and shall be enforceable until the same provisions of this act become enforceable. (Amended by Stats. 2024, Ch. 121, Sec. 9. (AB 3286) Effective January 1, 2025.) 1798.190. Anti-Avoidance A court or the agency shall disregard the intermediate steps or transactions for purposes of effectuating the purposes of this title: (a) If a series of steps or transactions were component parts of a single transaction intended from the beginning to be taken with the intention of avoiding the reach of this title, including the disclosure of information by a business to a third party in order to avoid the definition of sell or share.\n",
            "\n",
            "\n",
            "(b) On and after the later of July 1, 2021, or within six months of the agency providing the Attorney General with notice that it is prepared to assume rulemaking responsibilities under this title, adopt, amend, and rescind regulations pursuant to Section 1798.185 to carry out the purposes and provisions of the California Consumer Privacy Act of 2018, including regulations specifying recordkeeping requirements for businesses to ensure compliance with this title. (c) Through the implementation of this title, protect the fundamental privacy rights of natural persons with respect to the use of their personal information. (d) Promote public awareness and understanding of the risks, rules, responsibilities, safeguards, and rights in relation to the collection, use, sale, and disclosure of personal information, including the rights of minors with respect to their own information, and provide a public report summarizing the risk assessments filed with the agency pursuant to paragraph (14) of subdivision (a) of Section 1798.185 while ensuring that data security is not compromised. (e) Provide guidance to consumers regarding their rights under this title. (f) Provide guidance to businesses regarding their duties and responsibilities under this title and appoint a Chief Privacy Auditor to conduct audits of businesses to ensure compliance with this title pursuant to regulations adopted pursuant to paragraph (17) of subdivision (a) of Section 1798.185.\n",
            "\n",
            "\n",
            "(g) Provide technical assistance and advice to the Legislature, upon request, with respect to privacy-related legislation. (h) Monitor relevant developments relating to the protection of personal information and, in particular, the development of information and communication technologies and commercial practices. (i) Cooperate with other agencies with jurisdiction over privacy laws and with data processing authorities in California, other states, territories, and countries to ensure consistent application of privacy protections. (j) Establish a mechanism pursuant to which persons doing business in California that do not meet the definition of business set forth in paragraph (1), (2), or (3) of subdivision (d) of Section 1798.140 may voluntarily certify that they are in compliance with this title, as set forth in paragraph (4) of subdivision (d) of Section 1798.140, and make a list of those entities available to the public. (k) Solicit, review, and approve applications for grants to the extent funds are available pursuant to paragraph (2) of subdivision (b) of Section 1798.160. (l) Perform all other acts necessary or appropriate in the exercise of its power, authority, and jurisdiction and seek to balance the goals of strengthening consumer privacy while giving attention to the impact on businesses. (Amended by Stats. 2024, Ch. 121, Sec. 11. (AB 3286) Effective January 1, 2025.) 1798.199.45.\n",
            "\n",
            "\n",
            "Any covered entity may condition compliance with a confidential communication request on the individual specifying an alternative address or method of contact and explaining how any payment will be handled. OCR Privacy Rule Summary 14 Last Revised 05/03 Administrative Requirements HHS recognizes that covered entities range from the smallest provider to the largest, multi-state health plan. Therefore the flexibility and scalability of the Rule are intended to allow covered entities to analyze their own needs and implement solutions appropriate for their own environment. What is appropriate for a particular covered entity will depend on the nature of the covered entity’s business, as well as the covered entity’s size and resources. Privacy Policies and Procedures. A covered entity must develop and implement written privacy policies and procedures that are consistent with the Privacy Rule.64 Privacy Personnel. A covered entity must designate a privacy official responsible for developing and implementing its privacy policies and procedures, and a contact person or contact office responsible for receiving complaints and providing individuals with information on the covered entity’s privacy practices.65 Workforce Training and Management.\n",
            "\n",
            "\n",
            "The Development of Privacy Protection in the United States: A Sectoral Approach The United States has historically taken a markedly different approach to privacy protection compared to Europe, developing a patchwork of sector-specific laws rather than comprehensive federal legislation. This sectoral approach reflects American values of free market economics and limited government intervention. Early Privacy Developments (1960s-1970s): The Fair Credit Reporting Act of 1970 was one of the first federal laws addressing privacy concerns, focusing specifically on the collection and use of consumer credit information. This law established important principles including: - Consumer right to access their credit reports - Requirement for accurate reporting - Time limits on negative information - Procedures for disputing incorrect information The Privacy Act of 1974 represented another significant step, though limited to government agencies. It established: - Rules for government collection and use of personal data - Individual rights to access and correct records - Restrictions on sharing between agencies - Civil and criminal penalties for violations The Evolution of Sectoral Privacy Laws: Different industries received specific privacy regulations over time: Healthcare: The Health Insurance Portability and Accountability Act (HIPAA) of 1996 created comprehensive privacy rules for medical information, including: - Patient rights to access medical records -\n",
            "\n",
            "\n",
            "Restrictions on information sharing - Security requirements for health data - Breach notification requirements - Substantial penalties for violations Financial Services: The Gramm-Leach-Bliley Act of 1999 established privacy rules for financial institutions: - Required privacy notices to customers - Opt-out rights for information sharing - Security standards for financial data - State enforcement mechanisms Children's Privacy: The Children's Online Privacy Protection Act (COPPA) of 1998 specifically addressed children's privacy online: - Parental consent requirements - Restrictions on data collection from children under 13 - Requirements for privacy policies - Limits on marketing to children Education: The Family Educational Rights and Privacy Act (FERPA) protects student education records: - Parent/student rights to access records - Limitations on disclosure without consent - Requirements for schools' privacy practices The Digital Age and New Challenges: The rise of internet companies in the 1990s and 2000s exposed gaps in U.S. privacy protection. The Federal Trade Commission (FTC) became the de facto privacy regulator, using its authority to: - Enforce company privacy promises - Investigate data breaches - Issue privacy guidelines - Impose fines for privacy violations Notable FTC actions included: - 2011 Facebook settlement requiring privacy audits - 2012 Google privacy violation fine ($22.5 million) -\n",
            "\n",
            "\n",
            "2019 Facebook fine ($5 billion) for privacy violations State-Level Innovation: In the absence of comprehensive federal legislation, states have taken the lead: California's Leadership: - 2003 Security Breach Notification Law (first in the nation) - 2018 California Consumer Privacy Act (CCPA) - 2020 California Privacy Rights Act (CPRA) These laws have influenced other states and national privacy discussions. Recent Developments: - Growing number of state privacy laws (Virginia, Colorado, Utah) - Increased focus on biometric privacy protection - Emerging regulations for artificial intelligence - Ongoing debates about federal privacy legislation The U.S. approach continues to evolve, with calls for comprehensive federal privacy legislation growing stronger. However, the sectoral approach remains deeply embedded in the American legal framework, creating ongoing challenges for businesses operating across state lines and internationally.\n",
            "\n",
            "\n",
            "Annotated Text of the California Privacy Rights Act (As Approved by Voters, Including Changes from the CCPA) Below is annotated text of the California Privacy Rights Act (CPRA) of 2020. This text is what was approved by voters with the passage of Proposition 24 that includes changes from the text of the California Consumer Privacy Act (CCPA). Annotations can be viewed on a PC or Mac by hovering over highlighted blue text or by tapping highlighted blue text on a mobile device. This Resource Center includes other versions of the text of the CPRA: Annotated text of the CPRA as approved by voters, including changes from the CCPA (this page) Unannotated text of the CPRA as approved by voters, including changes from the CCPA Annotated text of the CPRA with no changes from the CCPA Unannotated text of the CPRA with no changes from the CCPA Proposition 24 This initiative measure is submitted to the people in accordance with the provisions of Section 8 of Article II of the California Constitution. This initiative measure amends and adds sections to the Civil Code; therefore, existing provisions proposed to be deleted are printed in strikeout type and new provisions proposed to be added are printed in italic type to indicate that they are new.\n",
            "\n",
            "\n",
            "Proposed Law The California Privacy Rights Act of 2020 Section 0.5: Table of Contents Section 1: Title: The California Privacy Rights Act of 2020 Section 2: Findings and Declarations Section 3: Purpose and Intent (A) Consumer Rights (B) Responsibilities of Businesses (C) Implementation of the Law Section 4: General Duties of Businesses that Collect Personal Information Section 5: Consumers’ Right to Delete Personal Information Section 6: Consumers’ Right to Correct Inaccurate Personal Information Section 7: Consumers’ Right to Know What Personal Information is Being Collected.\n",
            "\n",
            "\n",
            "Right to Access Personal Information Section 8: Consumers’ Right to Know What Personal Information is Sold or shared and to Whom Section 9: Consumers’ Right to Opt Out of Sale or sharing of Personal Information Section 10: Consumers’ Right to Limit Use and Disclosure of Sensitive Personal Information Section 11: Consumers’ Right of No Retaliation Following Opt Out or Exercise of Other Rights Section 12: Notice, Disclosure, Correction, and Deletion Requirements Section 13: Methods of Limiting Sale, Sharing, and Use of Personal Information and Use of Sensitive Personal Information Section 14: Definitions Section 15: Exemptions Section 16: Personal Information Security Breaches Section 17: Administrative Enforcement Section 18: Consumer Privacy Fund Section 19: Conflicting Provisions Section 20: Preemption Section 21: Regulations Section 22: Anti-Avoidance Section 23: Waiver Section 24: Establishment of California Privacy Protection Agency Section 25: Amendment Section 26: Severability Section 27: Conflicting Initiatives Section 28: Standing Section 29: Construction Section 30: Savings Clause Section 31: Effective and Operative Dates SEC. 1. Title. This measure shall be known, and may be cited, as the “California Privacy Rights Act of 2020.” SEC. 2. Findings and Declarations.\n",
            "\n",
            "\n",
            "The people of the State of California hereby find and declare all of the following: (A) In 1972, California voters amended the California Constitution to include the right of privacy among the “inalienable” rights of all people. Voters acted in response to the accelerating encroachment on personal freedom and security caused by increased data collection and usage in contemporary society. The amendment established a legal and enforceable constitutional right of privacy for every Californian. Fundamental to this right of privacy is the ability of individuals to control the use, including the sale, of their personal information. (B) Since California voters approved the constitutional right of privacy, the California Legislature has adopted specific mechanisms to safeguard Californians’ privacy, including the Online Privacy Protection Act, the Privacy Rights for California Minors in the Digital World Act, and Shine the Light, but consumers had no right to learn what personal information a business had collected about them and how they used it or to direct businesses not to sell the consumer’s personal information. (C) That changed in 2018, when more than 629,000 California voters signed petitions to qualify the California Consumer Privacy Act of 2018 for the ballot. In response to the measure’s qualification, the Legislature enacted the California Consumer Privacy Act of 2018 (CCPA) into law.\n",
            "\n",
            "\n",
            "The CCPA gives California consumers the right to learn what information a business has collected about them, to delete their personal information, to stop businesses from selling their personal information, including using it to target them with ads that follow them as they browse the internet from one website to another, and to hold businesses accountable if they do not take reasonable steps to safeguard their personal information. (D) Even before the CCPA had gone into effect, the Legislature considered many bills in 2019 to amend the law, some of which would have significantly weakened it. Unless California voters take action, the hard-fought rights consumers have won could be undermined by future legislation. (E) Rather than diluting privacy rights, California should strengthen them over time. Many businesses collect and use consumers’ personal information, sometimes without consumers’ knowledge regarding the business’s use and retention of their personal information. In practice, consumers are often entering into a form of contractual arrangement in which, while they do not pay money for a good or service, they exchange access to that good or service in return for access to their attention or access to their personal information. Because the value of the personal information they are exchanging for the good or service is often opaque, depending on the practices of the business, consumers often have no good way to value the transaction.\n",
            "\n",
            "\n",
            "In enacting this Act, it is the purpose and intent of the people of the State of California to further protect consumers’ rights, including the constitutional right of privacy. The implementation of this Act shall be guided by the following principles: (A) Consumer Rights (1) Consumers should know who is collecting their personal information and that of their children, how it is being used, and to whom it is disclosed so that they have the information necessary to exercise meaningful control over businesses’ use of their personal information and that of their children. (2) Consumers should be able to control the use of their personal information, including limiting the use of their sensitive personal information, the unauthorized use or disclosure of which creates a heightened risk of harm to the consumer, and they should have meaningful options over how it is collected, used, and disclosed. (3) Consumers should have access to their personal information and should be able to correct it, delete it, and take it with them from one business to another. (4) Consumers or their authorized agents should be able to exercise these options through easily accessible self-serve tools. (5) Consumers should be able to exercise these rights without being penalized for doing so. (6) Consumers should be able to hold businesses accountable for failing to take reasonable precautions to protect their most sensitive personal information from hackers and security breaches.\n",
            "\n",
            "\n",
            "(5) Comply with the California Electronic Communications Privacy Act pursuant to Chapter 3.6 (commencing with Section 1546) of Title 12 of Part 2 of the Penal Code. (6) Engage in public or peer reviewed scientific, historical, or statistical research in the public interest that conforms or adheres to all other applicable ethics and privacy laws, when the business’s deletion of the information is likely to render impossible or seriously impair the achievement of ability to complete such research, if the consumer has provided informed consent. (7) To enable solely internal uses that are reasonably aligned with the expectations of the consumer based on the consumer’s relationship with the business and compatible with the context in which the consumer provided the information. (8) Comply with a legal obligation. (9) Otherwise use the consumer’s personal information, internally, in a lawful manner that is compatible with the context in which the consumer provided the information. SEC. 6. Section 1798.106 is added to the Civil Code, to read: 1798.106. Consumers’ Right to Correct Inaccurate Personal Information (a) A consumer shall have the right to request a business that maintains inaccurate personal information about the consumer correct such inaccurate personal information, taking into account the nature of the personal information and the purposes of the processing of the personal information.\n",
            "\n",
            "\n",
            "(C) Identify by category or categories the personal information of the consumer that the business disclosed for a business purpose in the preceding 12 monthsduring the applicable period of time by reference to the enumerated category or categories in subdivision (c) that most closely describes the personal information, and provide the categories of third parties persons to whom the consumer’s personal information was disclosed for a business purpose in the preceding 12 months during the applicable period of time by reference to the enumerated category or categories in subdivision (c) that most closely describes the personal information disclosed. The business shall disclose the information in a list that is separate from a list generated for the purposes of subparagraph (B). (5) Disclose the following information in its online privacy policy or policies if the business has an online privacy policy or policies and in any California‐specific description of consumers’ privacy rights, or if the business does not maintain those policies, on its internet website, and update that information at least once every 12 months: (A) A description of a consumer’s rights pursuant to Sections 1798.100, 1798.105, 1798.106, 1798.110, 1798.115, and 1798.125 and one two or more designated methods for submitting requests, except as provided in subparagraph (A) of paragraph (1) of subdivision (a).\n",
            "\n",
            "\n",
            "(c) A business that is subject to this section shall: (1) not Not require a consumer to create an account or provide additional information beyond what is necessary in order to direct the business not to sell or share the consumer’s personal information or to limit use or disclosure of the consumer’s sensitive personal information (2) Include a description of a consumer’s rights pursuant to Section Sections 1798.120 and 1798.121, along with a separate link to the “Do Not Sell or share My Personal Information” Internet Web page internet web page and a separate link to the “Limit the Use of My Sensitive Personal Information” internet web page, if applicable, or a single link to both choices, or a statement that the business responds to and abides by opt-out preference signals sent by a platform, technology, or mechanism in accordance with subdivision (b), in: (A) Its online privacy policy or policies if the business has an online privacy policy or policies. (B) Any California-specific description of consumers’ privacy rights. (3) Ensure that all individuals responsible for handling consumer inquiries about the business’s privacy practices or the business’s compliance with this title are informed of all requirements in Section Sections 1798.120, 1798.121, and this section and how to direct consumers to exercise their rights under those sections.\n",
            "\n",
            "\n",
            "(D) Combining the personal information that the service provider receives from, or on behalf of, the business with personal information that it receives from, or on behalf of, another person or persons, or collects from its own interaction with the consumer, provided that the service provider may combine personal information to perform any business purpose as defined in regulations adopted pursuant to paragraph (10) of subdivision (a) of Section 1798.185, except as provided for in paragraph (6) of subdivision (e) of this section and in regulations adopted by the California Privacy Protection Agency. The contract may, subject to agreement with the service provider, permit the business to monitor the service provider’s compliance with the contract through measures, including, but not limited to, ongoing manual reviews and automated scans and regular assessments, audits, or other technical and operational testing at least once every 12 months. (2) If a service provider engages any other person to assist it in processing personal information for a business purpose on behalf of the business, or if any other person engaged by the service provider engages another person to assist in processing personal information for that business purpose, it shall notify the business of that engagement, and the engagement shall be pursuant to a written contract binding the other person to observe all the requirements set forth in paragraph (1). (ah) (1) “Share,” “shared,” or “sharing“.\n",
            "\n",
            "\n",
            "(4) Cooperate with a government agency request for emergency access to a consumer’s personal information if a natural person is at risk or danger of death or serious physical injury provided that: (A) The request is approved by a high-ranking agency officer for emergency access to a consumer’s personal information. (B) The request is based on the agency’s good faith determination that it has a lawful basis to access the information on a nonemergency basis. (C) The agency agrees to petition a court for an appropriate order within three days and to destroy the information if that order is not granted. (4) (5) Exercise or defend legal claims. (5) (6) Collect, use, retain, sell, share, or disclose consumer consumers’ personal information that is deidentified or in the aggregate consumer information. (6) (7) Collect, or sell, or share a consumer’s personal information if every aspect of that commercial conduct takes place wholly outside of California. For purposes of this title, commercial conduct takes place wholly outside of California if the business collected that information while the consumer was outside of California, no part of the sale of the consumer’s personal information occurred in California, and no personal information collected while the consumer was in California is sold.\n",
            "\n",
            "\n",
            "This paragraph shall not permit prohibit a business from storing, including on a device, personal information about a consumer when the consumer is in California and then collecting that personal information when the consumer and stored personal information is outside of California. (b) The obligations imposed on businesses by Sections 1798.110, 1798.115, 1798.120, 1798.121, 1798.130, and to 1798.135, inclusive, shall not apply where compliance by the business with the title would violate an evidentiary privilege under California law and shall not prevent a business from providing the personal information of a consumer to a person covered by an evidentiary privilege under California law as part of a privileged communication.\n",
            "\n",
            "\n",
            "Any business, service provider, contractor, or other person that violates this title shall be subject to an injunction and liable for an administrative fine of not more than two thousand five hundred dollars ($2,500) for each violation or seven thousand five hundred dollars ($7,500) for each intentional violation or violations involving the personal information of consumers whom the business, service provider, contractor, or other person has actual knowledge are under 16 years of age, as adjusted pursuant to paragraph (5) of subdivision (a) of Section 1798.185, in an administrative enforcement action brought by the California Privacy Protection Agency. a civil penalty of not more than two thousand five hundred dollars ($2,500) for each violation or seven thousand five hundred dollars ($7,500) for each intentional violation, which shall be assessed and recovered in a civil action brought in the name of the people of the State of California by the Attorney General. The civil penalties provided for in this section shall be exclusively assessed and recovered in a civil action brought in the name of the people of the State of California by the Attorney General.\n",
            "\n",
            "\n",
            "(b) Any civil penalty administrative fine assessed for a violation of this title, and the proceeds of any settlement of an action brought pursuant to subdivision (b) (a), shall be deposited in the Consumer Privacy Fund, created within the General Fund pursuant to subdivision (a) of Section 1798.160 with the intent to fully offset any costs incurred by the state courts, and the Attorney General, and the California Privacy Protection Agency in connection with this title. SEC. 18. Section 1798.160 of the Civil Code is amended to read: 1798.160. Consumer Privacy Fund 1798.160 (a) A special fund to be known as the “Consumer Privacy Fund” is hereby created within the General Fund in the State Treasury, and is available upon appropriation by the Legislature first to offset any costs incurred by the state courts in connection with actions brought to enforce this title, and any the costs incurred by the Attorney General in carrying out the Attorney General’s duties under this title, and then for the purposes of establishing an investment fund in the State Treasury, with any earnings or interest from the fund to be deposited in the General Fund, and making grants to promote and protect consumer privacy, educate children in the area of online privacy, and fund cooperative programs with international law enforcement organizations to combat fraudulent activities with respect to consumer data breaches.\n",
            "\n",
            "\n",
            "(b) Funds transferred to the Consumer Privacy Fund shall be used exclusively as follows: (1) to To offset any costs incurred by the state courts and the Attorney General in connection with this title. (2) After satisfying the obligations under paragraph (1), the remaining funds shall be allocated each fiscal year as follows: (A) Ninety-one percent shall be invested by the Treasurer in financial assets with the goal of maximizing long term yields consistent with a prudent level of risk. The principal shall not be subject to transfer or appropriation, provided that any interest and earnings shall be transferred on an annual basis to the General Fund for appropriation by the Legislature for General Fund purposes. (B) Nine percent shall be made available to the California Privacy Protection Agency for the purposes of making grants in California, with 3 percent allocated to each of the following grant recipients: (i) Nonprofit organizations to promote and protect consumer privacy. (ii) Nonprofit organizations and public agencies, including school districts, to educate children in the area of online privacy. (iii) State and local law enforcement agencies to fund cooperative programs with international law enforcement organizations to combat fraudulent activities with respect to consumer data breaches. (c) These funds Funds in the Consumer Privacy Fund shall not be subject to appropriation or transfer by the Legislature for any other purpose.\n",
            "\n",
            "\n",
            "(15) Issuing regulations requiring businesses whose processing of consumers’ personal information presents significant risk to consumers’ privacy or security, to: (A) Perform a cybersecurity audit on an annual basis, including defining the scope of the audit and establishing a process to ensure that audits are thorough and independent. The factors to be considered in determining when processing may result in significant risk to the security of personal information shall include the size and complexity of the business and the nature and scope of processing activities. (B) Submit to the California Privacy Protection Agency on a regular basis a risk assessment with respect to their processing of personal information, including whether the processing involves sensitive personal information, and identifying and weighing the benefits resulting from the processing to the business, the consumer, other stakeholders, and the public, against the potential risks to the rights of the consumer associated with that processing, with the goal of restricting or prohibiting the processing if the risks to privacy of the consumer outweigh the benefits resulting from processing to the consumer, the business, other stakeholders, and the public. Nothing in this section shall require a business to divulge trade secrets.\n",
            "\n",
            "\n",
            "(c) The Attorney General shall not bring an enforcement action under this title until six months after the publication of the final regulations issued pursuant to this section or July 1, 2020, whichever is sooner. (d) Notwithstanding subdivision (a), the timeline for adopting final regulations required by the act adding this subdivision shall be July 1, 2022. Beginning the later of July 1, 2021, or six months after the agency provides notice to the Attorney General that it is prepared to begin rulemaking under this title, the authority assigned to the Attorney General to adopt regulations under this section shall be exercised by the California Privacy Protection Agency. Notwithstanding any other law, civil and administrative enforcement of the provisions of law added or amended by this act shall not commence until July 1, 2023, and shall only apply to violations occurring on or after that date. Enforcement of provisions of law contained in the California Consumer Privacy Act of 2018 amended by this act shall remain in effect and shall be enforceable until the same provisions of this act become enforceable. SEC. 22. Section 1798.190 of the Civil Code is amended to read: 1798.190. Anti-Avoidance 1798.190.\n",
            "\n",
            "\n",
            "This section shall not prevent a consumer from declining to request information from a business, declining to opt-out opt out of a business’s sale of the consumer’s personal information, or authorizing a business to sell or share the consumer’s personal information after previously opting out. SEC. 24. Establishment of California Privacy Protection Agency. SEC. 24.1. Section 1798.199.10 is added to the Civil Code, to read: 1798.199.10. (a) There is hereby established in state government the California Privacy Protection Agency, which is vested with full administrative power, authority, and jurisdiction to implement and enforce the California Consumer Privacy Act of 2018. The agency shall be governed by a five-member board, including the chairperson. The chairperson and one member of the board shall be appointed by the Governor. The Attorney General, Senate Rules Committee, and Speaker of the Assembly shall each appoint one member. These appointments should be made from among Californians with expertise in the areas of privacy, technology, and consumer rights. (b) The initial appointments to the agency shall be made within 90 days of the effective date of the act adding this section. SEC. 24.2. Section 1798.199.15 is added to the Civil Code, to read: 1798.199.15. Members of the agency board shall: (a) Have qualifications, experience, and skills, in particular in the areas of privacy and technology, required to perform the duties of the agency and exercise its powers.\n",
            "\n",
            "\n",
            "(b) On and after the earlier of July 1, 2021, or within six months of the agency providing the Attorney General with notice that it is prepared to assume rulemaking responsibilities under this title, adopt, amend, and rescind regulations pursuant to Section 1798.185 to carry out the purposes and provisions of the California Consumer Privacy Act of 2018, including regulations specifying record keeping requirements for businesses to ensure compliance with this title. (c) Through the implementation of this title, protect the fundamental privacy rights of natural persons with respect to the use of their personal information. (d) Promote public awareness and understanding of the risks, rules, responsibilities, safeguards, and rights in relation to the collection, use, sale, and disclosure of personal information, including the rights of minors with respect to their own information, and provide a public report summarizing the risk assessments filed with the agency pursuant to paragraph (15) of subdivision (a) of Section 1798.185 while ensuring that data security is not compromised. (e) Provide guidance to consumers regarding their rights under this title. (f) Provide guidance to businesses regarding their duties and responsibilities under this title and appoint a Chief Privacy Auditor to conduct audits of businesses to ensure compliance with this title pursuant to regulations adopted pursuant to paragraph (18) of subdivision (a) of Section 1798.185.\n",
            "\n",
            "\n",
            "(g) Provide technical assistance and advice to the Legislature, upon request, with respect to privacy-related legislation. (h) Monitor relevant developments relating to the protection of personal information and in particular, the development of information and communication technologies and commercial practices. (i) Cooperate with other agencies with jurisdiction over privacy laws and with data processing authorities in California, other states, territories, and countries to ensure consistent application of privacy protections. (j) Establish a mechanism pursuant to which persons doing business in California that do not meet the definition of business set forth in paragraph (1), (2), or (3) of subdivision (d) of Section 1798.140 may voluntarily certify that they are in compliance with this title, as set forth in paragraph (4) of subdivision (d) of Section 1798.140, and make a list of those entities available to the public. (k) Solicit, review, and approve applications for grants to the extent funds are available pursuant to paragraph (2) of subdivision (b) of Section 1798.160. (l) Perform all other acts necessary or appropriate in the exercise of its power, authority, and jurisdiction and seek to balance the goals of strengthening consumer privacy while giving attention to the impact on businesses. SEC. 24.8. Section 1798.199.45 is added to the Civil Code, to read: 1798.199.45.\n",
            "\n",
            "\n",
            "(a) The provisions of this act may be amended after its approval by the voters by a statute that is passed by a vote of a majority of the members of each house of the Legislature and signed by the Governor, provided that those amendments are consistent with and further the purpose and intent of this act as set forth in Section 3, including amendments to the exemptions in Section 1798.145 if the laws upon which the exemptions are based are amended to enhance privacy and are consistent with and further the purposes and intent of this act and amendments to address a decision of a state or federal court holding that a provision of the act is unconstitutional or preempted by federal law, provided that any further amendments to legislation that addresses a court holding shall be subject to this subdivision. (b) Notwithstanding Section 1798.199.25, the Legislature may authorize additional compensation for members of the California Consumer Privacy Agency, if it determines that it is necessary to carry out the agency’s functions, by a statute that is passed by a vote of a majority of the members of each house of the Legislature and signed by the Governor. (c) This section applies to all statutes amended or reenacted as part of this act, and all provisions of those statutes, regardless of whether this act makes any substantive change thereto. (d) The provisions of this act shall prevail over any conflicting legislation enacted after January 1, 2020.\n",
            "\n",
            "\n",
            "This act shall be liberally construed to effectuate its purposes. SEC. 30. Savings Clause. This act is intended to supplement federal and state law, where permissible, but shall not apply if that application is preempted by, or in conflict with, federal law, or the California Constitution. The provisions of the act relating to children under 16 years of age shall only apply to the extent not in conflict with the federal Children’s Online Privacy Protection Act. SEC. 31. Effective and Operative Dates. (a) This act shall become effective as provided in subdivision (a) of Section 10 of Article II of the California Constitution. Except as provided in subdivision (b), this act shall become operative January 1, 2023, and with the exception of the right of access, shall only apply to personal information collected by a business on or after January 1, 2022. (b) Subdivisions (m) and (n) of Section 1798.145, Sections 1798.160, 1798.185, Sections 1798.199.10 through 1798.199.40, inclusive, and Section 1798.199.95 shall become operative on the effective date of the act. (c) The provisions of the California Consumer Privacy Act of 2018, amended by this act, shall remain in full force and effect and shall be enforceable until the same provisions of this act become operative and enforceable.\n",
            "\n",
            "\n",
            "Query: Who is covered by privacy protection?\n",
            "Similar Sentences:\n",
            "(2) Include a description of a consumer’s rights pursuant to Sections 1798.120 and 1798.121, along with a separate link to the “Do Not Sell or Share My Personal Information” internet web page and a separate link to the “Limit the Use of My Sensitive Personal Information” internet web page, if applicable, or a single link to both choices, or a statement that the business responds to and abides by opt-out preference signals sent by a platform, technology, or mechanism in accordance with subdivision (b), in: (A) Its online privacy policy or policies if the business has an online privacy policy or policies. (B) Any California-specific description of consumers’ privacy rights. (3) Ensure that all individuals responsible for handling consumer inquiries about the business’ privacy practices or the business’ compliance with this title are informed of all requirements in Sections 1798.120, 1798.121, and this section and how to direct consumers to exercise their rights under those sections.\n",
            "\n",
            "\n",
            "(14) Issuing regulations requiring businesses whose processing of consumers’ personal information presents significant risk to consumers’ privacy or security, to: (A) Perform a cybersecurity audit on an annual basis, including defining the scope of the audit and establishing a process to ensure that audits are thorough and independent. The factors to be considered in determining when processing may result in significant risk to the security of personal information shall include the size and complexity of the business and the nature and scope of processing activities. (B) Submit to the California Privacy Protection Agency on a regular basis a risk assessment with respect to their processing of personal information, including whether the processing involves sensitive personal information, and identifying and weighing the benefits resulting from the processing to the business, the consumer, other stakeholders, and the public, against the potential risks to the rights of the consumer associated with that processing, with the goal of restricting or prohibiting the processing if the risks to privacy of the consumer outweigh the benefits resulting from processing to the consumer, the business, other stakeholders, and the public. Nothing in this section shall require a business to divulge trade secrets.\n",
            "\n",
            "\n",
            "(b) On and after the later of July 1, 2021, or within six months of the agency providing the Attorney General with notice that it is prepared to assume rulemaking responsibilities under this title, adopt, amend, and rescind regulations pursuant to Section 1798.185 to carry out the purposes and provisions of the California Consumer Privacy Act of 2018, including regulations specifying recordkeeping requirements for businesses to ensure compliance with this title. (c) Through the implementation of this title, protect the fundamental privacy rights of natural persons with respect to the use of their personal information. (d) Promote public awareness and understanding of the risks, rules, responsibilities, safeguards, and rights in relation to the collection, use, sale, and disclosure of personal information, including the rights of minors with respect to their own information, and provide a public report summarizing the risk assessments filed with the agency pursuant to paragraph (14) of subdivision (a) of Section 1798.185 while ensuring that data security is not compromised. (e) Provide guidance to consumers regarding their rights under this title. (f) Provide guidance to businesses regarding their duties and responsibilities under this title and appoint a Chief Privacy Auditor to conduct audits of businesses to ensure compliance with this title pursuant to regulations adopted pursuant to paragraph (17) of subdivision (a) of Section 1798.185.\n",
            "\n",
            "\n",
            "(g) Provide technical assistance and advice to the Legislature, upon request, with respect to privacy-related legislation. (h) Monitor relevant developments relating to the protection of personal information and, in particular, the development of information and communication technologies and commercial practices. (i) Cooperate with other agencies with jurisdiction over privacy laws and with data processing authorities in California, other states, territories, and countries to ensure consistent application of privacy protections. (j) Establish a mechanism pursuant to which persons doing business in California that do not meet the definition of business set forth in paragraph (1), (2), or (3) of subdivision (d) of Section 1798.140 may voluntarily certify that they are in compliance with this title, as set forth in paragraph (4) of subdivision (d) of Section 1798.140, and make a list of those entities available to the public. (k) Solicit, review, and approve applications for grants to the extent funds are available pursuant to paragraph (2) of subdivision (b) of Section 1798.160. (l) Perform all other acts necessary or appropriate in the exercise of its power, authority, and jurisdiction and seek to balance the goals of strengthening consumer privacy while giving attention to the impact on businesses. (Amended by Stats. 2024, Ch. 121, Sec. 11. (AB 3286) Effective January 1, 2025.) 1798.199.45.\n",
            "\n",
            "\n",
            "The scale of the collection and sharing of personal data has increased significantly. Technology allows both private companies and public authorities to make use of personal data on an unprecedented scale in order to pursue their activities. Natural persons increasingly make personal information available publicly and globally. Technology has transformed both the economy and social life, and should further facilitate the free flow of personal data within the Union and the transfer to third countries and international organisations, while ensuring a high level of the protection of personal data. (7) Those developments require a strong and more coherent data protection framework in the Union, backed by strong enforcement, given the importance of creating the trust that will allow the digital economy to develop across the internal market. Natural persons should have control of their own personal data. Legal and practical certainty for natural persons, economic operators and public authorities should be enhanced. (8) Where this Regulation provides for specifications or restrictions of its rules by Member State law, Member States may, as far as necessary for coherence and for making the national provisions comprehensible to the persons to whom they apply, incorporate elements of this Regulation into their national law.\n",
            "\n",
            "\n",
            "In such cases the controller shall take appropriate measures to protect the data subject's rights and freedoms and legitimate interests, including making the information publicly available; (c) obtaining or disclosure is expressly laid down by Union or Member State law to which the controller is subject and which provides appropriate measures to protect the data subject's legitimate interests; or (d) where the personal data must remain confidential subject to an obligation of professional secrecy regulated by Union or Member State law, including a statutory obligation of secrecy.\n",
            "\n",
            "\n",
            "1 The Privacy Rule standards address the use and disclosure of individuals’ health information—called “protected health information” by organizations subject to the Privacy Rule — called “covered entities,” as well as standards for individuals' privacy rights to understand and control how their health information is used. Within HHS, the Office for Civil Rights (“OCR”) has responsibility for implementing and enforcing the Privacy Rule with respect to voluntary compliance activities and civil money penalties. A major goal of the Privacy Rule is to assure that individuals’ health information is properly protected while allowing the flow of health information needed to provide and promote high quality health care and to protect the public's health and well being. The Rule strikes a balance that permits important uses of information, while protecting the privacy of people who seek care and healing. Given that the health care marketplace is diverse, the Rule is designed to be flexible and comprehensive to cover the variety of uses and disclosures that need to be addressed. This is a summary of key elements of the Privacy Rule and not a complete or comprehensive guide to compliance. Entities regulated by the Rule are obligated to comply with all of its applicable requirements and should not rely on this summary as a source of legal information or advice.\n",
            "\n",
            "\n",
            "There are two ways to de-identify information; either: 1) a formal determination by a qualified statistician; or 2) the removal of specified identifiers of the individual and of the individual’s relatives, household members, and employers is required, and is adequate only if the covered entity has no actual knowledge that the remaining information could be used to identify the individual.15 General Principle for Uses and Disclosures Basic Principle. A major purpose of the Privacy Rule is to define and limit the circumstances in which an individual’s protected heath information may be used or disclosed by covered entities. A covered entity may not use or disclose protected health information, except either: (1) as the Privacy Rule permits or requires; or (2) as the individual who is the subject of the information (or the individual’s personal representative) authorizes in writing.16 Required Disclosures. A covered entity must disclose protected health information in only two situations: (a) to individuals (or their personal representatives) specifically when they request access to, or an accounting of disclosures of, their protected health information; and (b) to HHS when it is undertaking a compliance investigation or review or enforcement action.17 See OCR “Government Access” Guidance. Permitted Uses and Disclosures Permitted Uses and Disclosures.\n",
            "\n",
            "\n",
            "A covered entity is permitted, but not required, to use and disclose protected health information, without an individual’s authorization, for the following purposes or situations: (1) To the Individual (unless required for access or accounting of disclosures); (2) Treatment, Payment, and Health Care Operations; (3) Opportunity to Agree or Object; (4) Incident to an otherwise permitted use and disclosure; (5) Public Interest and Benefit Activities; and OCR Privacy Rule Summary 5 Last Revised 05/03 (6) Limited Data Set for the purposes of research, public health or health care operations.18 Covered entities may rely on professional ethics and best judgments in deciding which of these permissive uses and disclosures to make. (1) To the Individual. A covered entity may disclose protected health information to the individual who is the subject of the information. (2) Treatment, Payment, Health Care Operations.\n",
            "\n",
            "\n",
            "26 This provision, for example, allows a pharmacist to dispense filled prescriptions to a person acting on behalf of the patient. Similarly, a covered entity may rely on an individual’s informal permission to use or disclose protected health information for the purpose of notifying (including identifying or locating) family members, personal representatives, or others responsible for the individual’s care of the individual’s location, general condition, or death. In addition, protected health information may be disclosed for notification purposes to public or private entities authorized by law or charter to assist in disaster relief efforts. (4) Incidental Use and Disclosure. The Privacy Rule does not require that every risk of an incidental use or disclosure of protected health information be eliminated. A use or disclosure of this information that occurs as a result of, or as “incident to,” an otherwise permitted use or disclosure is permitted as long as the covered entity has adopted reasonable safeguards as required by the Privacy Rule, and the information being shared was limited to the “minimum necessary,” as required by the Privacy Rule.27 See OCR “Incidental Uses and Disclosures” Guidance. (5) Public Interest and Benefit Activities.\n",
            "\n",
            "\n",
            "The Privacy Rule permits use and disclosure of protected health information, without an individual’s authorization or permission, for 12 national priority purposes.28 These disclosures are permitted, although not required, by the Rule in recognition of the important uses made of health information outside of the health care context. Specific conditions or limitations apply to each public interest purpose, striking the balance between the individual privacy interest and the public interest need for this information. Required by Law. Covered entities may use and disclose protected health information without individual authorization as required by law (including by OCR Privacy Rule Summary 7 Last Revised 05/03 statute, regulation, or court orders).29 Public Health Activities.\n",
            "\n",
            "\n",
            "Covered entities may disclose protected health information to health oversight agencies (as defined in the Rule) for purposes of legally authorized health oversight activities, such as audits and investigations necessary for oversight of the health care system and government benefit programs.32 Judicial and Administrative Proceedings. Covered entities may disclose protected health information in a judicial or administrative proceeding if the request for the information is through an order from a court or administrative tribunal. Such information may also be disclosed in response to a subpoena or other lawful process if certain assurances regarding notice to the individual or a protective order are provided.33 Law Enforcement Purposes.\n",
            "\n",
            "\n",
            "Covered entities may disclose protected health information to law enforcement officials for law enforcement purposes under the following six circumstances, and subject to specified conditions: (1) as required by law (including court orders, court-ordered warrants, subpoenas) and administrative requests; (2) to identify or locate a suspect, fugitive, material witness, or missing person; (3) in response to a law enforcement official’s request for information about a victim or suspected victim of a crime; (4) to alert law enforcement of a person’s death, if the covered entity suspects that criminal activity caused the death; (5) when a covered entity believes that protected health information is evidence of a crime that occurred on its premises; and (6) by a covered health care provider in a medical emergency not occurring on its premises, when necessary to inform law enforcement about the commission and nature of a crime, the location of the crime or crime victims, and the perpetrator of the crime.34 OCR Privacy Rule Summary 8 Last Revised 05/03 Decedents. Covered entities may disclose protected health information to funeral directors as needed, and to coroners or medical examiners to identify a deceased person, determine the cause of death, and perform other functions authorized by law.35 Cadaveric Organ, Eye, or Tissue Donation.\n",
            "\n",
            "\n",
            "The minimum necessary requirement is not imposed in any of the following circumstances: (a) disclosure to or a request by a health care provider for treatment; (b) disclosure to an individual who is the subject of the information, or the individual’s personal representative; (c) use or disclosure made pursuant to an authorization; (d) disclosure to HHS for complaint investigation, compliance review or enforcement; (e) use or disclosure that is required by law; or (f) use or disclosure required for compliance with the HIPAA Transactions Rule or other HIPAA Administrative Simplification Rules. Access and Uses. For internal uses, a covered entity must develop and implement policies and procedures that restrict access and uses of protected health information based on the specific roles of the members of their workforce. These policies and procedures must identify the persons, or classes of persons, in the workforce who need access to protected health information to carry out their duties, the categories of OCR Privacy Rule Summary 11 Last Revised 05/03 protected health information to which access is needed, and any conditions under which they need the information to do their jobs. Disclosures and Requests for Disclosures.\n",
            "\n",
            "\n",
            "Covered entities must establish and implement policies and procedures (which may be standard protocols) for routine, recurring disclosures, or requests for disclosures, that limits the protected health information disclosed to that which is the minimum amount reasonably necessary to achieve the purpose of the disclosure. Individual review of each disclosure is not required. For non-routine, non-recurring disclosures, or requests for disclosures that it makes, covered entities must develop criteria designed to limit disclosures to the information reasonably necessary to accomplish the purpose of the disclosure and review each of these requests individually in accordance with the established criteria. Reasonable Reliance. If another covered entity makes a request for protected health information, a covered entity may rely, if reasonable under the circumstances, on the request as complying with this minimum necessary standard. Similarly, a covered entity may rely upon requests as being the minimum necessary protected health information from: (a) a public official, (b) a professional (such as an attorney or accountant) who is the covered entity’s business associate, seeking the information to provide services to or for the covered entity; or (c) a researcher who provides the documentation or representation required by the Privacy Rule for research. Notice and Other Individual Rights Privacy Practices Notice.\n",
            "\n",
            "\n",
            "Any covered entity may condition compliance with a confidential communication request on the individual specifying an alternative address or method of contact and explaining how any payment will be handled. OCR Privacy Rule Summary 14 Last Revised 05/03 Administrative Requirements HHS recognizes that covered entities range from the smallest provider to the largest, multi-state health plan. Therefore the flexibility and scalability of the Rule are intended to allow covered entities to analyze their own needs and implement solutions appropriate for their own environment. What is appropriate for a particular covered entity will depend on the nature of the covered entity’s business, as well as the covered entity’s size and resources. Privacy Policies and Procedures. A covered entity must develop and implement written privacy policies and procedures that are consistent with the Privacy Rule.64 Privacy Personnel. A covered entity must designate a privacy official responsible for developing and implementing its privacy policies and procedures, and a contact person or contact office responsible for receiving complaints and providing individuals with information on the covered entity’s privacy practices.65 Workforce Training and Management.\n",
            "\n",
            "\n",
            "Workforce members include employees, volunteers, trainees, and may also include other persons whose conduct is under the direct control of the entity (whether or not they are paid by the entity).66 A covered entity must train all workforce members on its privacy policies and procedures, as necessary and appropriate for them to carry out their functions.67 A covered entity must have and apply appropriate sanctions against workforce members who violate its privacy policies and procedures or the Privacy Rule.68 Mitigation. A covered entity must mitigate, to the extent practicable, any harmful effect it learns was caused by use or disclosure of protected health information by its workforce or its business associates in violation of its privacy policies and procedures or the Privacy Rule.69 Data Safeguards. A covered entity must maintain reasonable and appropriate administrative, technical, and physical safeguards to prevent intentional or unintentional use or disclosure of protected health information in violation of the Privacy Rule and to limit its incidental use and disclosure pursuant to otherwise permitted or required use or disclosure.70 For example, such safeguards might include shredding documents containing protected health information before discarding them, securing medical records with lock and key or pass code, and limiting access to keys or pass codes. See OCR “Incidental Uses and Disclosures” Guidance. Complaints.\n",
            "\n",
            "\n",
            "Legally separate covered entities that are affiliated by common ownership or control may designate themselves (including their health care components) as a single covered entity for Privacy Rule compliance.79 The designation must be in writing. An affiliated covered entity that performs multiple covered functions must operate its different covered functions in compliance with the Privacy Rule provisions applicable to those covered functions. Organized Health Care Arrangement. The Privacy Rule identifies relationships in which participating covered entities share protected health information to manage and benefit their common enterprise as “organized health care arrangements.”80 Covered entities in an organized health care arrangement can share protected health information with each other for the arrangement’s joint health care operations.81 Covered Entities With Multiple Covered Functions. A covered entity that performs multiple covered functions must operate its different covered functions in compliance with the Privacy Rule provisions applicable to those covered functions.82 The covered entity may not use or disclose the protected health information of an individual who receives services from one covered function (e.g., health care provider) for another covered function (e.g., health plan) if the individual is not involved with the other function. OCR Privacy Rule Summary 16 Last Revised 05/03 Group Health Plan disclosures to Plan Sponsors.\n",
            "\n",
            "\n",
            "These restrictions must include the representation that the plan sponsor will not use or disclose the protected health information for any employment-related action or decision or in connection with any other benefit plan. Other Provisions: Personal Representatives and Minors Personal Representatives. The Privacy Rule requires a covered entity to treat a \"personal representative\" the same as the individual, with respect to uses and disclosures of the individual’s protected health information, as well as the individual’s rights under the Rule.84 A personal representative is a person legally authorized to make health care decisions on an individual’s behalf or to act for a deceased individual or the estate. The Privacy Rule permits an exception when a covered entity has a reasonable belief that the personal representative may be abusing or neglecting the individual, or that treating the person as the personal representative could otherwise endanger the individual. Special case: Minors. In most cases, parents are the personal representatives for their minor children. Therefore, in most cases, parents can exercise individual rights, such as access to the medical record, on behalf of their minor children. In certain exceptional cases, the parent is not considered the personal representative. In these situations, the Privacy Rule defers to State and other law to determine the rights of parents to access and control the protected health information of their minor children.\n",
            "\n",
            "\n",
            "57 A covered entity may deny an individual access, provided that the individual is given a right to have such denials reviewed by a licensed health care professional (who is designated by the covered entity and who did not participate in the original decision to deny), when a licensed health care professional has determined, in the exercise of professional judgment, that: (a) the access requested is reasonably likely to endanger the life or physical safety of the individual or another person; (b) the protected health information makes reference to another person (unless such other person is a health care provider) and the access requested is reasonably likely to cause substantial harm to such other person; or (c) the request for access is made by the individual’s personal representative and the provision of access to such personal representative is reasonably likely to cause substantial harm to the individual or another person.\n",
            "\n",
            "\n",
            "A covered entity may deny access to individuals, without providing the individual an opportunity for review, in the following protected situations: (a) the protected health information falls under an exception to the right of access; (b) an inmate request for protected health information under certain circumstances; (c) information that a provider creates or obtains in the course of research that includes treatment for which the individual has agreed not to have access as part of consenting OCR Privacy Rule Summary 22 Last Revised 05/03 to participate in the research (as long as access to the information is restored upon completion of the research); (d) for records subject to the Privacy Act, information to which access may be denied under the Privacy Act, 5 U.S.C. § 552a; and (e) information obtained under a promise of confidentiality from a source other than a health care provider, if granting access would likely reveal the source. 45 C.F.R. § 164.524. 58 45 C.F.R. § 164.526. 59 Covered entities may deny an individual’s request for amendment only under specified circumstances. A covered entity may deny the request if it: (a) may exclude the information from access by the individual; (b) did not create the information (unless the individual provides a reasonable basis to believe the originator is no longer available); (c) determines that the information is accurate and complete; or (d) does not hold the information in its designated record set. 164.526(a)(2). 60 45 C.F.R.\n",
            "\n",
            "\n",
            "The Development of Privacy Protection in the United States: A Sectoral Approach The United States has historically taken a markedly different approach to privacy protection compared to Europe, developing a patchwork of sector-specific laws rather than comprehensive federal legislation. This sectoral approach reflects American values of free market economics and limited government intervention. Early Privacy Developments (1960s-1970s): The Fair Credit Reporting Act of 1970 was one of the first federal laws addressing privacy concerns, focusing specifically on the collection and use of consumer credit information. This law established important principles including: - Consumer right to access their credit reports - Requirement for accurate reporting - Time limits on negative information - Procedures for disputing incorrect information The Privacy Act of 1974 represented another significant step, though limited to government agencies. It established: - Rules for government collection and use of personal data - Individual rights to access and correct records - Restrictions on sharing between agencies - Civil and criminal penalties for violations The Evolution of Sectoral Privacy Laws: Different industries received specific privacy regulations over time: Healthcare: The Health Insurance Portability and Accountability Act (HIPAA) of 1996 created comprehensive privacy rules for medical information, including: - Patient rights to access medical records -\n",
            "\n",
            "\n",
            "Restrictions on information sharing - Security requirements for health data - Breach notification requirements - Substantial penalties for violations Financial Services: The Gramm-Leach-Bliley Act of 1999 established privacy rules for financial institutions: - Required privacy notices to customers - Opt-out rights for information sharing - Security standards for financial data - State enforcement mechanisms Children's Privacy: The Children's Online Privacy Protection Act (COPPA) of 1998 specifically addressed children's privacy online: - Parental consent requirements - Restrictions on data collection from children under 13 - Requirements for privacy policies - Limits on marketing to children Education: The Family Educational Rights and Privacy Act (FERPA) protects student education records: - Parent/student rights to access records - Limitations on disclosure without consent - Requirements for schools' privacy practices The Digital Age and New Challenges: The rise of internet companies in the 1990s and 2000s exposed gaps in U.S. privacy protection. The Federal Trade Commission (FTC) became the de facto privacy regulator, using its authority to: - Enforce company privacy promises - Investigate data breaches - Issue privacy guidelines - Impose fines for privacy violations Notable FTC actions included: - 2011 Facebook settlement requiring privacy audits - 2012 Google privacy violation fine ($22.5 million) -\n",
            "\n",
            "\n",
            "Some companies that do not charge consumers a fee, subsidize these services by monetizing consumers’ personal information. Consumers should have the information and tools necessary to limit the use of their information to noninvasive proprivacy advertising, where their personal information is not sold to or shared with hundreds of businesses they’ve never heard of, if they choose to do so. Absent these tools, it will be virtually impossible for consumers to fully understand these contracts they are essentially entering into when they interact with various businesses. (J) Children are particularly vulnerable from a negotiating perspective with respect to their privacy rights. Parents should be able to control what information is collected and sold or shared about their young children and should be given the right to demand that companies erase information collected about their children. (K) Business should also be held directly accountable to consumers for data security breaches and notify consumers when their most sensitive information has been compromised. (L) An independent watchdog whose mission is to protect consumer privacy should ensure that businesses and consumers are well-informed about their rights and obligations and should vigorously enforce the law against businesses that violate consumers’ privacy rights. SEC. 3. Purpose and Intent.\n",
            "\n",
            "\n",
            "(4) Businesses should provide consumers or their authorized agents with easily accessible means to allow consumers and their children to obtain their personal information, to delete it, or correct it, and to opt‐out of its sale and the sharing across business platforms, services, businesses and devices, and to limit the use of their sensitive personal information. (5) Businesses should not penalize consumers for exercising these rights. (6) Businesses should take reasonable precautions to protect consumers’ personal information from a security breach. (7) Businesses should be held accountable when they violate consumers’ privacy rights, and the penalties should be higher when the violation affects children. (C) Implementation of the Law (1) The rights of consumers and the responsibilities of businesses should be implemented with the goal of strengthening consumer privacy, while giving attention to the impact on business and innovation. Consumer privacy and the development of beneficial new products and services are not necessarily incompatible goals. Strong consumer privacy rights create incentives to innovate and develop new products that are privacy protective. (2) Businesses and consumers should be provided with clear guidance about their responsibilities and rights. (3) The law should place the consumer in a position to knowingly and freely negotiate with a business over the business’ use of the consumer’s personal information.\n",
            "\n",
            "\n",
            "(c) A business that is subject to this section shall: (1) not Not require a consumer to create an account or provide additional information beyond what is necessary in order to direct the business not to sell or share the consumer’s personal information or to limit use or disclosure of the consumer’s sensitive personal information (2) Include a description of a consumer’s rights pursuant to Section Sections 1798.120 and 1798.121, along with a separate link to the “Do Not Sell or share My Personal Information” Internet Web page internet web page and a separate link to the “Limit the Use of My Sensitive Personal Information” internet web page, if applicable, or a single link to both choices, or a statement that the business responds to and abides by opt-out preference signals sent by a platform, technology, or mechanism in accordance with subdivision (b), in: (A) Its online privacy policy or policies if the business has an online privacy policy or policies. (B) Any California-specific description of consumers’ privacy rights. (3) Ensure that all individuals responsible for handling consumer inquiries about the business’s privacy practices or the business’s compliance with this title are informed of all requirements in Section Sections 1798.120, 1798.121, and this section and how to direct consumers to exercise their rights under those sections.\n",
            "\n",
            "\n",
            "(15) Issuing regulations requiring businesses whose processing of consumers’ personal information presents significant risk to consumers’ privacy or security, to: (A) Perform a cybersecurity audit on an annual basis, including defining the scope of the audit and establishing a process to ensure that audits are thorough and independent. The factors to be considered in determining when processing may result in significant risk to the security of personal information shall include the size and complexity of the business and the nature and scope of processing activities. (B) Submit to the California Privacy Protection Agency on a regular basis a risk assessment with respect to their processing of personal information, including whether the processing involves sensitive personal information, and identifying and weighing the benefits resulting from the processing to the business, the consumer, other stakeholders, and the public, against the potential risks to the rights of the consumer associated with that processing, with the goal of restricting or prohibiting the processing if the risks to privacy of the consumer outweigh the benefits resulting from processing to the consumer, the business, other stakeholders, and the public. Nothing in this section shall require a business to divulge trade secrets.\n",
            "\n",
            "\n",
            "This section shall not prevent a consumer from declining to request information from a business, declining to opt-out opt out of a business’s sale of the consumer’s personal information, or authorizing a business to sell or share the consumer’s personal information after previously opting out. SEC. 24. Establishment of California Privacy Protection Agency. SEC. 24.1. Section 1798.199.10 is added to the Civil Code, to read: 1798.199.10. (a) There is hereby established in state government the California Privacy Protection Agency, which is vested with full administrative power, authority, and jurisdiction to implement and enforce the California Consumer Privacy Act of 2018. The agency shall be governed by a five-member board, including the chairperson. The chairperson and one member of the board shall be appointed by the Governor. The Attorney General, Senate Rules Committee, and Speaker of the Assembly shall each appoint one member. These appointments should be made from among Californians with expertise in the areas of privacy, technology, and consumer rights. (b) The initial appointments to the agency shall be made within 90 days of the effective date of the act adding this section. SEC. 24.2. Section 1798.199.15 is added to the Civil Code, to read: 1798.199.15. Members of the agency board shall: (a) Have qualifications, experience, and skills, in particular in the areas of privacy and technology, required to perform the duties of the agency and exercise its powers.\n",
            "\n",
            "\n",
            "(b) On and after the earlier of July 1, 2021, or within six months of the agency providing the Attorney General with notice that it is prepared to assume rulemaking responsibilities under this title, adopt, amend, and rescind regulations pursuant to Section 1798.185 to carry out the purposes and provisions of the California Consumer Privacy Act of 2018, including regulations specifying record keeping requirements for businesses to ensure compliance with this title. (c) Through the implementation of this title, protect the fundamental privacy rights of natural persons with respect to the use of their personal information. (d) Promote public awareness and understanding of the risks, rules, responsibilities, safeguards, and rights in relation to the collection, use, sale, and disclosure of personal information, including the rights of minors with respect to their own information, and provide a public report summarizing the risk assessments filed with the agency pursuant to paragraph (15) of subdivision (a) of Section 1798.185 while ensuring that data security is not compromised. (e) Provide guidance to consumers regarding their rights under this title. (f) Provide guidance to businesses regarding their duties and responsibilities under this title and appoint a Chief Privacy Auditor to conduct audits of businesses to ensure compliance with this title pursuant to regulations adopted pursuant to paragraph (18) of subdivision (a) of Section 1798.185.\n",
            "\n",
            "\n",
            "(g) Provide technical assistance and advice to the Legislature, upon request, with respect to privacy-related legislation. (h) Monitor relevant developments relating to the protection of personal information and in particular, the development of information and communication technologies and commercial practices. (i) Cooperate with other agencies with jurisdiction over privacy laws and with data processing authorities in California, other states, territories, and countries to ensure consistent application of privacy protections. (j) Establish a mechanism pursuant to which persons doing business in California that do not meet the definition of business set forth in paragraph (1), (2), or (3) of subdivision (d) of Section 1798.140 may voluntarily certify that they are in compliance with this title, as set forth in paragraph (4) of subdivision (d) of Section 1798.140, and make a list of those entities available to the public. (k) Solicit, review, and approve applications for grants to the extent funds are available pursuant to paragraph (2) of subdivision (b) of Section 1798.160. (l) Perform all other acts necessary or appropriate in the exercise of its power, authority, and jurisdiction and seek to balance the goals of strengthening consumer privacy while giving attention to the impact on businesses. SEC. 24.8. Section 1798.199.45 is added to the Civil Code, to read: 1798.199.45.\n",
            "\n",
            "\n",
            "Query: What are the key differences between the articles tagged with PrivacyLaw?\n",
            "Similar Sentences:\n",
            "\n",
            "=== Querying GraphRAG ===\n",
            "\n",
            "Query: When was the Tor network released?\n",
            "Top Relevant Triples:\n",
            "- Tor name Tor Network\n",
            "- Tor type Software\n",
            "- Tor functionality Anonymous internet browsing\n",
            "- Tor influenced ModernAnonymityTools\n",
            "- CDUniverseBreach1999 name CD Universe Breach (1999)\n",
            "- TJXBreach2007 name TJX Companies Breach (2007)\n",
            "- CapitalOneBreach2019 resultedIn CloudSecurityEnhancement\n",
            "- EggheadBreach2000 name Egghead.com Breach (2000)\n",
            "- TLS name Transport Layer Security\n",
            "- PhilZimmermann jobTitle Creator of Pretty Good Privacy (PGP)\n",
            "- TLS type Software\n",
            "- CapitalOneBreach2019 name Capital One Breach (2019)\n",
            "- TRWBreach1984 name TRW Credit Data Breach (1984)\n",
            "- MicrosoftExchangeBreach2021 name Microsoft Exchange Breach (2021)\n",
            "- PGP creator PhilZimmermann\n",
            "- MicrosoftExchangeBreach2021 resultedIn CloudSecurityEnhancement\n",
            "- TJXCompanies name TJX Companies\n",
            "- Encryption supportsCompliance GDPR\n",
            "- TRWBreach1984 resultedIn EnhancedCreditAgencySecurity\n",
            "- EuropeanCommission name European Commission\n",
            "\n",
            "\n",
            "Query: List where the GDPR approach was applied.\n",
            "Top Relevant Triples:\n",
            "- GDPR type Legislation\n",
            "- GDPR influencedBy MajorDataBreaches\n",
            "- GDPR appliesTo Processor\n",
            "- GDPR appliesTo Processor\n",
            "- GDPR enforcedIn EuropeanUnion\n",
            "- GDPR mandates RightToRestrictionOfProcessing\n",
            "- GDPR mandates RightToRestrictionOfProcessing\n",
            "- GDPR name General Data Protection Regulation\n",
            "- GDPR jurisdiction European Union\n",
            "- ZeroKnowledgeProofs supportsCompliance GDPR\n",
            "- GDPR appliesTo Controller\n",
            "- GDPR appliesTo Controller\n",
            "- GDPR legalStatus In force since 2018\n",
            "- GDPR mandates RightToAccess\n",
            "- GDPR mandates RightToAccess\n",
            "- GDPR mandates RightToRectification\n",
            "- GDPR mandates RightToRectification\n",
            "- DifferentialPrivacy supportsCompliance GDPR\n",
            "- GDPR mandates RightToDataPortability\n",
            "- GDPR mandates RightToDataPortability\n",
            "\n",
            "\n",
            "Query: How major data breaches impacted Apple and Microsoft?\n",
            "Top Relevant Triples:\n",
            "- TRWBreach1984 name TRW Credit Data Breach (1984)\n",
            "- TargetBreach2013 description 40 million credit card numbers exposed, 70 million customer records compromised\n",
            "- CapitalOneBreach2019 description 100 million records compromised\n",
            "- EggheadBreach2000 description 3.7 million customer records compromised\n",
            "- TJXBreach2007 name TJX Companies Breach (2007)\n",
            "- CapitalOneBreach2019 name Capital One Breach (2019)\n",
            "- MicrosoftExchangeBreach2021 name Microsoft Exchange Breach (2021)\n",
            "- Microsoft name Microsoft\n",
            "- GDPR influencedBy MajorDataBreaches\n",
            "- GDPR requires BreachNotification\n",
            "- TargetBreach2013 name Target Breach (2013)\n",
            "- HIPAA requires BreachNotification\n",
            "- HIPAA requiresCompliance BreachNotification\n",
            "- HIPAA requiresCompliance BreachNotification\n",
            "- CapitalOneBreach2019 resultedIn CloudSecurityEnhancement\n",
            "- EquifaxBreach2017 description 147 million people affected\n",
            "- MicrosoftExchangeBreach2021 description 250,000 servers affected\n",
            "- ChoicePointBreach2005 name ChoicePoint Breach (2005)\n",
            "- ChoicePointBreach2005 description 163,000 consumer records compromised\n",
            "- MicrosoftExchangeBreach2021 resultedIn CloudSecurityEnhancement\n",
            "\n",
            "\n",
            "Query: How privacy regulations affect various industries in the USA?\n",
            "Top Relevant Triples:\n",
            "- DifferentialPrivacy functionality Statistical analysis with privacy protection\n",
            "- GDPR name General Data Protection Regulation\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- PrivacyPreservingDataMining supportsCompliance GDPR\n",
            "- Business processes SensitivePersonalInformation\n",
            "- GDPR type Legislation\n",
            "- PrivacyNotice requiredBy HIPAA\n",
            "- CCPA name California Consumer Privacy Act\n",
            "- DifferentialPrivacy name Differential Privacy\n",
            "- GDPR mandates RightToAccess\n",
            "- GDPR mandates RightToAccess\n",
            "- CoveredEntity processes ProtectedHealthInformation\n",
            "- GDPR mandates RightToDataPortability\n",
            "- GDPR mandates RightToDataPortability\n",
            "- GDPR mandates RightToRectification\n",
            "- GDPR mandates RightToRectification\n",
            "- Business processes PersonalInformation\n",
            "- GDPR mandates RightToRestrictionOfProcessing\n",
            "- GDPR mandates RightToRestrictionOfProcessing\n",
            "\n",
            "\n",
            "Query: When was the TRW Credit Data breach and how many credit records were exposed?\n",
            "Top Relevant Triples:\n",
            "- TRWBreach1984 name TRW Credit Data Breach (1984)\n",
            "- TRWBreach1984 description Exposed 90 million credit records\n",
            "- TRW name TRW Credit Data\n",
            "- TargetBreach2013 description 40 million credit card numbers exposed, 70 million customer records compromised\n",
            "- CapitalOneBreach2019 description 100 million records compromised\n",
            "- TJXBreach2007 description 45.7 million credit card numbers stolen\n",
            "- EquifaxBreach2017 name Equifax Breach (2017)\n",
            "- TJXBreach2007 name TJX Companies Breach (2007)\n",
            "- EquifaxBreach2017 resultedIn CreditMonitoringRequirements\n",
            "- CDUniverseBreach1999 description 300,000 credit card numbers exposed\n",
            "- EquifaxBreach2017 description 147 million people affected\n",
            "- CapitalOneBreach2019 name Capital One Breach (2019)\n",
            "- TRWBreach1984 resultedIn EnhancedCreditAgencySecurity\n",
            "- EggheadBreach2000 description 3.7 million customer records compromised\n",
            "- CCPA requiresCompliance BreachNotification\n",
            "- CCPA requiresCompliance BreachNotification\n",
            "- CPRA requiresCompliance BreachNotification\n",
            "- CPRA requiresCompliance BreachNotification\n",
            "- CDUniverseBreach1999 name CD Universe Breach (1999)\n",
            "- TargetBreach2013 name Target Breach (2013)\n",
            "\n",
            "\n",
            "Query: How have approaches to data breach notification evolved since 2000, and what are the key differences between jurisdictions?\n",
            "Top Relevant Triples:\n",
            "- GDPR requires BreachNotification\n",
            "- HIPAA requires BreachNotification\n",
            "- TRWBreach1984 name TRW Credit Data Breach (1984)\n",
            "- HIPAA requiresCompliance BreachNotification\n",
            "- HIPAA requiresCompliance BreachNotification\n",
            "- CPRA requiresCompliance BreachNotification\n",
            "- CPRA requiresCompliance BreachNotification\n",
            "- TJXBreach2007 name TJX Companies Breach (2007)\n",
            "- CCPA requiresCompliance BreachNotification\n",
            "- CCPA requiresCompliance BreachNotification\n",
            "- CapitalOneBreach2019 name Capital One Breach (2019)\n",
            "- TargetBreach2013 name Target Breach (2013)\n",
            "- EquifaxBreach2017 name Equifax Breach (2017)\n",
            "- MicrosoftExchangeBreach2021 name Microsoft Exchange Breach (2021)\n",
            "- EggheadBreach2000 description 3.7 million customer records compromised\n",
            "- ChoicePointBreach2005 name ChoicePoint Breach (2005)\n",
            "- GDPR name General Data Protection Regulation\n",
            "- CapitalOneBreach2019 description 100 million records compromised\n",
            "- CDUniverseBreach1999 name CD Universe Breach (1999)\n",
            "- GDPR legalStatus In force since 2018\n",
            "\n",
            "\n",
            "Query: What kind of data is protected by privacy acts?\n",
            "Top Relevant Triples:\n",
            "- PrivacyNotice requiredBy HIPAA\n",
            "- PrivacyPreservingDataMining supportsCompliance GDPR\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- CPRA name California Privacy Rights Act\n",
            "- ProtectedHealthInformation type DataType\n",
            "- PGP name Pretty Good Privacy\n",
            "- DifferentialPrivacy functionality Statistical analysis with privacy protection\n",
            "- GDPR name General Data Protection Regulation\n",
            "- GDPR mandates RightToDataPortability\n",
            "- GDPR mandates RightToDataPortability\n",
            "- DifferentialPrivacy name Differential Privacy\n",
            "- ProtectedHealthInformation name Protected Health Information\n",
            "- CCPA name California Consumer Privacy Act\n",
            "- Encryption supportsCompliance GDPR\n",
            "- SensitivePersonalInformation type DataType\n",
            "- DES name Data Encryption Standard\n",
            "- SensitivePersonalInformation name Sensitive Personal Information\n",
            "- GDPR type Legislation\n",
            "- HomomorphicEncryption appliedIn HealthcareDataAnalysis\n",
            "\n",
            "\n",
            "Query: Summarize how GDPR is applicable to international organizations using only articles tagged with GDPR  (EU GDPR paper)\n",
            "Top Relevant Triples:\n",
            "- GDPR type Legislation\n",
            "- GDPR enforcedIn EuropeanUnion\n",
            "- GDPR jurisdiction European Union\n",
            "- GDPR legalStatus In force since 2018\n",
            "- GDPR appliesTo Processor\n",
            "- GDPR appliesTo Processor\n",
            "- GDPR influencedBy MajorDataBreaches\n",
            "- GDPR name General Data Protection Regulation\n",
            "- GDPR mandates RightToRectification\n",
            "- GDPR mandates RightToRectification\n",
            "- GDPR mandates RightToAccess\n",
            "- GDPR mandates RightToAccess\n",
            "- GDPR appliesTo Controller\n",
            "- GDPR appliesTo Controller\n",
            "- GDPR mandates RightToRestrictionOfProcessing\n",
            "- GDPR mandates RightToRestrictionOfProcessing\n",
            "- EuropeanCommission type Organization\n",
            "- GDPR mandates RightToObject\n",
            "- GDPR mandates RightToObject\n",
            "- DifferentialPrivacy supportsCompliance GDPR\n",
            "\n",
            "\n",
            "Query: What privacy protection is applicable in California?\n",
            "Top Relevant Triples:\n",
            "- CPRA name California Privacy Rights Act\n",
            "- CCPA name California Consumer Privacy Act\n",
            "- PrivacyNotice requiredBy HIPAA\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- CCPA enforcedIn California\n",
            "- CPRA enforcedIn California\n",
            "- California type Jurisdiction\n",
            "- PGP name Pretty Good Privacy\n",
            "- CCPA jurisdiction California, USA\n",
            "- DifferentialPrivacy name Differential Privacy\n",
            "- CPRA jurisdiction California, USA\n",
            "- DifferentialPrivacy functionality Statistical analysis with privacy protection\n",
            "- PrivacyPreservingDataMining supportsCompliance GDPR\n",
            "- ChoicePointBreach2005 resultedIn CaliforniaBreachNotificationLaw\n",
            "- HIPAA appliesTo CoveredEntity\n",
            "- HIPAA appliesTo CoveredEntity\n",
            "- Encryption supportsCompliance HIPAA\n",
            "- PhilZimmermann jobTitle Creator of Pretty Good Privacy (PGP)\n",
            "- CoveredEntity processes ProtectedHealthInformation\n",
            "\n",
            "\n",
            "Query: Who is covered by privacy protection?\n",
            "Top Relevant Triples:\n",
            "- PrivacyNotice requiredBy HIPAA\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- PGP name Pretty Good Privacy\n",
            "- CoveredEntity processes ProtectedHealthInformation\n",
            "- PrivacyPreservingDataMining supportsCompliance GDPR\n",
            "- CPRA name California Privacy Rights Act\n",
            "- PhilZimmermann jobTitle Creator of Pretty Good Privacy (PGP)\n",
            "- DifferentialPrivacy name Differential Privacy\n",
            "- ProtectedHealthInformation name Protected Health Information\n",
            "- CCPA name California Consumer Privacy Act\n",
            "- GDPR name General Data Protection Regulation\n",
            "- DifferentialPrivacy functionality Statistical analysis with privacy protection\n",
            "- HIPAA appliesTo CoveredEntity\n",
            "- HIPAA appliesTo CoveredEntity\n",
            "- CoveredEntity name Covered Entity\n",
            "- SensitivePersonalInformation name Sensitive Personal Information\n",
            "- CoveredEntity type OrganizationRole\n",
            "- ZeroKnowledgeProof functionality Privacy-preserving authentication\n",
            "- GDPR mandates RightToAccess\n",
            "\n",
            "\n",
            "Query: What are the key differences between the articles tagged with PrivacyLaw?\n",
            "Top Relevant Triples:\n",
            "- DifferentialPrivacy name Differential Privacy\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- PrivacyNotice requiredBy HIPAA\n",
            "- PrivacyPreservingDataMining supportsCompliance GDPR\n",
            "- CPRA name California Privacy Rights Act\n",
            "- GDPR type Legislation\n",
            "- CCPA name California Consumer Privacy Act\n",
            "- PGP name Pretty Good Privacy\n",
            "- DifferentialPrivacy functionality Statistical analysis with privacy protection\n",
            "- HIPAA type Legislation\n",
            "- PhilZimmermann jobTitle Creator of Pretty Good Privacy (PGP)\n",
            "- GDPR legalStatus In force since 2018\n",
            "- CPRA type Legislation\n",
            "- SensitivePersonalInformation name Sensitive Personal Information\n",
            "- HIPAA appliesTo CoveredEntity\n",
            "- HIPAA appliesTo CoveredEntity\n",
            "- GDPR mandates RightToAccess\n",
            "- GDPR mandates RightToAccess\n",
            "- GDPR name General Data Protection Regulation\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Main - Note that chunk size to use is set here in main and overrides default\n",
        "def main():\n",
        "    try:\n",
        "        # Directory containing Word documents\n",
        "        directory = \"content/docs\"\n",
        "\n",
        "        # Get all .docx files in the directory\n",
        "        docx_files = list(Path(directory).glob(\"*.docx\"))\n",
        "        print(f\"Found files: {docx_files}\")\n",
        "\n",
        "        if not docx_files:\n",
        "            print(f\"No Word documents found in {directory}\")\n",
        "            return\n",
        "\n",
        "        print(f\"Found {len(docx_files)} Word documents\")\n",
        "\n",
        "        vectors_dict = {}\n",
        "        vectors = []\n",
        "        # Initialize the model\n",
        "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "          # Process each document\n",
        "        for doc_path in docx_files:\n",
        "          try:\n",
        "              print(f\"\\nProcessing: {doc_path.name}\")\n",
        "\n",
        "              # Extract chunks of approximately 100 characters\n",
        "              chunks = extract_fixed_chunks(str(doc_path), chunk_size=1500)\n",
        "\n",
        "              # get chunk embeddings and save to vector dictionary\n",
        "              print(f\"\\nGenerating embeddings for next {len(chunks)} chunks...\\n\")\n",
        "              for chunk in chunks:\n",
        "                  embeddings = model.encode(chunk)\n",
        "                  vectors_dict[tuple(embeddings)] = chunk\n",
        "                  vectors.append(embeddings)\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"Error processing {doc_path.name}: {str(e)}\")\n",
        "              continue\n",
        "\n",
        "\n",
        "        # run queries to find similarity in chunks and graphs\n",
        "        queries = [\"When was the Tor network released?\",\n",
        "          \"List where the GDPR approach was applied.\",\n",
        "          \"How major data breaches impacted Apple and Microsoft?\",\n",
        "          \"How privacy regulations affect various industries in the USA?\",\n",
        "          \"When was the TRW Credit Data breach and how many credit records were exposed?\",\n",
        "          \"How have approaches to data breach notification evolved since 2000, and what are the key differences between jurisdictions?\",\n",
        "          \"What kind of data is protected by privacy acts?\",\n",
        "          \"Summarize how GDPR is applicable to international organizations using only articles tagged with GDPR  (EU GDPR paper)\",\n",
        "          \"What privacy protection is applicable in California?\",\n",
        "          \"Who is covered by privacy protection?\",\n",
        "          \"What are the key differences between the articles tagged with PrivacyLaw?\"]\n",
        "\n",
        "        # === Querying RAG ===\n",
        "        print(\"\\n=== Querying RAG ===\\n\")\n",
        "        print(\"\\nExtracting relevant chunks to queries...\\n\")\n",
        "        for query in queries:\n",
        "          query_embedding = model.encode(query)\n",
        "          similar_sentences = find_similar_sentences(query_embedding, vectors)\n",
        "\n",
        "          print(f\"Query: {query}\")\n",
        "          print(\"Similar Sentences:\")\n",
        "          for sentence in similar_sentences:\n",
        "            chunk = vectors_dict[tuple(sentence)]\n",
        "            print(chunk)\n",
        "            print('\\n')\n",
        "\n",
        "\n",
        "        # === Querying GraphRAG ===\n",
        "\n",
        "        print(\"\\n=== Querying GraphRAG ===\\n\")\n",
        "        # Load and process triples\n",
        "        triples = load_triples_from_ttl(\"content/privacy_and_security.ttl\")\n",
        "        triple_texts = [triple_to_text(str(s), str(p), str(o)) for s, p, o in triples]\n",
        "\n",
        "        # Embed all triple texts\n",
        "        triple_embeddings = embed_texts(triple_texts, model)\n",
        "\n",
        "        for query in queries:\n",
        "          # Retrieve top 20 relevant triples\n",
        "          top_triples = retrieve_top_k(query, triple_texts, triple_embeddings, model, k=20)\n",
        "\n",
        "          # Output results\n",
        "          print(f\"Query: {query}\")\n",
        "          print(\"Top Relevant Triples:\")\n",
        "          for t in top_triples:\n",
        "              print(\"-\", t)\n",
        "          print(\"\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error accessing directory: {str(e)}\")\n",
        "\n",
        "# Call main and start the creating embeddings\n",
        "main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHBRrpl15FzG"
      },
      "source": [
        "/content/sample_data/mydata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load RDF triples from a Turtle file\n",
        "def load_triples_from_ttl(file_path):\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=\"ttl\")\n",
        "    return list(g)\n",
        "\n",
        "# Convert a triple to a readable sentence\n",
        "def triple_to_text(s, p, o):\n",
        "    s = s.split(\"#\")[-1] if \"#\" in s else s.split(\"/\")[-1]\n",
        "    p = p.split(\"#\")[-1] if \"#\" in p else p.split(\"/\")[-1]\n",
        "    o = o.split(\"#\")[-1] if \"#\" in o else o.split(\"/\")[-1]\n",
        "\n",
        "    return f\"{s} {p.replace('_', ' ')} {o}\".replace('\"', '')\n",
        "\n",
        "# Embed a list of sentences\n",
        "def embed_texts(texts, model):\n",
        "    return model.encode(texts, convert_to_tensor=True)\n",
        "\n",
        "# Retrieve top-k most similar triples\n",
        "def retrieve_top_k(query, triple_texts, triple_embeddings, model, k=4):\n",
        "    query_embedding = embed_texts([query], model)\n",
        "    scores = cosine_similarity(query_embedding, triple_embeddings)\n",
        "    top_k_indices = torch.topk(scores, k).indices\n",
        "    return [triple_texts[i] for i in top_k_indices]\n",
        "\n",
        "# === Main Pipeline ===\n",
        "\n",
        "# Load and process triples\n",
        "triples = load_triples_from_ttl(\"content/privacy_and_security.ttl\")\n",
        "triple_texts = [triple_to_text(str(s), str(p), str(o)) for s, p, o in triples]\n",
        "\n",
        "# Load embedding model\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Embed all triple texts\n",
        "triple_embeddings = embed_texts(triple_texts, model)\n",
        "\n",
        "# run queries to find similarity in graph\n",
        "queries = [\"When was the Tor network released?\",\n",
        "  \"List where the GDPR approach was applied.\",\n",
        "  \"How major data breaches impacted Apple and Microsoft?\",\n",
        "  \"How privacy regulations affect various industries in the USA?\",\n",
        "  \"When was the TRW Credit Data breach and how many credit records were exposed?\",\n",
        "  \"How have approaches to data breach notification evolved since 2000, and what are the key differences between jurisdictions?\",\n",
        "  \"What kind of data is protected by privacy acts?\",\n",
        "  \"Summarize how GDPR is applicable to international organizations using only articles tagged with GDPR  (EU GDPR paper)\",\n",
        "  \"What privacy protection is applicable in California?\",\n",
        "  \"Who is covered by privacy protection?\",\n",
        "  \"What are the key differences between the articles tagged with PrivacyLaw?\"]\n",
        "\n",
        "\n",
        "for query in queries:\n",
        "  # Retrieve top 20 relevant triples\n",
        "  top_triples = retrieve_top_k(query, triple_texts, triple_embeddings, model, k=20)\n",
        "\n",
        "  # Output results\n",
        "  print(f\"Query: {query}\")\n",
        "  print(\"Top Relevant Triples:\")\n",
        "  for t in top_triples:\n",
        "      print(\"-\", t)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "yVge8kkh___C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f5621b9d-21bc-4e83-ab36-2f1492a6e61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: When was the Tor network released?\n",
            "Top Relevant Triples:\n",
            "- Tor name Tor Network\n",
            "- Tor type Software\n",
            "- Tor functionality Anonymous internet browsing\n",
            "- Tor influenced ModernAnonymityTools\n",
            "- CDUniverseBreach1999 name CD Universe Breach (1999)\n",
            "- TJXBreach2007 name TJX Companies Breach (2007)\n",
            "- CapitalOneBreach2019 resultedIn CloudSecurityEnhancement\n",
            "- EggheadBreach2000 name Egghead.com Breach (2000)\n",
            "- TLS name Transport Layer Security\n",
            "- PhilZimmermann jobTitle Creator of Pretty Good Privacy (PGP)\n",
            "- TLS type Software\n",
            "- CapitalOneBreach2019 name Capital One Breach (2019)\n",
            "- TRWBreach1984 name TRW Credit Data Breach (1984)\n",
            "- MicrosoftExchangeBreach2021 name Microsoft Exchange Breach (2021)\n",
            "- PGP creator PhilZimmermann\n",
            "- MicrosoftExchangeBreach2021 resultedIn CloudSecurityEnhancement\n",
            "- TJXCompanies name TJX Companies\n",
            "- Encryption supportsCompliance GDPR\n",
            "- TRWBreach1984 resultedIn EnhancedCreditAgencySecurity\n",
            "- EuropeanCommission name European Commission\n",
            "\n",
            "\n",
            "Query: List where the GDPR approach was applied.\n",
            "Top Relevant Triples:\n",
            "- GDPR type Legislation\n",
            "- GDPR influencedBy MajorDataBreaches\n",
            "- GDPR appliesTo Processor\n",
            "- GDPR appliesTo Processor\n",
            "- GDPR enforcedIn EuropeanUnion\n",
            "- GDPR mandates RightToRestrictionOfProcessing\n",
            "- GDPR mandates RightToRestrictionOfProcessing\n",
            "- GDPR name General Data Protection Regulation\n",
            "- GDPR jurisdiction European Union\n",
            "- ZeroKnowledgeProofs supportsCompliance GDPR\n",
            "- GDPR appliesTo Controller\n",
            "- GDPR appliesTo Controller\n",
            "- GDPR legalStatus In force since 2018\n",
            "- GDPR mandates RightToAccess\n",
            "- GDPR mandates RightToAccess\n",
            "- GDPR mandates RightToRectification\n",
            "- GDPR mandates RightToRectification\n",
            "- DifferentialPrivacy supportsCompliance GDPR\n",
            "- GDPR mandates RightToDataPortability\n",
            "- GDPR mandates RightToDataPortability\n",
            "\n",
            "\n",
            "Query: How major data breaches impacted Apple and Microsoft?\n",
            "Top Relevant Triples:\n",
            "- TRWBreach1984 name TRW Credit Data Breach (1984)\n",
            "- TargetBreach2013 description 40 million credit card numbers exposed, 70 million customer records compromised\n",
            "- CapitalOneBreach2019 description 100 million records compromised\n",
            "- EggheadBreach2000 description 3.7 million customer records compromised\n",
            "- TJXBreach2007 name TJX Companies Breach (2007)\n",
            "- CapitalOneBreach2019 name Capital One Breach (2019)\n",
            "- MicrosoftExchangeBreach2021 name Microsoft Exchange Breach (2021)\n",
            "- Microsoft name Microsoft\n",
            "- GDPR influencedBy MajorDataBreaches\n",
            "- GDPR requires BreachNotification\n",
            "- TargetBreach2013 name Target Breach (2013)\n",
            "- HIPAA requires BreachNotification\n",
            "- HIPAA requiresCompliance BreachNotification\n",
            "- HIPAA requiresCompliance BreachNotification\n",
            "- CapitalOneBreach2019 resultedIn CloudSecurityEnhancement\n",
            "- EquifaxBreach2017 description 147 million people affected\n",
            "- MicrosoftExchangeBreach2021 description 250,000 servers affected\n",
            "- ChoicePointBreach2005 name ChoicePoint Breach (2005)\n",
            "- ChoicePointBreach2005 description 163,000 consumer records compromised\n",
            "- MicrosoftExchangeBreach2021 resultedIn CloudSecurityEnhancement\n",
            "\n",
            "\n",
            "Query: How privacy regulations affect various industries in the USA?\n",
            "Top Relevant Triples:\n",
            "- DifferentialPrivacy functionality Statistical analysis with privacy protection\n",
            "- GDPR name General Data Protection Regulation\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- PrivacyPreservingDataMining supportsCompliance GDPR\n",
            "- Business processes SensitivePersonalInformation\n",
            "- GDPR type Legislation\n",
            "- PrivacyNotice requiredBy HIPAA\n",
            "- CCPA name California Consumer Privacy Act\n",
            "- DifferentialPrivacy name Differential Privacy\n",
            "- GDPR mandates RightToAccess\n",
            "- GDPR mandates RightToAccess\n",
            "- CoveredEntity processes ProtectedHealthInformation\n",
            "- GDPR mandates RightToDataPortability\n",
            "- GDPR mandates RightToDataPortability\n",
            "- GDPR mandates RightToRectification\n",
            "- GDPR mandates RightToRectification\n",
            "- Business processes PersonalInformation\n",
            "- GDPR mandates RightToRestrictionOfProcessing\n",
            "- GDPR mandates RightToRestrictionOfProcessing\n",
            "\n",
            "\n",
            "Query: When was the TRW Credit Data breach and how many credit records were exposed?\n",
            "Top Relevant Triples:\n",
            "- TRWBreach1984 name TRW Credit Data Breach (1984)\n",
            "- TRWBreach1984 description Exposed 90 million credit records\n",
            "- TRW name TRW Credit Data\n",
            "- TargetBreach2013 description 40 million credit card numbers exposed, 70 million customer records compromised\n",
            "- CapitalOneBreach2019 description 100 million records compromised\n",
            "- TJXBreach2007 description 45.7 million credit card numbers stolen\n",
            "- EquifaxBreach2017 name Equifax Breach (2017)\n",
            "- TJXBreach2007 name TJX Companies Breach (2007)\n",
            "- EquifaxBreach2017 resultedIn CreditMonitoringRequirements\n",
            "- CDUniverseBreach1999 description 300,000 credit card numbers exposed\n",
            "- EquifaxBreach2017 description 147 million people affected\n",
            "- CapitalOneBreach2019 name Capital One Breach (2019)\n",
            "- TRWBreach1984 resultedIn EnhancedCreditAgencySecurity\n",
            "- EggheadBreach2000 description 3.7 million customer records compromised\n",
            "- CCPA requiresCompliance BreachNotification\n",
            "- CCPA requiresCompliance BreachNotification\n",
            "- CPRA requiresCompliance BreachNotification\n",
            "- CPRA requiresCompliance BreachNotification\n",
            "- CDUniverseBreach1999 name CD Universe Breach (1999)\n",
            "- TargetBreach2013 name Target Breach (2013)\n",
            "\n",
            "\n",
            "Query: How have approaches to data breach notification evolved since 2000, and what are the key differences between jurisdictions?\n",
            "Top Relevant Triples:\n",
            "- GDPR requires BreachNotification\n",
            "- HIPAA requires BreachNotification\n",
            "- TRWBreach1984 name TRW Credit Data Breach (1984)\n",
            "- HIPAA requiresCompliance BreachNotification\n",
            "- HIPAA requiresCompliance BreachNotification\n",
            "- CPRA requiresCompliance BreachNotification\n",
            "- CPRA requiresCompliance BreachNotification\n",
            "- TJXBreach2007 name TJX Companies Breach (2007)\n",
            "- CCPA requiresCompliance BreachNotification\n",
            "- CCPA requiresCompliance BreachNotification\n",
            "- CapitalOneBreach2019 name Capital One Breach (2019)\n",
            "- TargetBreach2013 name Target Breach (2013)\n",
            "- EquifaxBreach2017 name Equifax Breach (2017)\n",
            "- MicrosoftExchangeBreach2021 name Microsoft Exchange Breach (2021)\n",
            "- EggheadBreach2000 description 3.7 million customer records compromised\n",
            "- ChoicePointBreach2005 name ChoicePoint Breach (2005)\n",
            "- GDPR name General Data Protection Regulation\n",
            "- CapitalOneBreach2019 description 100 million records compromised\n",
            "- CDUniverseBreach1999 name CD Universe Breach (1999)\n",
            "- GDPR legalStatus In force since 2018\n",
            "\n",
            "\n",
            "Query: What kind of data is protected by privacy acts?\n",
            "Top Relevant Triples:\n",
            "- PrivacyNotice requiredBy HIPAA\n",
            "- PrivacyPreservingDataMining supportsCompliance GDPR\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- CPRA name California Privacy Rights Act\n",
            "- ProtectedHealthInformation type DataType\n",
            "- PGP name Pretty Good Privacy\n",
            "- DifferentialPrivacy functionality Statistical analysis with privacy protection\n",
            "- GDPR name General Data Protection Regulation\n",
            "- GDPR mandates RightToDataPortability\n",
            "- GDPR mandates RightToDataPortability\n",
            "- DifferentialPrivacy name Differential Privacy\n",
            "- ProtectedHealthInformation name Protected Health Information\n",
            "- CCPA name California Consumer Privacy Act\n",
            "- Encryption supportsCompliance GDPR\n",
            "- SensitivePersonalInformation type DataType\n",
            "- DES name Data Encryption Standard\n",
            "- SensitivePersonalInformation name Sensitive Personal Information\n",
            "- GDPR type Legislation\n",
            "- HomomorphicEncryption appliedIn HealthcareDataAnalysis\n",
            "\n",
            "\n",
            "Query: Summarize how GDPR is applicable to international organizations using only articles tagged with GDPR  (EU GDPR paper)\n",
            "Top Relevant Triples:\n",
            "- GDPR type Legislation\n",
            "- GDPR enforcedIn EuropeanUnion\n",
            "- GDPR jurisdiction European Union\n",
            "- GDPR legalStatus In force since 2018\n",
            "- GDPR appliesTo Processor\n",
            "- GDPR appliesTo Processor\n",
            "- GDPR influencedBy MajorDataBreaches\n",
            "- GDPR name General Data Protection Regulation\n",
            "- GDPR mandates RightToRectification\n",
            "- GDPR mandates RightToRectification\n",
            "- GDPR mandates RightToAccess\n",
            "- GDPR mandates RightToAccess\n",
            "- GDPR appliesTo Controller\n",
            "- GDPR appliesTo Controller\n",
            "- GDPR mandates RightToRestrictionOfProcessing\n",
            "- GDPR mandates RightToRestrictionOfProcessing\n",
            "- EuropeanCommission type Organization\n",
            "- GDPR mandates RightToObject\n",
            "- GDPR mandates RightToObject\n",
            "- DifferentialPrivacy supportsCompliance GDPR\n",
            "\n",
            "\n",
            "Query: What privacy protection is applicable in California?\n",
            "Top Relevant Triples:\n",
            "- CPRA name California Privacy Rights Act\n",
            "- CCPA name California Consumer Privacy Act\n",
            "- PrivacyNotice requiredBy HIPAA\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- CCPA enforcedIn California\n",
            "- CPRA enforcedIn California\n",
            "- California type Jurisdiction\n",
            "- PGP name Pretty Good Privacy\n",
            "- CCPA jurisdiction California, USA\n",
            "- DifferentialPrivacy name Differential Privacy\n",
            "- CPRA jurisdiction California, USA\n",
            "- DifferentialPrivacy functionality Statistical analysis with privacy protection\n",
            "- PrivacyPreservingDataMining supportsCompliance GDPR\n",
            "- ChoicePointBreach2005 resultedIn CaliforniaBreachNotificationLaw\n",
            "- HIPAA appliesTo CoveredEntity\n",
            "- HIPAA appliesTo CoveredEntity\n",
            "- Encryption supportsCompliance HIPAA\n",
            "- PhilZimmermann jobTitle Creator of Pretty Good Privacy (PGP)\n",
            "- CoveredEntity processes ProtectedHealthInformation\n",
            "\n",
            "\n",
            "Query: Who is covered by privacy protection?\n",
            "Top Relevant Triples:\n",
            "- PrivacyNotice requiredBy HIPAA\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- PGP name Pretty Good Privacy\n",
            "- CoveredEntity processes ProtectedHealthInformation\n",
            "- PrivacyPreservingDataMining supportsCompliance GDPR\n",
            "- CPRA name California Privacy Rights Act\n",
            "- PhilZimmermann jobTitle Creator of Pretty Good Privacy (PGP)\n",
            "- DifferentialPrivacy name Differential Privacy\n",
            "- ProtectedHealthInformation name Protected Health Information\n",
            "- CCPA name California Consumer Privacy Act\n",
            "- GDPR name General Data Protection Regulation\n",
            "- DifferentialPrivacy functionality Statistical analysis with privacy protection\n",
            "- HIPAA appliesTo CoveredEntity\n",
            "- HIPAA appliesTo CoveredEntity\n",
            "- CoveredEntity name Covered Entity\n",
            "- SensitivePersonalInformation name Sensitive Personal Information\n",
            "- CoveredEntity type OrganizationRole\n",
            "- ZeroKnowledgeProof functionality Privacy-preserving authentication\n",
            "- GDPR mandates RightToAccess\n",
            "\n",
            "\n",
            "Query: What are the key differences between the articles tagged with PrivacyLaw?\n",
            "Top Relevant Triples:\n",
            "- DifferentialPrivacy name Differential Privacy\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- HIPAA requiresCompliance PrivacyNotice\n",
            "- PrivacyNotice requiredBy HIPAA\n",
            "- PrivacyPreservingDataMining supportsCompliance GDPR\n",
            "- CPRA name California Privacy Rights Act\n",
            "- GDPR type Legislation\n",
            "- CCPA name California Consumer Privacy Act\n",
            "- PGP name Pretty Good Privacy\n",
            "- DifferentialPrivacy functionality Statistical analysis with privacy protection\n",
            "- HIPAA type Legislation\n",
            "- PhilZimmermann jobTitle Creator of Pretty Good Privacy (PGP)\n",
            "- GDPR legalStatus In force since 2018\n",
            "- CPRA type Legislation\n",
            "- SensitivePersonalInformation name Sensitive Personal Information\n",
            "- HIPAA appliesTo CoveredEntity\n",
            "- HIPAA appliesTo CoveredEntity\n",
            "- GDPR mandates RightToAccess\n",
            "- GDPR mandates RightToAccess\n",
            "- GDPR name General Data Protection Regulation\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}